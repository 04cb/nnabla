# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, Sony Corporation
# This file is distributed under the same license as the Neural Network
# Libraries package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
msgid ""
msgstr ""
"Project-Id-Version: Neural Network Libraries 1.7.0.dev1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-04-27 16:10+0900\n"
"PO-Revision-Date: 2020-05-14 12:08+0900\n"
"Last-Translator: \n"
"Language: ja_JP\n"
"Language-Team: \n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"
"X-Generator: Poedit 2.3.1\n"

#: ../../cpp/command_line_interface.rst:2
msgid "C++ Command Line Interface"
msgstr "C++ コマンドラインインターフェイス"

#: ../../cpp/command_line_interface.rst:4
msgid ""
"Nnabla has c++ version's command line interface utility which can do "
"train, forward(inference). Using this command line interface, developers "
"can run train and infer without any python environment."
msgstr ""
"Nnabla は C++ バージョンのコマンドラインインターフェイスを持っており、学"
"習や推論 ( フォワード ) を実行できます。このコマンドラインインターフェイ"
"スを使うことで、開発者は python 環境がなくても学習や推論を実行できます。"

#: ../../cpp/command_line_interface.rst:8
msgid "usage: nbla (infer|dump|train)"
msgstr "usage: nbla (infer|dump|train)"

#: ../../cpp/command_line_interface.rst:14
msgid "Basic functions"
msgstr "基本機能"

#: ../../cpp/command_line_interface.rst:17
msgid "Forward"
msgstr "Forward"

#: ../../cpp/command_line_interface.rst:19
msgid ""
"usage: nbla infer -e EXECUTOR [-b BATCHSIZE] [-o OUTPUT] "
"input_files ...\n"
"\n"
"arguments:\n"
"   -e EXECUTOR         EXECUTOR is the name of executor network.\n"
"   input_files         input_file must be one of followings.\n"
"                           *.nnp      : Network structure and "
"parameter.\n"
"                           *.nntxt    : Network structure in prototxt "
"format.\n"
"                           *.prototxt : Same as nntxt.\n"
"                           *.h5       : Parameters in h5 format.\n"
"                           *.protobuf : Network structure and parameters "
"in binary.\n"
"                           *.bin      : Input data.\n"
"\n"
"optional arguments:\n"
"   -b BATCHSIZE        batch size for the input data.\n"
"   -o OUTPUT           the filename pattern of output file, default "
"output to stdout.\n"
"\n"
"example:\n"
"    Infer using LeNet_input.bin as input, LeNet_output_0.bin as output:\n"
"       nbla infer -e Executor -b 1 LeNet.nnp LeNet_input.bin -o "
"LeNet_output\n"
"\n"
"    Infer and output the result to console:\n"
"       nbla infer -e Executor -b 1 LeNet.nnp LeNet_input.bin"
msgstr ""
"usage: nbla infer -e EXECUTOR [-b BATCHSIZE] [-o OUTPUT] "
"input_files ...\n"
"\n"
"arguments:\n"
"   -e EXECUTOR         EXECUTOR is the name of executor network.\n"
"   input_files         input_file must be one of followings.\n"
"                           *.nnp      : Network structure and "
"parameter.\n"
"                           *.nntxt    : Network structure in prototxt "
"format.\n"
"                           *.prototxt : Same as nntxt.\n"
"                           *.h5       : Parameters in h5 format.\n"
"                           *.protobuf : Network structure and parameters "
"in binary.\n"
"                           *.bin      : Input data.\n"
"\n"
"optional arguments:\n"
"   -b BATCHSIZE        batch size for the input data.\n"
"   -o OUTPUT           the filename pattern of output file, default "
"output to stdout.\n"
"\n"
"example:\n"
"    Infer using LeNet_input.bin as input, LeNet_output_0.bin as output:\n"
"       nbla infer -e Executor -b 1 LeNet.nnp LeNet_input.bin -o "
"LeNet_output\n"
"\n"
"    Infer and output the result to console:\n"
"       nbla infer -e Executor -b 1 LeNet.nnp LeNet_input.bin"

#: ../../cpp/command_line_interface.rst:46
msgid "Dump"
msgstr "Dump"

#: ../../cpp/command_line_interface.rst:48
msgid ""
"usage: nbla dump input_files ...\n"
"\n"
"arguments:\n"
"   input_files         input_files must be one of *.nnp, *.nntxt, "
"prototxt, h5, protobuf\n"
"\n"
"example:\n"
"    Show network information by dump command:\n"
"      nbla dump LeNet.nnp"
msgstr ""
"usage: nbla dump input_files ...\n"
"\n"
"arguments:\n"
"   input_files         input_files must be one of *.nnp, *.nntxt, "
"prototxt, h5, protobuf\n"
"\n"
"example:\n"
"    Show network information by dump command:\n"
"      nbla dump LeNet.nnp"

#: ../../cpp/command_line_interface.rst:59
msgid "The output looks like:"
msgstr "出力例 :"

#: ../../cpp/command_line_interface.rst:61
msgid ""
"This configuration has 1 executors.\n"
"\n"
"  Executor No.0 Name [Executor]\n"
"    Using default batch size 64 .\n"
"     Inputs\n"
"      Input No.0 Name [x] Shape ( 64 1 28 28 )\n"
"     Outputs\n"
"      Output No.0 Name [y'] Shape ( 64 10 )\n"
"Finished"
msgstr ""
"This configuration has 1 executors.\n"
"\n"
"  Executor No.0 Name [Executor]\n"
"    Using default batch size 64 .\n"
"     Inputs\n"
"      Input No.0 Name [x] Shape ( 64 1 28 28 )\n"
"     Outputs\n"
"      Output No.0 Name [y'] Shape ( 64 10 )\n"
"Finished"

#: ../../cpp/command_line_interface.rst:75
msgid "Train"
msgstr "学習"

#: ../../cpp/command_line_interface.rst:77
msgid ""
"usage: nbla train input_file\n"
"\n"
"arguments:\n"
"   input_file          input_file must be *.nnp"
msgstr ""
"usage: nbla train input_file\n"
"\n"
"arguments:\n"
"   input_file          input_file must be *.nnp"
