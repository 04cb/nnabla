# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, Sony Corporation
# This file is distributed under the same license as the Neural Network
# Libraries package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
msgid ""
msgstr ""
"Project-Id-Version: Neural Network Libraries 1.7.0.dev1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-06-10 15:10+0900\n"
"PO-Revision-Date: 2020-06-15 14:35+0900\n"
"Last-Translator: \n"
"Language: ja_JP\n"
"Language-Team: \n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"
"X-Generator: Poedit 2.3.1\n"

#: ../../python/api/function.rst:5
msgid "Functions"
msgstr "関数"

#: ../../python/api/function.rst:7
msgid ""
"All NNabla functions are derived from the :class:`nnabla.function.Function` "
"class."
msgstr ""
"すべての NNabla 関数は `nnabla.function.Function` クラスから派生しています。"

#: ../../python/api/function.rst:10
msgid "Function"
msgstr "Function"

#: ../../docstring nnabla.function.Function:1 of
msgid "Function interface class."
msgstr "Function のインターフェイスクラス。"

#: ../../docstring nnabla.function.Function:3 of
msgid ""
"Instances of :class:`nnabla.function.Function` are not directly created by "
"users. It is indirectly created by the functions available in :mod:`nnabla."
"functions`. These functions return :class:`nnabla.Variable` (s) holding the "
"created function instance as the parent property."
msgstr ""
":class:`nnabla.function.Function` のインスタンスはユーザによって直接生成されるこ"
"とはありません。 `nnabla.functions` が提供する関数によって間接的に生成されます。"
"これらの関数は、親プロパティとして生成された関数のインスタンスを保持する :class:"
"`nnabla.Variable` を返します。"

#: ../../docstring nnabla.function.Function.info:1 of
msgid "object"
msgstr "object"

#: ../../docstring nnabla.function.Function.info of
msgid "type"
msgstr "型"

#: ../../docstring nnabla.function.Function.info:3 of
msgid "info"
msgstr "info"

#: ../../docstring nnabla.function.Function.tags:1 of
msgid "Experimental"
msgstr "Experimental"

#: ../../docstring nnabla.function.Function.tags:3 of
msgid "Get tags of the function."
msgstr "関数のタグを取得します。"

#: ../../python/api/function.rst:19
msgid "List of Functions"
msgstr "関数のリスト"

#: ../../python/api/function.rst:23
msgid ""
"The :mod:`nnabla.functions` module provides various types of functions listed "
"below. These functions takes input :class:`nnabla.Variable` (s) as its leading "
"argument(s), followed by options specific to each function."
msgstr ""
":mod:`nnabla.functions` モジュールは以下に挙げられた様々な型の関数を提供します。"
"これらの関数は、最初の引数として入力 :class:`nnabla.Variable` を取り、各関数固有"
"のオプションが続きます。"

#: ../../python/api/function.rst:32
msgid "Note:"
msgstr "注意 :"

#: ../../python/api/function.rst:28
msgid ""
"The functions can also take :obj:`~nnabla.NdArray`s as inputs instead of :obj:"
"`~nnabla.Variable`s. It will execute the function operation immediately, and "
"returns :obj:`~nnabla.NdArray` (s) as output(s) holding output values of the "
"operation. We call this \"Imperative Mode\" (NdArray + Functions)."
msgstr ""
"関数は、演算の出力値を保持する出力として :obj:`~nnabla.NdArray` も取ることもでき"
"ます。これを “ 命令モード ” ( NdArray + 関数 ) と呼びます。"

#: ../../python/api/function.rst:35
msgid "Neural Network Layers"
msgstr "ニューラルネットワーク層"

#: nnabla.functions.affine:1 of
msgid "Affine layer, also called as the fully connected layer. It calculates:"
msgstr "Affine 層、全結合層とも呼ばれます。Affine 層は次のように計算します。"

#: nnabla.functions.affine:3 of
msgid "{\\mathbf y} = {\\mathbf A} {\\mathbf x} + {\\mathbf b}."
msgstr ""

#: nnabla.functions.affine:6 of
msgid ""
"where :math:`{\\mathbf x}` is the input and :math:`{\\mathbf y}` is the output."
msgstr "ここで、 :math:`{\\mathbf x}` は入力、 :math:`{\\mathbf y}` は出力です。"

#: nnabla.functions.abs nnabla.functions.absolute_error nnabla.functions.acos
#: nnabla.functions.acosh nnabla.functions.adaptive_separable_convolution
#: nnabla.functions.add2 nnabla.functions.add_n nnabla.functions.add_scalar
#: nnabla.functions.affine nnabla.functions.arange nnabla.functions.asin
#: nnabla.functions.asinh nnabla.functions.assign nnabla.functions.atan
#: nnabla.functions.atan2 nnabla.functions.atanh nnabla.functions.average_pooling
#: nnabla.functions.batch_det nnabla.functions.batch_inv
#: nnabla.functions.batch_matmul nnabla.functions.batch_normalization
#: nnabla.functions.binary_connect_affine
#: nnabla.functions.binary_connect_convolution
#: nnabla.functions.binary_cross_entropy nnabla.functions.binary_error
#: nnabla.functions.binary_sigmoid nnabla.functions.binary_tanh
#: nnabla.functions.binary_weight_affine nnabla.functions.binary_weight_convolution
#: nnabla.functions.broadcast nnabla.functions.broadcast_to
#: nnabla.functions.categorical_cross_entropy nnabla.functions.ceil
#: nnabla.functions.celu nnabla.functions.clip_by_norm
#: nnabla.functions.clip_by_value nnabla.functions.clip_grad_by_norm
#: nnabla.functions.clip_grad_by_value nnabla.functions.concatenate
#: nnabla.functions.confusion_matrix nnabla.functions.constant
#: nnabla.functions.convolution nnabla.functions.cos nnabla.functions.cosh
#: nnabla.functions.crelu nnabla.functions.deconvolution
#: nnabla.functions.depthwise_convolution nnabla.functions.depthwise_deconvolution
#: nnabla.functions.div2 nnabla.functions.dropout nnabla.functions.elu
#: nnabla.functions.embed nnabla.functions.epsilon_insensitive_loss
#: nnabla.functions.equal nnabla.functions.equal_scalar nnabla.functions.exp
#: nnabla.functions.fft nnabla.functions.fixed_point_quantize nnabla.functions.flip
#: nnabla.functions.floor nnabla.functions.fused_batch_normalization
#: nnabla.functions.gather_nd nnabla.functions.gelu
#: nnabla.functions.global_average_pooling nnabla.functions.greater
#: nnabla.functions.greater_equal nnabla.functions.greater_equal_scalar
#: nnabla.functions.greater_scalar nnabla.functions.group_normalization
#: nnabla.functions.gru nnabla.functions.hard_sigmoid nnabla.functions.hard_tanh
#: nnabla.functions.huber_loss nnabla.functions.identity nnabla.functions.ifft
#: nnabla.functions.image_augmentation nnabla.functions.inq_affine
#: nnabla.functions.inq_convolution nnabla.functions.instance_normalization
#: nnabla.functions.interpolate nnabla.functions.isinf nnabla.functions.isnan
#: nnabla.functions.istft nnabla.functions.kl_multinomial
#: nnabla.functions.layer_normalization nnabla.functions.leaky_relu
#: nnabla.functions.less nnabla.functions.less_equal
#: nnabla.functions.less_equal_scalar nnabla.functions.less_scalar
#: nnabla.functions.log nnabla.functions.log_sigmoid nnabla.functions.log_softmax
#: nnabla.functions.logical_and nnabla.functions.logical_and_scalar
#: nnabla.functions.logical_not nnabla.functions.logical_or
#: nnabla.functions.logical_or_scalar nnabla.functions.logical_xor
#: nnabla.functions.logical_xor_scalar nnabla.functions.lstm
#: nnabla.functions.matrix_diag nnabla.functions.matrix_diag_part
#: nnabla.functions.max nnabla.functions.max_pooling nnabla.functions.maximum2
#: nnabla.functions.maximum_scalar nnabla.functions.mean
#: nnabla.functions.mean_subtraction nnabla.functions.min
#: nnabla.functions.min_max_quantize nnabla.functions.minimum2
#: nnabla.functions.minimum_scalar nnabla.functions.mul2 nnabla.functions.mul_n
#: nnabla.functions.mul_scalar nnabla.functions.multi_head_attention
#: nnabla.functions.nms_detection2d nnabla.functions.not_equal
#: nnabla.functions.not_equal_scalar nnabla.functions.one_hot nnabla.functions.pad
#: nnabla.functions.patch_correlation nnabla.functions.pow2
#: nnabla.functions.pow2_quantize nnabla.functions.pow_scalar
#: nnabla.functions.prelu nnabla.functions.prod nnabla.functions.prune
#: nnabla.functions.r_div_scalar nnabla.functions.r_pow_scalar
#: nnabla.functions.r_sub_scalar nnabla.functions.rand nnabla.functions.randint
#: nnabla.functions.randn nnabla.functions.random_choice
#: nnabla.functions.random_crop nnabla.functions.random_erase
#: nnabla.functions.random_flip nnabla.functions.random_shift
#: nnabla.functions.reduce_mean nnabla.functions.reduce_sum nnabla.functions.relu
#: nnabla.functions.relu6 nnabla.functions.reset_inf nnabla.functions.reset_nan
#: nnabla.functions.reshape nnabla.functions.rnn nnabla.functions.round
#: nnabla.functions.scatter_nd nnabla.functions.selu nnabla.functions.shift
#: nnabla.functions.sigmoid nnabla.functions.sigmoid_cross_entropy
#: nnabla.functions.sign nnabla.functions.sin nnabla.functions.sinc
#: nnabla.functions.sinh nnabla.functions.sink nnabla.functions.slice
#: nnabla.functions.softmax nnabla.functions.softmax_cross_entropy
#: nnabla.functions.softplus nnabla.functions.softsign nnabla.functions.sort
#: nnabla.functions.split nnabla.functions.squared_error nnabla.functions.stack
#: nnabla.functions.stft nnabla.functions.sub2 nnabla.functions.sum
#: nnabla.functions.sum_pooling nnabla.functions.swish
#: nnabla.functions.sync_batch_normalization nnabla.functions.tan
#: nnabla.functions.tanh nnabla.functions.tanh_shrink nnabla.functions.tile
#: nnabla.functions.top_k_data nnabla.functions.top_k_grad
#: nnabla.functions.top_n_error nnabla.functions.transpose nnabla.functions.unlink
#: nnabla.functions.unpooling nnabla.functions.vat_noise
#: nnabla.functions.warp_by_flow nnabla.functions.weight_standardization
#: nnabla.functions.where of
msgid "パラメータ"
msgstr "パラメータ"

#: nnabla.functions.affine:8 of
msgid ""
"Input N-D array with shape (:math:`M_0 \\times ... \\times M_{B-1} \\times D_B "
"\\times ... \\times D_N`). Dimensions before and after base_axis are flattened "
"as if it is a matrix."
msgstr ""
"(:math:`M_0 \\times ... \\times M_{B-1} \\times D_B \\times ... \\times D_N`) の"
"形状の入力 N-D 配列。 base_axis 前後の次元は行列のように平坦化されます。"

#: nnabla.functions.affine:10 of
msgid ""
"Weight matrix with shape (:math:`(D_B \\times ... \\times D_N) \\times L_{0} "
"\\times \\ldots \\times L_{I}`) [parameter]"
msgstr ""
"(:math:`(D_B \\times ... \\times D_N) \\times L_{0} \\times \\ldots \\times L_{I}"
"`) の形状の重みの行列 [ パラメータ ]"

#: nnabla.functions.affine:13 of
msgid ""
"Bias vector (:math:`L_{0} \\times \\ldots \\times L_{I}`) [optional][parameter]"
msgstr ""
"バイアスのベクトル (:math:`L_{0} \\times \\ldots \\times L_{I}`) [ オプション ]"
"[ パラメータ]"

#: nnabla.functions.affine:16 of
msgid ""
"Base axis of Affine operation. Dimensions up to base_axis is treated as sample "
"dimension. [default=``1``]"
msgstr ""
"Affine 演算の基本軸。base_axis までの次元はサンプルの次元として扱われます。 [ デ"
"フォルト = ``1`` ]"

#: nnabla.functions.abs nnabla.functions.absolute_error nnabla.functions.acos
#: nnabla.functions.acosh nnabla.functions.adaptive_separable_convolution
#: nnabla.functions.add2 nnabla.functions.add_n nnabla.functions.add_scalar
#: nnabla.functions.affine nnabla.functions.arange nnabla.functions.asin
#: nnabla.functions.asinh nnabla.functions.assign nnabla.functions.atan
#: nnabla.functions.atan2 nnabla.functions.atanh nnabla.functions.average_pooling
#: nnabla.functions.batch_det nnabla.functions.batch_inv
#: nnabla.functions.batch_matmul nnabla.functions.batch_normalization
#: nnabla.functions.binary_connect_affine
#: nnabla.functions.binary_connect_convolution
#: nnabla.functions.binary_cross_entropy nnabla.functions.binary_error
#: nnabla.functions.binary_sigmoid nnabla.functions.binary_tanh
#: nnabla.functions.binary_weight_affine nnabla.functions.binary_weight_convolution
#: nnabla.functions.broadcast nnabla.functions.broadcast_to
#: nnabla.functions.categorical_cross_entropy nnabla.functions.ceil
#: nnabla.functions.celu nnabla.functions.clip_by_norm
#: nnabla.functions.clip_by_value nnabla.functions.clip_grad_by_norm
#: nnabla.functions.clip_grad_by_value nnabla.functions.concatenate
#: nnabla.functions.confusion_matrix nnabla.functions.constant
#: nnabla.functions.convolution nnabla.functions.cos nnabla.functions.cosh
#: nnabla.functions.crelu nnabla.functions.deconvolution
#: nnabla.functions.depthwise_convolution nnabla.functions.depthwise_deconvolution
#: nnabla.functions.div2 nnabla.functions.dropout nnabla.functions.elu
#: nnabla.functions.embed nnabla.functions.epsilon_insensitive_loss
#: nnabla.functions.equal nnabla.functions.equal_scalar nnabla.functions.exp
#: nnabla.functions.fft nnabla.functions.fixed_point_quantize nnabla.functions.flip
#: nnabla.functions.floor nnabla.functions.fused_batch_normalization
#: nnabla.functions.gelu nnabla.functions.global_average_pooling
#: nnabla.functions.greater nnabla.functions.greater_equal
#: nnabla.functions.greater_equal_scalar nnabla.functions.greater_scalar
#: nnabla.functions.group_normalization nnabla.functions.gru
#: nnabla.functions.hard_sigmoid nnabla.functions.hard_tanh
#: nnabla.functions.huber_loss nnabla.functions.identity nnabla.functions.ifft
#: nnabla.functions.image_augmentation nnabla.functions.inq_affine
#: nnabla.functions.inq_convolution nnabla.functions.instance_normalization
#: nnabla.functions.interpolate nnabla.functions.isinf nnabla.functions.isnan
#: nnabla.functions.istft nnabla.functions.kl_multinomial
#: nnabla.functions.layer_normalization nnabla.functions.leaky_relu
#: nnabla.functions.less nnabla.functions.less_equal
#: nnabla.functions.less_equal_scalar nnabla.functions.less_scalar
#: nnabla.functions.log nnabla.functions.log_sigmoid nnabla.functions.log_softmax
#: nnabla.functions.logical_and nnabla.functions.logical_and_scalar
#: nnabla.functions.logical_not nnabla.functions.logical_or
#: nnabla.functions.logical_or_scalar nnabla.functions.logical_xor
#: nnabla.functions.logical_xor_scalar nnabla.functions.lstm
#: nnabla.functions.matrix_diag nnabla.functions.matrix_diag_part
#: nnabla.functions.max nnabla.functions.max_pooling nnabla.functions.maximum2
#: nnabla.functions.maximum_scalar nnabla.functions.mean
#: nnabla.functions.mean_subtraction nnabla.functions.min nnabla.functions.minimum2
#: nnabla.functions.minimum_scalar nnabla.functions.mul2 nnabla.functions.mul_n
#: nnabla.functions.mul_scalar nnabla.functions.multi_head_attention
#: nnabla.functions.nms_detection2d nnabla.functions.not_equal
#: nnabla.functions.not_equal_scalar nnabla.functions.one_hot nnabla.functions.pad
#: nnabla.functions.patch_correlation nnabla.functions.pow2
#: nnabla.functions.pow2_quantize nnabla.functions.pow_scalar
#: nnabla.functions.prelu nnabla.functions.prod nnabla.functions.prune
#: nnabla.functions.r_div_scalar nnabla.functions.r_pow_scalar
#: nnabla.functions.r_sub_scalar nnabla.functions.rand nnabla.functions.randint
#: nnabla.functions.randn nnabla.functions.random_choice
#: nnabla.functions.random_crop nnabla.functions.random_erase
#: nnabla.functions.random_flip nnabla.functions.random_shift
#: nnabla.functions.reduce_mean nnabla.functions.reduce_sum nnabla.functions.relu
#: nnabla.functions.relu6 nnabla.functions.reset_inf nnabla.functions.reset_nan
#: nnabla.functions.reshape nnabla.functions.rnn nnabla.functions.round
#: nnabla.functions.selu nnabla.functions.shift nnabla.functions.sigmoid
#: nnabla.functions.sigmoid_cross_entropy nnabla.functions.sign
#: nnabla.functions.sin nnabla.functions.sinc nnabla.functions.sinh
#: nnabla.functions.sink nnabla.functions.slice nnabla.functions.softmax
#: nnabla.functions.softmax_cross_entropy nnabla.functions.softplus
#: nnabla.functions.softsign nnabla.functions.squared_error nnabla.functions.stack
#: nnabla.functions.stft nnabla.functions.sub2 nnabla.functions.sum
#: nnabla.functions.sum_pooling nnabla.functions.swish
#: nnabla.functions.sync_batch_normalization nnabla.functions.tan
#: nnabla.functions.tanh nnabla.functions.tanh_shrink nnabla.functions.tile
#: nnabla.functions.top_k_data nnabla.functions.top_k_grad
#: nnabla.functions.top_n_error nnabla.functions.transpose nnabla.functions.unlink
#: nnabla.functions.unpooling nnabla.functions.vat_noise
#: nnabla.functions.warp_by_flow nnabla.functions.weight_standardization
#: nnabla.functions.where of
msgid "戻り値"
msgstr "戻り値"

#: nnabla.functions.affine:20 of
msgid ""
":math:`(B + 1)`-D array. (:math:`M_0 \\times ... \\times M_{B-1} \\times L_{0} "
"\\times \\ldots \\times L_{I}`)"
msgstr ""
":math:`(B + 1)` -D 配列。 (:math:`M_0 \\times ... \\times M_{B-1} \\times L_{0} "
"\\times \\ldots \\times L_{I}`)"

#: nnabla.functions.abs nnabla.functions.absolute_error nnabla.functions.acos
#: nnabla.functions.acosh nnabla.functions.adaptive_separable_convolution
#: nnabla.functions.add2 nnabla.functions.add_n nnabla.functions.add_scalar
#: nnabla.functions.affine nnabla.functions.arange nnabla.functions.asin
#: nnabla.functions.asinh nnabla.functions.assign nnabla.functions.atan
#: nnabla.functions.atan2 nnabla.functions.atanh nnabla.functions.average_pooling
#: nnabla.functions.batch_det nnabla.functions.batch_inv
#: nnabla.functions.batch_matmul nnabla.functions.binary_connect_affine
#: nnabla.functions.binary_connect_convolution
#: nnabla.functions.binary_cross_entropy nnabla.functions.binary_error
#: nnabla.functions.binary_sigmoid nnabla.functions.binary_tanh
#: nnabla.functions.binary_weight_affine nnabla.functions.binary_weight_convolution
#: nnabla.functions.broadcast nnabla.functions.broadcast_to
#: nnabla.functions.categorical_cross_entropy nnabla.functions.ceil
#: nnabla.functions.celu nnabla.functions.clip_by_norm
#: nnabla.functions.clip_by_value nnabla.functions.clip_grad_by_norm
#: nnabla.functions.clip_grad_by_value nnabla.functions.concatenate
#: nnabla.functions.confusion_matrix nnabla.functions.constant
#: nnabla.functions.convolution nnabla.functions.cos nnabla.functions.cosh
#: nnabla.functions.crelu nnabla.functions.deconvolution
#: nnabla.functions.depthwise_convolution nnabla.functions.depthwise_deconvolution
#: nnabla.functions.div2 nnabla.functions.dropout nnabla.functions.elu
#: nnabla.functions.embed nnabla.functions.epsilon_insensitive_loss
#: nnabla.functions.equal nnabla.functions.equal_scalar nnabla.functions.exp
#: nnabla.functions.fft nnabla.functions.fixed_point_quantize nnabla.functions.flip
#: nnabla.functions.floor nnabla.functions.gelu
#: nnabla.functions.global_average_pooling nnabla.functions.greater
#: nnabla.functions.greater_equal nnabla.functions.greater_equal_scalar
#: nnabla.functions.greater_scalar nnabla.functions.group_normalization
#: nnabla.functions.gru nnabla.functions.hard_sigmoid nnabla.functions.hard_tanh
#: nnabla.functions.huber_loss nnabla.functions.identity nnabla.functions.ifft
#: nnabla.functions.image_augmentation nnabla.functions.inq_affine
#: nnabla.functions.inq_convolution nnabla.functions.instance_normalization
#: nnabla.functions.interpolate nnabla.functions.isinf nnabla.functions.isnan
#: nnabla.functions.istft nnabla.functions.kl_multinomial
#: nnabla.functions.layer_normalization nnabla.functions.leaky_relu
#: nnabla.functions.less nnabla.functions.less_equal
#: nnabla.functions.less_equal_scalar nnabla.functions.less_scalar
#: nnabla.functions.log nnabla.functions.log_sigmoid nnabla.functions.log_softmax
#: nnabla.functions.logical_and nnabla.functions.logical_and_scalar
#: nnabla.functions.logical_not nnabla.functions.logical_or
#: nnabla.functions.logical_or_scalar nnabla.functions.logical_xor
#: nnabla.functions.logical_xor_scalar nnabla.functions.lstm
#: nnabla.functions.matrix_diag nnabla.functions.matrix_diag_part
#: nnabla.functions.max nnabla.functions.max_pooling nnabla.functions.maximum2
#: nnabla.functions.maximum_scalar nnabla.functions.mean
#: nnabla.functions.mean_subtraction nnabla.functions.min nnabla.functions.minimum2
#: nnabla.functions.minimum_scalar nnabla.functions.mul2 nnabla.functions.mul_n
#: nnabla.functions.mul_scalar nnabla.functions.multi_head_attention
#: nnabla.functions.nms_detection2d nnabla.functions.not_equal
#: nnabla.functions.not_equal_scalar nnabla.functions.one_hot nnabla.functions.pad
#: nnabla.functions.patch_correlation nnabla.functions.pow2
#: nnabla.functions.pow2_quantize nnabla.functions.pow_scalar
#: nnabla.functions.prelu nnabla.functions.prod nnabla.functions.prune
#: nnabla.functions.r_div_scalar nnabla.functions.r_pow_scalar
#: nnabla.functions.r_sub_scalar nnabla.functions.rand nnabla.functions.randint
#: nnabla.functions.randn nnabla.functions.random_choice
#: nnabla.functions.random_crop nnabla.functions.random_erase
#: nnabla.functions.random_flip nnabla.functions.random_shift
#: nnabla.functions.reduce_mean nnabla.functions.reduce_sum nnabla.functions.relu
#: nnabla.functions.relu6 nnabla.functions.reset_inf nnabla.functions.reset_nan
#: nnabla.functions.reshape nnabla.functions.rnn nnabla.functions.round
#: nnabla.functions.selu nnabla.functions.shift nnabla.functions.sigmoid
#: nnabla.functions.sigmoid_cross_entropy nnabla.functions.sign
#: nnabla.functions.sin nnabla.functions.sinc nnabla.functions.sinh
#: nnabla.functions.sink nnabla.functions.slice nnabla.functions.softmax
#: nnabla.functions.softmax_cross_entropy nnabla.functions.softplus
#: nnabla.functions.softsign nnabla.functions.squared_error nnabla.functions.stack
#: nnabla.functions.sub2 nnabla.functions.sum nnabla.functions.sum_pooling
#: nnabla.functions.swish nnabla.functions.tan nnabla.functions.tanh
#: nnabla.functions.tanh_shrink nnabla.functions.tile nnabla.functions.top_k_data
#: nnabla.functions.top_k_grad nnabla.functions.top_n_error
#: nnabla.functions.transpose nnabla.functions.unlink nnabla.functions.unpooling
#: nnabla.functions.vat_noise nnabla.functions.warp_by_flow
#: nnabla.functions.weight_standardization nnabla.functions.where of
msgid "戻り値の型"
msgstr "戻り値の型"

#: nnabla.functions.abs:14 nnabla.functions.absolute_error:16
#: nnabla.functions.acos:14 nnabla.functions.acosh:14
#: nnabla.functions.adaptive_separable_convolution:41 nnabla.functions.add2:19
#: nnabla.functions.add_n:15 nnabla.functions.add_scalar:18
#: nnabla.functions.affine:25 nnabla.functions.arange:18 nnabla.functions.asin:14
#: nnabla.functions.asinh:14 nnabla.functions.assign:30 nnabla.functions.atan:14
#: nnabla.functions.atan2:16 nnabla.functions.atanh:14
#: nnabla.functions.average_pooling:33 nnabla.functions.batch_det:11
#: nnabla.functions.batch_inv:11 nnabla.functions.batch_matmul:21
#: nnabla.functions.binary_connect_affine:60
#: nnabla.functions.binary_connect_convolution:73
#: nnabla.functions.binary_cross_entropy:17 nnabla.functions.binary_error:22
#: nnabla.functions.binary_sigmoid:32 nnabla.functions.binary_tanh:32
#: nnabla.functions.binary_weight_affine:61
#: nnabla.functions.binary_weight_convolution:74 nnabla.functions.broadcast:13
#: nnabla.functions.broadcast_to:19 nnabla.functions.categorical_cross_entropy:23
#: nnabla.functions.ceil:22 nnabla.functions.celu:18
#: nnabla.functions.clip_grad_by_norm:36 nnabla.functions.clip_grad_by_value:36
#: nnabla.functions.concatenate:15 nnabla.functions.confusion_matrix:17
#: nnabla.functions.constant:15 nnabla.functions.convolution:70
#: nnabla.functions.cos:14 nnabla.functions.cosh:14 nnabla.functions.crelu:24
#: nnabla.functions.deconvolution:47 nnabla.functions.depthwise_convolution:53
#: nnabla.functions.depthwise_deconvolution:47 nnabla.functions.div2:16
#: nnabla.functions.dropout:39 nnabla.functions.elu:26 nnabla.functions.embed:14
#: nnabla.functions.epsilon_insensitive_loss:22 nnabla.functions.equal:19
#: nnabla.functions.equal_scalar:20 nnabla.functions.exp:14 nnabla.functions.fft:53
#: nnabla.functions.flip:14 nnabla.functions.floor:22 nnabla.functions.gelu:25
#: nnabla.functions.global_average_pooling:14 nnabla.functions.greater:20
#: nnabla.functions.greater_equal:20 nnabla.functions.greater_equal_scalar:21
#: nnabla.functions.greater_scalar:21 nnabla.functions.gru:48
#: nnabla.functions.hard_sigmoid:15 nnabla.functions.hard_tanh:15
#: nnabla.functions.huber_loss:25 nnabla.functions.identity:14
#: nnabla.functions.ifft:32 nnabla.functions.image_augmentation:59
#: nnabla.functions.inq_affine:50 nnabla.functions.inq_convolution:62
#: nnabla.functions.isinf:11 nnabla.functions.isnan:11
#: nnabla.functions.kl_multinomial:19 nnabla.functions.leaky_relu:23
#: nnabla.functions.less:21 nnabla.functions.less_equal:21
#: nnabla.functions.less_equal_scalar:22 nnabla.functions.less_scalar:21
#: nnabla.functions.log:14 nnabla.functions.log_sigmoid:14
#: nnabla.functions.log_softmax:35 nnabla.functions.logical_and:19
#: nnabla.functions.logical_and_scalar:19 nnabla.functions.logical_not:17
#: nnabla.functions.logical_or:18 nnabla.functions.logical_or_scalar:18
#: nnabla.functions.logical_xor:20 nnabla.functions.logical_xor_scalar:20
#: nnabla.functions.lstm:52 nnabla.functions.matrix_diag:11
#: nnabla.functions.matrix_diag_part:12 nnabla.functions.max_pooling:30
#: nnabla.functions.maximum2:16 nnabla.functions.maximum_scalar:17
#: nnabla.functions.minimum2:16 nnabla.functions.minimum_scalar:17
#: nnabla.functions.mul2:16 nnabla.functions.mul_n:15
#: nnabla.functions.mul_scalar:17 nnabla.functions.nms_detection2d:52
#: nnabla.functions.not_equal:19 nnabla.functions.not_equal_scalar:20
#: nnabla.functions.one_hot:62 nnabla.functions.pad:63 nnabla.functions.pow2:16
#: nnabla.functions.pow_scalar:17 nnabla.functions.prelu:22
#: nnabla.functions.prune:25 nnabla.functions.r_div_scalar:17
#: nnabla.functions.r_pow_scalar:17 nnabla.functions.r_sub_scalar:17
#: nnabla.functions.rand:23 nnabla.functions.randint:23 nnabla.functions.randn:23
#: nnabla.functions.random_choice:66 nnabla.functions.random_crop:20
#: nnabla.functions.random_erase:75 nnabla.functions.random_flip:20
#: nnabla.functions.random_shift:23 nnabla.functions.reduce_mean:13
#: nnabla.functions.reduce_sum:13 nnabla.functions.relu:17
#: nnabla.functions.relu6:15 nnabla.functions.reset_inf:14
#: nnabla.functions.reset_nan:14 nnabla.functions.reshape:21
#: nnabla.functions.rnn:49 nnabla.functions.round:22 nnabla.functions.selu:52
#: nnabla.functions.shift:17 nnabla.functions.sigmoid:15
#: nnabla.functions.sigmoid_cross_entropy:24 nnabla.functions.sign:31
#: nnabla.functions.sin:14 nnabla.functions.sinc:14 nnabla.functions.sinh:14
#: nnabla.functions.sink:27 nnabla.functions.slice:25 nnabla.functions.softmax:19
#: nnabla.functions.softmax_cross_entropy:25 nnabla.functions.softplus:15
#: nnabla.functions.softsign:16 nnabla.functions.squared_error:16
#: nnabla.functions.stack:20 nnabla.functions.sub2:16
#: nnabla.functions.sum_pooling:30 nnabla.functions.swish:20
#: nnabla.functions.tan:14 nnabla.functions.tanh:14 nnabla.functions.tanh_shrink:14
#: nnabla.functions.top_k_data:40 nnabla.functions.top_k_grad:25
#: nnabla.functions.top_n_error:28 nnabla.functions.transpose:13
#: nnabla.functions.unlink:27 nnabla.functions.unpooling:18
#: nnabla.functions.vat_noise:44 nnabla.functions.warp_by_flow:26
#: nnabla.functions.where:35 of
msgid ""
"All nnabla functions in :obj:`nnabla.functions` are decorated with the :obj:"
"`nnabla.function_bases.function_api` decorator, which queries the current "
"context and passes it into the first argument of the original function. The "
"original function always takes a context as the first argument."
msgstr ""
":obj:`nnabla.functions` にあるすべての nnabla 関数は `nnabla.function_bases."
"function_api` デコレーターを使ってデコレートされ、デコレーターは現在のコンテキス"
"トを問い合わせて元の関数の第一引数に渡します。元の関数は常に第一引数としてコンテ"
"キストを取ります。"

#: nnabla.functions.convolution:1 of
msgid "N-D Convolution with bias."
msgstr "バイアスを伴う N-D Convolution。"

#: nnabla.functions.convolution:3 of
msgid "See references for dilated convolution (a.k.a. atrous convolution)."
msgstr ""
"拡張型 Convolution (通称 Atrous Convolution) については以下を参照してください。"

#: nnabla.functions.adaptive_separable_convolution:20
#: nnabla.functions.batch_normalization:15
#: nnabla.functions.binary_connect_affine:32 nnabla.functions.binary_sigmoid:19
#: nnabla.functions.binary_tanh:19 nnabla.functions.convolution:6
#: nnabla.functions.crelu:7 nnabla.functions.depthwise_convolution:4
#: nnabla.functions.elu:11 nnabla.functions.fused_batch_normalization:4
#: nnabla.functions.gelu:12 nnabla.functions.group_normalization:22
#: nnabla.functions.gru:13 nnabla.functions.inq_affine:13
#: nnabla.functions.instance_normalization:17
#: nnabla.functions.layer_normalization:17 nnabla.functions.lstm:14
#: nnabla.functions.min_max_quantize:110 nnabla.functions.multi_head_attention:8
#: nnabla.functions.nms_detection2d:31 nnabla.functions.patch_correlation:72
#: nnabla.functions.random_erase:29 nnabla.functions.rnn:11
#: nnabla.functions.selu:33 nnabla.functions.swish:8
#: nnabla.functions.sync_batch_normalization:15 nnabla.functions.vat_noise:24
#: nnabla.functions.weight_standardization:12 of
msgid "参照"
msgstr "参照"

#: nnabla.functions.convolution:7 of
msgid ""
"`Chen et al., DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, "
"Atrous Convolution, and Fully Connected CRFs. <https://arxiv.org/"
"abs/1606.00915>`_"
msgstr ""
"`Chen et al., DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, "
"Atrous Convolution, and Fully Connected CRFs. <https://arxiv.org/"
"abs/1606.00915>`_"

#: nnabla.functions.convolution:11 of
msgid ""
"`Yu et al., Multi-Scale Context Aggregation by Dilated Convolutions. <https://"
"arxiv.org/abs/1511.07122>`_"
msgstr ""
"`Yu et al., Multi-Scale Context Aggregation by Dilated Convolutions. <https://"
"arxiv.org/abs/1511.07122>`_"

#: nnabla.functions.convolution:16 of
msgid ""
"Convolution is a computationally intensive operation that should preferrably be "
"run with the `cudnn` backend. NNabla then uses CuDNN library functions to "
"determine and cache the fastest algorithm for the given set of convolution "
"parameters, which results in additional memory consumption which may pose a "
"problem for GPUs with insufficient memory size. In that case, the "
"`NNABLA_CUDNN_WORKSPACE_LIMIT` environment variable can be used to restrict the "
"choice of algorithms to those that fit the given workspace memory limit, "
"expressed in bytes. In some cases it may also be desired to restrict the "
"automatic search to algorithms that produce deterministic (reproducable) "
"results. This can be requested by setting the the environment variable "
"`NNABLA_CUDNN_DETERMINISTIC` to a non-zero value."
msgstr ""
"Convolution は計算量が集中する演算であるため、 `cudnn` バックエンドを使って実行す"
"ることを推奨します。そして、NNabla は CuDNN ライブラリ関数を使用して指定された "
"convolution パラメータセットによる最速アルゴリズムを決定およびキャッシュするた"
"め、結果的にメモリーの追加消費により、GPU のメモリサイズが足りないという問題が発"
"生する可能性があります。そのような場合は、バイト単位で指定する環境変数 "
"`NNABLA_CUDNN_WORKSPACE_LIMIT` を使って、ワークスペースのメモリ制限に適合するよう"
"にアルゴリズムの選択肢を制限できます。また自動検索を確定的な（再現可能な）結果を"
"生成するアルゴリズムに制約した方がよい場合もあります。これは、環境変数 "
"`NNABLA_CUDNN_DETERMINISTIC` をゼロでない値に設定することで要求できます。"

#: nnabla.functions.convolution:30 nnabla.functions.deconvolution:7
#: nnabla.functions.depthwise_convolution:8
#: nnabla.functions.depthwise_deconvolution:3 of
msgid ""
":math:`(B + 1 + N)`-D array (:math:`M_1 \\times ... \\times M_B \\times C "
"\\times L_1 \\times ... \\times L_N`)."
msgstr ""
":math:`(B + 1 + N)` -D 配列 (:math:`M_1 \\times ... \\times M_B \\times C "
"\\times L_1 \\times ... \\times L_N`) 。"

#: nnabla.functions.convolution:32 nnabla.functions.deconvolution:9 of
msgid ""
":math:`(2 + N)`-D array (:math:`C' \\times C \\times K_1 \\times ... \\times "
"K_N`). [parameter]"
msgstr ""
":math:`(2 + N)` -D 配列 (:math:`C' \\times C \\times K_1 \\times ... \\times "
"K_N`) 。 [ パラメータ]"

#: nnabla.functions.convolution:35 nnabla.functions.deconvolution:12 of
msgid "Bias vector (:math:`C'`). [optional][parameter]"
msgstr "バイアスのベクトル (:math:`C'`) 。[ オプション ][ パラメータ ]"

#: nnabla.functions.convolution:38 nnabla.functions.deconvolution:15
#: nnabla.functions.depthwise_convolution:16
#: nnabla.functions.depthwise_deconvolution:11 of
msgid "base axis :math:`B`. [default=``1``]"
msgstr "基本軸 :math:`B` 。 [ デフォルト = ``1`` ]"

#: nnabla.functions.binary_connect_convolution:52
#: nnabla.functions.binary_weight_convolution:53 nnabla.functions.convolution:41
#: nnabla.functions.deconvolution:18 nnabla.functions.depthwise_convolution:19
#: nnabla.functions.depthwise_deconvolution:14 nnabla.functions.inq_convolution:32
#: of
msgid ""
"Padding sizes for dimensions. [default=``(0,) * (len(x.shape) - (base_axis+1))``]"
msgstr ""
"次元のパディングサイズ。 [ デフォルト = ``(0,) * (len(x.shape) - (base_axis"
"+1))`` ]"

#: nnabla.functions.binary_connect_convolution:55
#: nnabla.functions.binary_weight_convolution:56 nnabla.functions.convolution:44
#: nnabla.functions.deconvolution:21 nnabla.functions.depthwise_convolution:22
#: nnabla.functions.depthwise_deconvolution:17 nnabla.functions.inq_convolution:35
#: of
msgid ""
"Stride sizes for dimensions. [default=``(1,) * (len(x.shape) - (base_axis+1))``]"
msgstr ""
"次元のストライドサイズ。 [ デフォルト = ``(1,) * (len(x.shape) - (base_axis"
"+1))`` ]"

#: nnabla.functions.binary_connect_convolution:58
#: nnabla.functions.binary_weight_convolution:59 nnabla.functions.convolution:47
#: nnabla.functions.deconvolution:24 nnabla.functions.depthwise_convolution:25
#: nnabla.functions.depthwise_deconvolution:20 nnabla.functions.inq_convolution:38
#: of
msgid ""
"Dilation sizes for dimensions. [default=``(1,) * (len(x.shape) - (base_axis"
"+1))``]"
msgstr ""
"次元の拡張サイズ。 [ デフォルト = ``(1,) * (len(x.shape) - (base_axis+1))`` ]"

#: nnabla.functions.binary_connect_convolution:61
#: nnabla.functions.binary_weight_convolution:62 nnabla.functions.convolution:50
#: nnabla.functions.deconvolution:27 nnabla.functions.inq_convolution:41 of
msgid ""
"Number of groups of channels. This makes the connection across channels sparser, "
"by grouping connections along the mapping direction. [default=``1``]"
msgstr ""
"チャネルのグループ数。マップ方向に沿って接続をグループ化することにより、チャネル"
"間の接続がより疎らになります。 [ デフォルト = ``1`` ]"

#: nnabla.functions.average_pooling:21 nnabla.functions.convolution:53
#: nnabla.functions.deconvolution:30 nnabla.functions.max_pooling:21
#: nnabla.functions.random_erase:63 nnabla.functions.sum_pooling:21 of
msgid ""
"If True, the last dimension is considered as channel dimension, a.k.a NHWC "
"order. [default=``False``]"
msgstr ""
"True の場合、最後の次元はチャネル (通常、 NHWC 形式) となります。 [ デフォルト = "
"``False`` ]"

#: nnabla.functions.convolution:57 of
msgid ""
":math:`(B + 1 + N)`-D array (:math:`M_1 \\times ... \\times M_B \\times C' "
"\\times L'_1 \\times ... \\times L'_N`).  A spatial size of the output is "
"calculated as  .. math::    L'_i = \\frac{L_i + 2 p_i - d_i (k_i - 1) - 1}{s_i} "
"+ 1,  where :math:`L_i` is the spatial size, :math:`p_i` is the padding, :math:"
"`d_i` is the dilation, :math:`k_i` is the kernel size, and :math:`s_i` is the "
"stride for :math:`i`-th spatial dimension. The same calculation can also be "
"applied to the other spatial dimensions."
msgstr ""

#: nnabla.functions.convolution:57 nnabla.functions.deconvolution:34
#: nnabla.functions.depthwise_convolution:32
#: nnabla.functions.depthwise_deconvolution:27 of
msgid ""
":math:`(B + 1 + N)`-D array (:math:`M_1 \\times ... \\times M_B \\times C' "
"\\times L'_1 \\times ... \\times L'_N`)."
msgstr ""

#: nnabla.functions.convolution:59 nnabla.functions.deconvolution:36
#: nnabla.functions.depthwise_convolution:42
#: nnabla.functions.depthwise_deconvolution:37
#: nnabla.functions.patch_correlation:105 of
msgid "A spatial size of the output is calculated as"
msgstr "出力の空間サイズは、以下のように計算します。"

#: nnabla.functions.convolution:61 nnabla.functions.depthwise_convolution:44 of
msgid "L'_i = \\frac{L_i + 2 p_i - d_i (k_i - 1) - 1}{s_i} + 1,"
msgstr ""

#: nnabla.functions.convolution:65 nnabla.functions.depthwise_convolution:48 of
msgid ""
"where :math:`L_i` is the spatial size, :math:`p_i` is the padding, :math:`d_i` "
"is the dilation, :math:`k_i` is the kernel size, and :math:`s_i` is the stride "
"for :math:`i`-th spatial dimension. The same calculation can also be applied to "
"the other spatial dimensions."
msgstr ""
"ここで、 :math:`L_i` は空間サイズ、 :math:`p_i` は パディング、 :math:`d_i` は拡"
"張、 :math:`k_i` はカーネルサイズ、 :math:`s_i` は :math:`i` 空間次元のストライド"
"です。同様の計算は他の空間次元へも適用できます。"

#: nnabla.functions.depthwise_convolution:1 of
msgid "N-D Depthwise Convolution with bias."
msgstr "バイアスを伴う N-D Depthwise Convolution。"

#: nnabla.functions.depthwise_convolution:5 of
msgid ""
"`F. Chollet. Xception: Deep Learning with Depthwise Separable Convolutions. "
"<https://arxiv.org/abs/1610.02357>`_"
msgstr ""

#: nnabla.functions.depthwise_convolution:10
#: nnabla.functions.depthwise_deconvolution:5 of
msgid ""
":math:`(1 + N)`-D array (:math:`C \\times K_1 \\times ... \\times K_N`). "
"[parameter]"
msgstr ""
":math:`(1 + N)` -D 配列 (:math:`C \\times K_1 \\times ... \\times K_N`) 。 [ パラ"
"メータ ]"

#: nnabla.functions.depthwise_convolution:13
#: nnabla.functions.depthwise_deconvolution:8 of
msgid "Bias vector (:math:`C`). [optional][parameter]"
msgstr "バイアスのベクトル (:math:`C`) 。 [ オプション ][ パラメータ ]"

#: nnabla.functions.depthwise_convolution:28 of
msgid "Number of output feature maps per input feature map. [default=``1``]"
msgstr "入力特徴マップごとの出力特徴マップの数。 [ デフォルト = ``1`` ]"

#: nnabla.functions.depthwise_convolution:32 of
msgid ""
":math:`(B + 1 + N)`-D array (:math:`M_1 \\times ... \\times M_B \\times C' "
"\\times L'_1 \\times ... \\times L'_N`).  The output map size :math:`C'` is :"
"math:`C` multiplied by :math:`m`  .. math::    C' =  m \\times C,  where :math:"
"`m` is the multiplier.  A spatial size of the output is calculated as  .. "
"math::    L'_i = \\frac{L_i + 2 p_i - d_i (k_i - 1) - 1}{s_i} + 1,  where :math:"
"`L_i` is the spatial size, :math:`p_i` is the padding, :math:`d_i` is the "
"dilation, :math:`k_i` is the kernel size, and :math:`s_i` is the stride for :"
"math:`i`-th spatial dimension. The same calculation can also be applied to the "
"other spatial dimensions."
msgstr ""

#: nnabla.functions.depthwise_convolution:34
#: nnabla.functions.depthwise_deconvolution:29 of
msgid "The output map size :math:`C'` is :math:`C` multiplied by :math:`m`"
msgstr "出力のマップサイズ :math:`C'` は :math:`C` に :math:`m` を掛けて"

#: nnabla.functions.depthwise_convolution:36 of
msgid "C' =  m \\times C,"
msgstr ""

#: nnabla.functions.depthwise_convolution:40 of
msgid "where :math:`m` is the multiplier."
msgstr "となります。ここで、 :math:`m` は乗数です。"

#: nnabla.functions.deconvolution:1 of
msgid ""
"N-D deconvolution, also known as transposed convolution, with bias operates "
"backward convolution (derivative of the output w.r.t. the input) plus channel-"
"wise learned bias."
msgstr ""
"N-D deconvolution は、transposed convolution としても知られています。逆方向の畳み"
"込み (入力に対する出力の微分) にチャネルごとに学習したバイアス加えて演算を行いま"
"す。"

#: nnabla.functions.deconvolution:3 of
msgid ""
"The weights are specified in the same manner as :meth:`~nnabla.functions."
"convolution` , as if it was an ordinary convolution function. The forward "
"operation of :meth:`~nnabla.functions.deconvolution` will then be operationally "
"equivalent to the backward pass of :meth:`~nnabla.functions.convolution` . "
"Therefore, the number of input channels (can be seen as output channels of "
"forward convolution) is specified in the first dimension, and the number of the "
"output channels divided by the number of groups is specified in the second "
"dimension."
msgstr ""
"通常の convolution 関数のように、 :meth:`~nnabla.functions.convolution` と同じ方"
"法で重みを指定します。そして、 :meth:`~nnabla.functions.deconvolution` の "
"forward 演算が :meth:`~nnabla.functions.convolution` の逆方向パスと演算的に同等に"
"行われます。したがって、入力のチャネル数 ( forward convolution の出力として認識で"
"きる) を 1 次元目で指定し、グループ数で割った出力のチャネル数を 2 次元目で指定し"
"ます。"

#: nnabla.functions.deconvolution:34 of
msgid ""
":math:`(B + 1 + N)`-D array (:math:`M_1 \\times ... \\times M_B \\times C' "
"\\times L'_1 \\times ... \\times L'_N`).  A spatial size of the output is "
"calculated as  .. math::    L'_i =s_i (L_i - 1) - 2 p_i + d_i (k_i - 1) + 1,  "
"where :math:`s_i` is the stride, :math:`L_i` is the spatial size, :math:`p_i` is "
"the padding, :math:`d_i` is the dilation, and :math:`k_i` is the kernel size "
"for :math:`i`-th spatial dimension. The same calculation can also be applied to "
"the other spatial dimensions."
msgstr ""

#: nnabla.functions.deconvolution:38 nnabla.functions.depthwise_deconvolution:39 of
msgid "L'_i =s_i (L_i - 1) - 2 p_i + d_i (k_i - 1) + 1,"
msgstr ""

#: nnabla.functions.deconvolution:42 nnabla.functions.depthwise_deconvolution:42 of
msgid ""
"where :math:`s_i` is the stride, :math:`L_i` is the spatial size, :math:`p_i` is "
"the padding, :math:`d_i` is the dilation, and :math:`k_i` is the kernel size "
"for :math:`i`-th spatial dimension. The same calculation can also be applied to "
"the other spatial dimensions."
msgstr ""
"のように計算します。ここで、 :math:`s_i` はストライド、 :math:`L_i` は空間サイ"
"ズ、 :math:`p_i` はパディング、 :math:`d_i` は拡張、 :math:`k_i` は :math:`i` 空"
"間次元のカーネルサイズです。同様計算は他の空間次元にも適用することができます。"

#: nnabla.functions.depthwise_deconvolution:1 of
msgid ""
"Depthwise deconvolution computes the transposed depthwise convolution with bias "
"for one-dimensional and two-dimensional input data."
msgstr ""
"Depthwise deconvolution は、1 次元および 2 次元入力データに対して、バイアスを伴っ"
"て transposed depthwise convolution を計算します。"

#: nnabla.functions.depthwise_deconvolution:23 of
msgid "Number of input feature maps per output feature map. [default=``1``]"
msgstr "出力特徴マップごとの入力特徴マップの数。 [ デフォルト = ``1`` ]"

#: nnabla.functions.depthwise_deconvolution:27 of
msgid ""
":math:`(B + 1 + N)`-D array (:math:`M_1 \\times ... \\times M_B \\times C' "
"\\times L'_1 \\times ... \\times L'_N`).  The output map size :math:`C'` is :"
"math:`C` multiplied by :math:`m`  .. math::    C' =  \\frac{C}{d},  where :math:"
"`d` is the divisor.  A spatial size of the output is calculated as  .. math::   "
"L'_i =s_i (L_i - 1) - 2 p_i + d_i (k_i - 1) + 1,  where :math:`s_i` is the "
"stride, :math:`L_i` is the spatial size, :math:`p_i` is the padding, :math:`d_i` "
"is the dilation, and :math:`k_i` is the kernel size for :math:`i`-th spatial "
"dimension. The same calculation can also be applied to the other spatial "
"dimensions."
msgstr ""

#: nnabla.functions.depthwise_deconvolution:31 of
msgid "C' =  \\frac{C}{d},"
msgstr ""

#: nnabla.functions.depthwise_deconvolution:35 of
msgid "where :math:`d` is the divisor."
msgstr "となります。ここで、 :math:`d` は除数です。"

#: nnabla.functions.adaptive_separable_convolution:1 of
msgid ""
"2-D Adaptive Separable Convolution for NCHW (the channel-first tensor). Sample "
"and pixel dependent vertical and horizontal kernels are dynamically generated "
"ones, which are used for approximating a feature-independent 2-D kernel in this "
"function. Thus, the kernel used in this function is dependent on samples and "
"pixels but independent on features."
msgstr ""
"NCHW (チャネル優先テンソル) 用の 2-D Adaptive Separable Convolution。サンプルおよ"
"びピクセル依存の垂直カーネルと水平カーネルが動的に生成され、この関数において特徴"
"方向に依存しない 2 次元カーネルを近似するために使用されます。したがって、この関数"
"で使用されるカーネルは、サンプルおよびピクセルに依存しますが、特徴方向には依存し"
"ません。"

#: nnabla.functions.adaptive_separable_convolution:6 of
msgid ""
"If the padding is needed, use the pad function to the input :math:`x` before "
"this function."
msgstr ""
"パディングが必要な場合は、この関数の前に pad 関数を使って :math:`x` を入力してく"
"ださい。"

#: nnabla.functions.adaptive_separable_convolution:8 of
msgid "Adaptive separable convolution is formulated as"
msgstr "Adaptive separable convolution は次の式で表されます。"

#: nnabla.functions.adaptive_separable_convolution:10 of
msgid ""
"\\tilde{I}(c, h, w) = \\sum_{j, i} K_v(j, h, w) \\times K_h(i, h, w) \\times "
"I(c, h + j, w + i),"
msgstr ""

#: nnabla.functions.adaptive_separable_convolution:14 of
msgid ""
"where :math:`I(c, h, w)` and :math:`\\tilde{I}(c, h, w)` are the input and "
"output images at :math:`c`-th channel, :math:`h`-th height, :math:`w`-th width. :"
"math:`K_V(:, h, w)` and :math:`K_h(:, h, w)` are vertical and horizontal 1-D "
"kernels at :math:`h`-th height and :math:`w`-th width."
msgstr ""
"ここでは、 :math:`I(c, h, w)` および :math:`\\tilde{I}(c, h, w)` は、 :math:`c` "
"番目のチャネル、 :math:`h` 番目の高さ、 :math:`w` 番目の幅における入力および出力"
"画像であり、 :math:`K_V(:, h, w)` および :math:`K_h(:, h, w)` は、 :math:`h` 番目"
"の高さ、 :math:`w` 番目の幅における垂直および水平な 1 次元カーネルとなります。"

#: nnabla.functions.adaptive_separable_convolution:21 of
msgid ""
"`Simon Niklaus, Long Mai, Feng Liu, Video Frame Interpolation via Adaptive "
"Separable Convolution, <https://arxiv.org/abs/1708.01692>`_"
msgstr ""

#: nnabla.functions.adaptive_separable_convolution:25 of
msgid ""
"`Mart Kartasev, Carlo Rapisarda, Dominik Fay, Implementing Adaptive Separable "
"Convolution for Video Frame Interpolation, <https://arxiv.org/abs/1809.07759>`_"
msgstr ""

#: nnabla.functions.adaptive_separable_convolution:29 of
msgid ":math:`4-D` array (:math:`B \\times C \\times H \\times W`)"
msgstr ":math:`4-D` 配列 (:math:`B \\times C \\times H \\times W`)"

#: nnabla.functions.adaptive_separable_convolution:31 of
msgid ":math:`4-D` array (:math:`B \\times K_v \\times H \\times W`)"
msgstr ":math:`4-D` 配列 (:math:`B \\times K_v \\times H \\times W`)"

#: nnabla.functions.adaptive_separable_convolution:33 of
msgid ":math:`4-D` array (:math:`B \\times K_h \\times H \\times W`)"
msgstr ":math:`4-D` 配列 (:math:`B \\times K_h \\times H \\times W`)"

#: nnabla.functions.adaptive_separable_convolution:36 of
msgid ""
":math:`4-D` array (:math:`B \\times C \\times H - K_v + 1 \\times W - K_h + 1`)"
msgstr ""
":math:`4-D` 配列 (:math:`B \\times C \\times H - K_v + 1 \\times W - K_h + 1`)"

#: nnabla.functions.max_pooling:1 of
msgid "Max pooling. It pools the maximum values inside the scanning kernel:"
msgstr "最大プーリング。カーネルによって決定される受容野内の最大値をプールします。"

#: nnabla.functions.max_pooling:3 of
msgid "y_{i_1, i_2} = \\max_{k_1, k_2 \\in K} (x_{i_1 + k_1, i_2 + k_2})"
msgstr ""

#: nnabla.functions.average_pooling:6 nnabla.functions.max_pooling:6
#: nnabla.functions.sum_pooling:6 of
msgid ""
"where :math:`x_{i_1 + k_1, i_2 + k_2}` is the input and :math:`y_{i_1, i_2}` is "
"the output."
msgstr ""
"ここでは、 :math:`x_{i_1 + k_1, i_2 + k_2}` は入力、 :math:`y_{i_1, i_2}` は出力"
"です。"

#: nnabla.functions.average_pooling:8 nnabla.functions.global_average_pooling:6
#: nnabla.functions.max_pooling:8 nnabla.functions.sum_pooling:8
#: nnabla.functions.unpooling:8 of
msgid "Input variable."
msgstr "入力変数。"

#: nnabla.functions.average_pooling:10 nnabla.functions.max_pooling:10
#: nnabla.functions.sum_pooling:10 nnabla.functions.unpooling:10 of
msgid "Kernel sizes for each spatial axis."
msgstr "各空間軸に対するカーネルサイズ。"

#: nnabla.functions.average_pooling:12 nnabla.functions.max_pooling:12
#: nnabla.functions.sum_pooling:12 of
msgid "Subsampling factors for each spatial axis. [default=``kernel``]"
msgstr "各空間軸に対するサブサンプリングの係数。[ デフォルト = ``kernel`` ]"

#: nnabla.functions.average_pooling:15 nnabla.functions.max_pooling:15
#: nnabla.functions.sum_pooling:15 of
msgid ""
"If false, kernels covering borders are also considered for the output. "
"[default=``True``]"
msgstr ""
"false の場合、境界線を覆っているカーネルも出力に考慮されます。 [ デフォルト = "
"``True`` ]"

#: nnabla.functions.average_pooling:18 nnabla.functions.max_pooling:18
#: nnabla.functions.sum_pooling:18 of
msgid ""
"Border padding values for each spatial axis. Padding will be added both sides of "
"the dimension. [default=``(0,) * len(kernel)``]"
msgstr ""
"各空間軸に対する境界線のパディング値。パディングは次元の両側に追加されます。[ デ"
"フォルト = ``(0,) * len(kernel)`` ]"

#: nnabla.functions.max_pooling:25 of
msgid "Maximum values variable"
msgstr "最大値変数"

#: nnabla.functions.average_pooling:1 of
msgid "Average pooling. It pools the averaged values inside the scanning kernel:"
msgstr "平均プーリング。カーネルによって決定される受容野内の平均値をプールします。"

#: nnabla.functions.average_pooling:3 of
msgid ""
"y_{i_1, i_2} = \\frac{1}{K_1 K_2} \\sum_{k1} \\sum_{k2} x_{i_1 + k_1, i_2 + k_2}"
msgstr ""

#: nnabla.functions.average_pooling:24 of
msgid ""
"If true, border padding values are considered for the output. [default=``True``]"
msgstr ""
"True の場合、境界線のパディング値は出力に考慮されます。[ デフォルト = ``True`` ]"

#: nnabla.functions.average_pooling:28 nnabla.functions.global_average_pooling:9 of
msgid "Average values variable"
msgstr "平均値変数"

#: nnabla.functions.broadcast_to:2 nnabla.functions.global_average_pooling:2 of
msgid "This function is experimental support, so please do not actively use it."
msgstr "この関数は実験的なサポートなので、積極的には使用しないでください。"

#: nnabla.functions.global_average_pooling:4 of
msgid "Global average pooling. It pools an averaged value from the whole image"
msgstr "全体平均プーリング。全体のイメージから平均値をプールします。"

#: nnabla.functions.sum_pooling:1 of
msgid "Sum pooling. It pools the summed values inside the scanning kernel:"
msgstr "合計プーリング。カーネルによって決定される受容野内の合計値をプールします。"

#: nnabla.functions.sum_pooling:3 of
msgid "y_{i_1, i_2} = \\sum_{k1} \\sum_{k2} x_{i_1 + k_1, i_2 + k_2}"
msgstr ""

#: nnabla.functions.sum_pooling:25 of
msgid "Summed values variable"
msgstr "合計された値の変数"

#: nnabla.functions.unpooling:1 of
msgid "Inverse operation of pooling. It spreads the input values:"
msgstr "プーリングの逆演算。入力値をスプレッドします。"

#: nnabla.functions.unpooling:3 of
msgid "y_{k_1 i_1 + j_1, k_2 i_2 + j_2} = x_{i_1, i_2}"
msgstr ""

#: nnabla.functions.unpooling:6 of
msgid ""
"where :math:`_{i_1, i_2}` is the input and :math:`y_{k_1 i_1 + j_1, k_2 i_2 + "
"j_2}` is the output."
msgstr ""
"ここでは、 :math:`_{i_1, i_2}` は入力、 :math:`y_{k_1 i_1 + j_1, k_2 i_2 + j_2}` "
"は出力です。"

#: nnabla.functions.unpooling:13 of
msgid "Spread values variable"
msgstr "スプレッドされた値の変数"

#: nnabla.functions.embed:1 of
msgid "Embed slices of a matrix/tensor with indexing array/tensor."
msgstr "インデックス配列／テンソルを使った行列 ／テンソルのスライス。"

#: nnabla.functions.embed:3 of
msgid "Indices with shape :math:`(I_0, ..., I_N)`"
msgstr ":math:`(I_0, ..., I_N)` の形状のインデックス"

#: nnabla.functions.embed:5 of
msgid "Weights with shape :math:`(W_0, ..., W_M)` [parameter]"
msgstr ":math:`(W_0, ..., W_M)` の形状の重み [ パラメータ ]"

#: nnabla.functions.embed:9 of
msgid "Output with shape :math:`(I_0, ..., I_N, W_1, ..., W_M)`"
msgstr ":math:`(I_0, ..., I_N, W_1, ..., W_M)` の形状の出力"

#: nnabla.functions.rnn:1 of
msgid ""
"RNN function implements Elman RNN with nonlineraity to input sequence. RNN "
"function is defined as following:"
msgstr ""
"RNN 関数は、入力シーケンスに対して非線形のエルマン RNN を実行します。 RNN 関数は"
"次のように定義します。"

#: nnabla.functions.rnn:4 of
msgid ""
"{\\mathbf h_t} = {\\mathbf \\tanh}( {\\mathbf w_{ih}} *{\\mathbf x_t} + "
"{\\mathbf b_{ih}} + {\\mathbf w_{hh}}* {\\mathbf h_{(t-1)}} + {\\mathbf b_{hh}})."
msgstr ""

#: nnabla.functions.gru:9 nnabla.functions.lstm:10 nnabla.functions.rnn:7 of
msgid ""
"We use the following notations to describe the inputs and outputs below. :math:"
"`T`: sequcne length, :math:`B`: batch size, :math:`I`: input size, :math:`L`: "
"number of layers, :math:`D`: number of directions, can be either 1 or 2, :math:"
"`H`: hidden size."
msgstr ""
"以下の入出力を説明するために、次のような表記を使います。 :math:`T`: シーケンスの"
"長さ、 :math:`B`: バッチサイズ、 :math:`I`: 入力サイズ、 :math:`L`: 層の数、 :"
"math:`D`: 方向の数で1か2、 :math:`H`: 非表示のサイズ。"

#: nnabla.functions.rnn:12 of
msgid ""
"`Jeffrey Elman, Finding Structure in Time. <https://crl.ucsd.edu/~elman/Papers/"
"fsit.pdf>`_"
msgstr ""

#: nnabla.functions.gru:16 nnabla.functions.lstm:17 nnabla.functions.rnn:14 of
msgid "Input N-D array with shape :math:`(T, B, I)`."
msgstr ":math:`(T, B, I)` の形状の入力 N-D 配列。"

#: nnabla.functions.gru:18 nnabla.functions.lstm:19 nnabla.functions.lstm:21
#: nnabla.functions.rnn:16 of
msgid "Input N-D array with shape :math:`(L, D, B, H)`."
msgstr ":math:`(L, D, B, H)` の形状の入力 N-D 配列。"

#: nnabla.functions.rnn:18 of
msgid "Input N-D array with shape :math:`(D, H, I + H)`. [parameter]"
msgstr ":math:`(D, H, I + H)` の形状の入力 N-D 配列。[パラメータ]"

#: nnabla.functions.rnn:21 of
msgid ""
"Input N-D array with shape :math:`(L-1, D, H, D * H + H)`. [optional][parameter]"
msgstr ""
":math:`(L-1, D, H, D * H + H)` の形状の入力 N-D 配列。[ オプション ][ パラメー"
"タ ]"

#: nnabla.functions.rnn:24 of
msgid "Input N-D array with shape :math:`(L, D, H)`. [optional][parameter]"
msgstr ":math:`(L, D, H)` の N-D 配列。 [ オプション ][ パラメータ ]"

#: nnabla.functions.gru:29 nnabla.functions.lstm:32 nnabla.functions.rnn:27 of
msgid ""
"Number of layers in the network. If set to 1, only the weights for the first "
"layer will be invoked. Default is 1. [default=``1``]"
msgstr ""
"ネットワークの層数。1 を設定した場合は、第 1 層の重みだけが呼び出されます。デフォ"
"ルトは 1 です。[ デフォルト = ``1`` ]"

#: nnabla.functions.rnn:30 of
msgid ""
"Type of nonlinearity applied to input sequcne. Must be either tanh or relu. "
"Default is tanh. [default=``'tanh'``]"
msgstr ""
"入力シーケンスに対して適用される非線形の種類。 tanh または relu が指定される必要"
"があります。デフォルトは tanh です。 [ デフォルト = ``’tanh’`` ]"

#: nnabla.functions.gru:32 nnabla.functions.lstm:35 nnabla.functions.rnn:33 of
msgid "Dropout ratio applied to parameters. Default is 0.0. [default=``0.0``]"
msgstr ""
"パラメータに対して適用されるドロップアウトの割合。デフォルトは 0.0 です。 [ デ"
"フォルト = ``0.0`` ]"

#: nnabla.functions.rnn:36 of
msgid ""
"If True, bidirectional computation will be performed in each layer. Default is "
"False. [default=``False``]"
msgstr ""
"True の場合、双方向計算が各層で行われます。デフォルトは False です。 [ デフォル"
"ト = ``False`` ]"

#: nnabla.functions.rnn:39 of
msgid ""
"Backpropagation will be performed only when it is true. Default is True. "
"[default=``True``]"
msgstr ""
"true のバイアのみ、バックプロパゲーションが行われます。デフォルトは True です。 "
"[ デフォルト = ``True`` ]"

#: nnabla.functions.rnn:43 of
msgid ""
"Output :math:`y` with shape :math:`(T, B, D * H)` ~nnabla.Variable: Output :math:"
"`h_n` with shape :math:`(L, D, B, H)`"
msgstr ""
":math:`(T, B, D * H)` の形状の出力 :math:`y` ~nnabla.Variable: :math:`(L, D, B, "
"H)` の形状の出力 :math:`h_n`"

#: nnabla.functions.lstm:1 of
msgid "N-Step LSTM layer."
msgstr "N-ステップ LSTM 層。"

#: nnabla.functions.lstm:3 of
msgid ""
"{\\mathbf f_t} = {\\mathbf \\sigma}( {\\mathbf W_f} *{\\mathbf x_t} + {\\mathbf "
"U_f}* {\\mathbf h_{(t-1)}} + {\\mathbf b_f})\\\\ {\\mathbf i_t} = {\\mathbf "
"\\sigma}( {\\mathbf W_i} *{\\mathbf x_t} + {\\mathbf U_i}* {\\mathbf h_{(t-1)}} "
"+ {\\mathbf b_i})\\\\ {\\mathbf o_t} = {\\mathbf \\sigma}( {\\mathbf W_o} "
"*{\\mathbf x_t} + {\\mathbf U_o}* {\\mathbf h_{(t-1)}} + {\\mathbf b_o})\\\\ "
"{\\mathbf c_t} = {\\mathbf f_t}\\odot {\\mathbf c_{(t-1)}} + {\\mathbf "
"i_t}\\odot {\\mathbf \\tanh}({\\mathbf W_c}*{\\mathbf x_t} + {\\mathbf U_c} "
"*{\\mathbf h_{(t-1)}} + {\\mathbf b_c})\\\\ {\\mathbf h_t} = {\\mathbf o_t} "
"\\odot {\\mathbf \\tanh}({\\mathbf c_t})."
msgstr ""

#: nnabla.functions.lstm:15 of
msgid ""
"`S. Hochreiter and J. Schmidhuber, Long Short-Term Memory. <https://www.bioinf."
"jku.at/publications/older/2604.pdf>`_"
msgstr ""

#: nnabla.functions.lstm:23 of
msgid ""
"weight parameters for the first layer. Shape is :math:`(D, 4, H, I + H)`. "
"[parameter]"
msgstr ""
"第 1 層に対する重みパラメータ。シェイプは :math:`(D, 4, H, I + H)`。 [ パラメー"
"タ ]"

#: nnabla.functions.lstm:26 of
msgid ""
"weight parameters for the second layer and above. Shape is :math:`(L-1, D, 4, H, "
"D * H + H)`. [optional][parameter]"
msgstr ""
"第 2 層以上に対する重みパラメータ。形状は :math:`(L-1, D, 4, H, D * H + H)`。 "
"[ オプション ][ パラメータ ]"

#: nnabla.functions.gru:26 nnabla.functions.lstm:29 of
msgid ""
"Bias vector (:math:`L`). Shape is :math:`(L, D, 4, H)`. [optional][parameter]"
msgstr ""
"バイアスのベクトル (:math:`L`)。形状は :math:`(L, D, 4, H)`。 [ オプション ][ パ"
"ラメータ ]"

#: nnabla.functions.gru:35 nnabla.functions.lstm:38 of
msgid ""
"If True, bidirecitonal computation will be performed in each layer. Default is "
"False. [default=``False``]"
msgstr ""
"True の場合、双方向計算が各層で行われます。デフォルトは False です。 [ デフォル"
"ト = ``False`` ]"

#: nnabla.functions.gru:38 nnabla.functions.lstm:41 of
msgid ""
"Backpropagation will be performed only when it is True. Default is True. "
"[default=``True``]"
msgstr ""
"True の場合のみ、バックプロパゲーションが行われます。デフォルトは True です。 "
"[ デフォルト = ``True`` ]"

#: nnabla.functions.lstm:45 of
msgid ""
"Output :math:`y` with shape :math:`(T, B, D * H)`. Its memory layout can be "
"reshaped as :math:`(T, B, D, H)`. ~nnabla.Variable: Output :math:`h_n` with "
"shape :math:`(L, D, B, H)` ~nnabla.Variable: Output :math:`c_n` with shape :math:"
"`(L, D, B, H)`"
msgstr ""
":math:`(T, B, D * H)` の形状の出力 :math:`y`。メモリレイアウトは :math:`(T, B, "
"D, H)` として再形成することができます。 ~nnabla.Variable: :math:`(L, D, B, H)` の"
"形状の出力 :math:`h_n` ~nnabla.Variable:\n"
":math:`(L, D, B, H)` の形状の出力 :math:`c_n`"

#: nnabla.functions.gru:1 of
msgid "N-Step GRU layer."
msgstr "N-ステップ GRU 層。"

#: nnabla.functions.gru:3 of
msgid ""
"{\\mathbf r_t} = {\\mathbf \\sigma}( {\\mathbf W_r} *{\\mathbf x_t} + {\\mathbf "
"U_r}* {\\mathbf h_{(t-1)}} + {\\mathbf b_r})\\\\   {\\mathbf z_t} = {\\mathbf "
"\\sigma}( {\\mathbf W_z} *{\\mathbf x_t} + {\\mathbf U_z}* {\\mathbf h_{(t-1)}} "
"+ {\\mathbf b_z})\\\\ {\\mathbf n_t} = {\\mathbf \\tanh}( {\\mathbf W_n}"
"{\\mathbf x_t}+ {\\mathbf b_{in}}+ {\\mathbf r_n}\\odot( {\\mathbf U_n}{\\mathbf "
"h_{t-1}}+ {\\mathbf b_{hn}})) \\\\ {\\mathbf h_t} = (1- {\\mathbf z_t})\\odot "
"{\\mathbf n_t} + {\\mathbf z_t}\\odot {\\mathbf h_{t-1}}."
msgstr ""

#: nnabla.functions.gru:14 of
msgid ""
"`K. cho et al., Learning Phrases Representations using RNN Encoder-Decoder for "
"Statistical Machine Translation. <https://www.aclweb.org/anthology/D14-1179>`_"
msgstr ""

#: nnabla.functions.gru:20 of
msgid ""
"weight parameters for the first layer. Shape is :math:`(D, 3, H, I + H)`. "
"[parameter]"
msgstr ""
"第 1 層に対する重みパラメータ。形状は :math:`(D, 3, H, I + H)` 。 [ パラメータ ]"

#: nnabla.functions.gru:23 of
msgid ""
"weight parameters for the second layer and above. Shape is :math:`(L-1, D, 3, H, "
"D * H + H)`. [optional][parameter]"
msgstr ""
"第 2 層以上に対する重みパラメータ。形状は :math:`(L-1, D, 3, H, D * H + H)` 。 "
"[ オプション ][ パラメータ ]"

#: nnabla.functions.gru:42 of
msgid ""
"Output :math:`y` with shape :math:`(T, B, D * H)`. Its memory layout can be "
"reshaped as :math:`(T, B, D, H)`. ~nnabla.Variable: Output :math:`h_n` with "
"shape :math:`(L, D, B, H)`"
msgstr ""
":math:`(T, B, D * H)` の形状の出力 :math:`y` 。メモリレイアウトは :math:`(T, B, "
"D, H)` として再形成できます。 ~nnabla.Variable: :math:`(L, D, B, H)` の形状の出"
"力 :math:`h_n`"

#: nnabla.functions.multi_head_attention:1 of
msgid "MultiHeadAttention."
msgstr "MultiHeadAttention。"

#: nnabla.functions.multi_head_attention:3 of
msgid ""
"Computes multi-headed attention with query, key, and value. We use the following "
"notations to describe the inputs and outputs below. :math:`L_T`: target sequence "
"length, :math:`L_S`: source sequence length, :math:`B`: batch size, :math:`E`: "
"embedding dimension, :math`H`: number of attention heads."
msgstr ""
"クエリ、キー、値をもつ multi-headed attention を計算します。以下の入出力を記述す"
"るために次のような表記を使います。 :math:`L_T`: ターゲットシーケンスの長さ、 :"
"math:`L_S`: ソースシーケンスの長さ、 :math:`B`: バッチサイズ、 :math:`E`: 埋め込"
"みの次元、 :math:`H`: attention heard の数。"

#: nnabla.functions.multi_head_attention:9 of
msgid ""
"A. Vaswani et al. \"Attention is All You Need.\" NIPS. 2017. <https://papers."
"nips.cc/paper/7181-attention-is-all-you-need.pdf>"
msgstr ""

#: nnabla.functions.multi_head_attention:13 of
msgid "Input N-D array with shape :math:`(L_T, B, E)`."
msgstr ":math:`(L_T, B, E)` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:15 of
msgid "Input N-D array with shape :math:`(L_S, B, E_k)`."
msgstr ":math:`(L_S, B, E_k)` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:17 of
msgid "Input N-D array with shape :math:`(L_S, B, E_v)`."
msgstr ":math:`(L_S, B, E_v)` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:19 of
msgid ""
"Number of attention heads. Note that embedding dimensoin E must be divisible by "
"the number of heads. Default is 12 which is conventional."
msgstr ""
"attention head の数。埋め込みの次元 E はヘッドの数で割り切れなければなりません。"
"通例どおり、デフォルトは 12 です。"

#: nnabla.functions.multi_head_attention:21 of
msgid "Input N-D array with shape :math:`(E E)`."
msgstr ":math:`(E E)` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:23 of
msgid "Input N-D array with shape :math:`(E_k, E)`."
msgstr ":math:`(E_k, E)` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:25 of
msgid "Input N-D array with shape :math:`(E_v, E)`."
msgstr ":math:`(E_v, E)` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:27 of
msgid "Input N-D array with shape :math:`(E, E)`."
msgstr ":math:`(E, E)` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:29
#: nnabla.functions.multi_head_attention:31
#: nnabla.functions.multi_head_attention:33
#: nnabla.functions.multi_head_attention:35
#: nnabla.functions.multi_head_attention:37
#: nnabla.functions.multi_head_attention:39 of
msgid "Input N-D array with shape :math:`(E, )`."
msgstr ":math:`(E, )` の形状の入力 N-D 配列。"

#: nnabla.functions.multi_head_attention:41 of
msgid "Dropout ratio applied to parameters. Default is 0."
msgstr "パラメータに対して適用されたドロップアウトの割合。デフォルトは 0 です。"

#: nnabla.functions.multi_head_attention:43 of
msgid ""
"Input N-D array with shape :math:`(L_T, L_S)`. Values will be added to the "
"attention layer to prevent attention to certain positions."
msgstr ""
":math:`(L_T, L_S)` の形状の入力 N-D 配列。特定の位置へのアテンションを防ぐため、"
"値はアテンション層へ追加されます。"

#: nnabla.functions.multi_head_attention:45 of
msgid ""
"Input N-D array with shape :math:`(B, L_S)`. Specified padding elements will be "
"ignored by the attention layer. Values must be either 1 or 0."
msgstr ""
":math:`(B, L_S)` の形状の入力 N-D 配列。アテンション層は、指定されたパディング要"
"素を無視します。値は 1 または 0 である必要があります。"

#: nnabla.functions.multi_head_attention:48 of
msgid ""
"Output :math:`y` with shape :math:`(L_T, B, E)` ~nnabla.Variable: Output :math:"
"`h_n` with shape :math:`(B, L_T, L_S)`"
msgstr ""
":math:`(L_T, B, E)` の形状の出力 :math:`y` ~nnabla.Variable: :math:`(B, L_T, "
"L_S)` の形状の出力 :math:`h_n`"

#: nnabla.functions.patch_correlation:1 of
msgid ""
"Multiplicative patch-wise comparision between inputs `x1` and `x2`, which must "
"both be 4-dimensional NCHW (with `channel_last=False`) or NHWC (with "
"`channel_last=True`) arrays (where *N* is the number of samples, *H* and *W* are "
"the sample height and width and *C* is the number of channels). The function "
"returns a 5-D array with shape :math:`(N, C_y, C_x, H_o, W_o)` where :math:`H_o, "
"W_o` are determined by the possible patch locations within the, optionally "
"padded, input image sizeand :math:`C_y, C_x` are determined by the optionally "
"shifted patch positions."
msgstr ""
"入力 `x1` と 入力 `x2` のパッチごとの内積計算。これらの入力はともに NCHW 形式 "
"( `channel_last=False` ) または NHWC 形式 ( `channel_last=True` ) の 4 次元配列で"
"ある必要があります (ここでは *N* はサンプル数、 *H* および *W* はサンプルの高さお"
"よび幅、*C* はチャネル数です)。この関数は、 :math:`(N, C_y, C_x, H_o, W_o)` の形"
"状の5 次元配列を返します。ここでは、 :math:`H_o, W_o` はオプションに応じてパディ"
"ングされた入力画像サイズ内で可能なパッチ位置によって決まり、 :math:`C_y, C_x` は"
"オプションに応じてシフトされたパッチ位置によって決まります。"

#: nnabla.functions.patch_correlation:10 of
msgid "Mathmatically, the patch correlation is formulated as"
msgstr "数学的には、パッチ相関は以下の式で表されます。"

#: nnabla.functions.patch_correlation:12 of
msgid ""
"O(s_y, s_x, h_0, w_0) = \\sum_{c} \\sum_{k_h} \\sum_{k_w} I_1(c, h + k_h, w + "
"k_w) \\times I_2(c, h + k_h + s_h, w + k_w + s_w),"
msgstr ""

#: nnabla.functions.patch_correlation:17 of
msgid ""
"where :math:`I_1(c, h, w)` and :math:`I_2(c, h, w)` are the inputs at :math:`c`-"
"th channel, :math:`h`-th height, and :math:`w`-th width, :math:`k_h, k_w` "
"indices for the patch size and :math:`s_h, s_w` indices for the shifts."
msgstr ""
"ここでは、 :math:`I_1(c, h, w)` および :math:`I_2(c, h, w)` は :math:`c` 番目の"
"チャネル、 :math:`h` 番目の高さ、 :math:`w` 番目の幅における入力、 :math:`k_h, "
"k_w` はパッチサイズのインデックス、 :math:`s_h, s_w` はシフトのインデックスです。"

#: nnabla.functions.patch_correlation:21 of
msgid ""
"A single correlation value (per sample) is produced if the patch extends to the "
"image dimensions and all other parameters use the default values."
msgstr ""
"パッチが画像の次元まで拡張され、他のすべてのパラメータがデフォルト値を使用する場"
"合は、(サンプルごとに) 単一の相関値が生成されます。"

#: nnabla.functions.patch_correlation:30 of
msgid ""
"A patch that is smaller than the image size moves horizontal and vertical "
"producing a value per position. The `patch_step` argument may be used to control "
"the position increments."
msgstr ""
"画像サイズより小さいパッチは、水平方向および垂直方向に移動し、位置ごとの値を生成"
"します。 `patch_step` 引数は、位置の増分を調整するために使うことができます。"

#: nnabla.functions.patch_correlation:40 of
msgid ""
"Multiple correlations may be performed at each position between the patch from "
"`x1` and patches from `x2` at relative offsets striding the maximum vertical and "
"horizontal distance given by the `shift` values at increments of `shift_step`. "
"The shifted correlation values can be obtained for the from the second and third "
"output dimension for the vertical and horizontal shifts."
msgstr ""
"複数の相関は、 `shift_step` の増分の `shift` 値によって指定される最大垂直および水"
"平距離にまたがる相対オフセットで、 `x1` からのパッチと `x2` からのパッチの間の各"
"位置で実行することができます。シフトされた相関値は、垂直および水平シフトの第 2 お"
"よび第 3 出力の次元から取得することができます。"

#: nnabla.functions.patch_correlation:57 of
msgid ""
"Padding with zero values may be applied individually to the top, bottom, left "
"and right side of the input image."
msgstr "ゼロ値のパディングは、入力画像の上下左右にそれぞれ適用することができます。"

#: nnabla.functions.patch_correlation:64 of
msgid "This function may be used to implement the FlowNetC correlation layer."
msgstr "この関数を使って FlowNetC correlation 層を実装することができます。"

#: nnabla.functions.patch_correlation:73 of
msgid ""
"`Fischer et al., FlowNet: Learning Optical Flow with Convolutional Networks. "
"<https://arxiv.org/abs/1504.06852>`_"
msgstr ""

#: nnabla.functions.patch_correlation:76 nnabla.functions.patch_correlation:79 of
msgid "Input N-D array with shape :math:`(N, C, H, W)` or :math:`(N, H, W, C)`."
msgstr ":math:`(N, C, H, W)` または :math:`(N, H, W, C)` の形状の入力 N-D 配列。"

#: nnabla.functions.patch_correlation:82 of
msgid ""
"A tuple with height and width of the correlation patch. A single integer expands "
"to identical height and width."
msgstr ""
"相関パッチの高さおよび幅のタプル。単一整数の場合は、高さと幅が同じ値になります。"

#: nnabla.functions.patch_correlation:84 of
msgid ""
"A tuple of maximum vertical and horizontal displacement of patches from `x2` "
"that are correlated with a single patch from `x1`. A single integer expands to "
"identical vertical and horizontal displacement."
msgstr ""
"`x1` からの単一パッチと相関関係にある `x2` からのパッチの最大垂直および水平変位の"
"タプル。単一整数の場合は、垂直および水平変位が同じ値になります。"

#: nnabla.functions.patch_correlation:88 of
msgid ""
"A tuple of vertical and horizontal increments for advancing the position of the "
"correlation patch within the input image shape. A single integer expands to "
"identical vertical and horizontal increments."
msgstr ""
"入力画像形状内での相関パッチの位置の移動のための垂直および水平増分のタプル。単一"
"整数の場合は、垂直および水平増分が同じ値になります。"

#: nnabla.functions.patch_correlation:92 of
msgid ""
"A tuple of vertical and horizontal increments for advancing the relative offset "
"position within the shift range. A single integer expands to identical vertical "
"and horizontal increments."
msgstr ""
"シフト範囲内での相対オフセット位置の移動のための垂直および水平増分のタプル。単一"
"整数の場合は、垂直および水平増分が同じ値になります。"

#: nnabla.functions.patch_correlation:95 of
msgid ""
"A tuple of top, bottom, left and right padding extent. A tuple of two values "
"yields identical top/bottom and left/right padding from the first and second "
"tuple value. A single integer expands to indential padding extent for all sides."
msgstr ""
"上下左右のパディング範囲のタプル。2 つの値からなるタプルは、タプルの 1 番目、2 番"
"目の値がそれぞれ上下の値 (同じ値)、左右の値 (同じ値) となります。単一整数の場合"
"は、すべてのサイドのパディング範囲の値が同じになります。"

#: nnabla.functions.interpolate:56 nnabla.functions.patch_correlation:99 of
msgid "Last dimension is the channel (NHWC order) if True."
msgstr "True の場合、最後の次元はチャネル (NHWC 形式) となります。"

#: nnabla.functions.patch_correlation:101 of
msgid ""
"N-D array with shape :math:`(N, C_y, C_x, H_o, W_o)` or :math:`(N, H, W, C_y, "
"C_x)` if `channel_last=True`.    A spatial size of the output is calculated "
"as    .. math::      H_o = \\frac{H + (top\\_pad + bottom\\_pad) - patch_v}{patch"
"\\_step_v} + 1.    A channel size of the ouptut is calculated as    .. "
"math::      C_y = \\frac{2 \\times shift_v}{shift\\_step_v} + 1.    :math:`W_o` "
"and :math:`C_x` are the same calculation with differenct components."
msgstr ""

#: nnabla.functions.patch_correlation:103 of
msgid ""
"N-D array with shape :math:`(N, C_y, C_x, H_o, W_o)` or :math:`(N, H, W, C_y, "
"C_x)` if `channel_last=True`."
msgstr ""
"`channel_last=True` の場合、 :math:`(N, C_y, C_x, H_o, W_o)` または :math:`(N, "
"H, W, C_y, C_x)` の形式の N-D 配列。"

#: nnabla.functions.patch_correlation:107 of
msgid "H_o = \\frac{H + (top\\_pad + bottom\\_pad) - patch_v}{patch\\_step_v} + 1."
msgstr ""

#: nnabla.functions.patch_correlation:111 of
msgid "A channel size of the ouptut is calculated as"
msgstr "出力のチャネルサイズは次のように計算されます。"

#: nnabla.functions.patch_correlation:113 of
msgid "C_y = \\frac{2 \\times shift_v}{shift\\_step_v} + 1."
msgstr ""

#: nnabla.functions.patch_correlation:117 of
msgid ""
":math:`W_o` and :math:`C_x` are the same calculation with differenct components."
msgstr ""
":math:`W_o` および :math:`C_x` は異なるコンポーネントでも同じ計算となります。"

#: ../../python/api/function.rst:57
msgid "Neural Network Activation"
msgstr "ニューラルネットワークの活性化"

#: nnabla.functions.sigmoid:1 of
msgid "Element-wise sigmoid function."
msgstr "要素ごとの sigmoid 関数。"

#: nnabla.functions.sigmoid:3 of
msgid "f(x) = \\frac{1}{1 + \\exp(-x)},"
msgstr ""

#: nnabla.functions.sigmoid:7 nnabla.functions.sign:20 nnabla.functions.swish:12 of
msgid "Input"
msgstr "入力"

#: nnabla.functions.binary_connect_convolution:68
#: nnabla.functions.binary_weight_convolution:69
#: nnabla.functions.inq_convolution:57 nnabla.functions.sigmoid:10
#: nnabla.functions.stack:15 nnabla.functions.swish:15 of
msgid "Output"
msgstr "出力"

#: nnabla.functions.swish:1 of
msgid "Element-wise swish function, by Ramachandran et al. (2017)."
msgstr "Ramachandran 他 (2017) による要素ごとの swish 関数。"

#: nnabla.functions.swish:3 of
msgid "y_i = \\frac{x_i}{1 + \\exp(-x_i)},"
msgstr ""

#: nnabla.functions.swish:9 of
msgid ""
"`Prajit Ramachandran, Barret Zoph, and Quoc V. Le, Swish: a Self-Gated "
"Activation Function, arXiv:1710.05941 [cs.NE] <https://arxiv.org/"
"abs/1710.05941>`_"
msgstr ""

#: nnabla.functions.tanh:1 of
msgid "Element-wise hyperbolic tangent (tanh) function."
msgstr "要素ごとの双曲線正接 (tanh) 関数。"

#: nnabla.functions.tanh:3 of
msgid "y_i = \\tanh (x_i)"
msgstr ""

#: nnabla.functions.acos:6 nnabla.functions.acosh:6 nnabla.functions.add2:6
#: nnabla.functions.add2:8 nnabla.functions.add2:14 nnabla.functions.add_n:10
#: nnabla.functions.asin:6 nnabla.functions.asinh:6 nnabla.functions.atan:6
#: nnabla.functions.atan2:6 nnabla.functions.atan2:8 nnabla.functions.atanh:6
#: nnabla.functions.broadcast:3 nnabla.functions.broadcast_to:6
#: nnabla.functions.broadcast_to:8 nnabla.functions.cos:6 nnabla.functions.cosh:6
#: nnabla.functions.div2:6 nnabla.functions.div2:8 nnabla.functions.div2:11
#: nnabla.functions.dropout:25 nnabla.functions.elu:15 nnabla.functions.equal:9
#: nnabla.functions.equal:11 nnabla.functions.flip:3 nnabla.functions.flip:9
#: nnabla.functions.fused_batch_normalization:22 nnabla.functions.gelu:17
#: nnabla.functions.greater:10 nnabla.functions.greater:12
#: nnabla.functions.greater_equal:10 nnabla.functions.greater_equal:12
#: nnabla.functions.hard_sigmoid:7 nnabla.functions.hard_tanh:7
#: nnabla.functions.identity:9 nnabla.functions.leaky_relu:9
#: nnabla.functions.less:11 nnabla.functions.less:13 nnabla.functions.less_equal:11
#: nnabla.functions.less_equal:13 nnabla.functions.log_sigmoid:6
#: nnabla.functions.logical_and:9 nnabla.functions.logical_and:11
#: nnabla.functions.logical_or:8 nnabla.functions.logical_or:10
#: nnabla.functions.logical_xor:10 nnabla.functions.logical_xor:12
#: nnabla.functions.maximum2:6 nnabla.functions.maximum2:8
#: nnabla.functions.minimum2:6 nnabla.functions.minimum2:8 nnabla.functions.mul2:6
#: nnabla.functions.mul2:8 nnabla.functions.mul2:11 nnabla.functions.mul_n:10
#: nnabla.functions.not_equal:9 nnabla.functions.not_equal:11
#: nnabla.functions.pad:37 nnabla.functions.pow2:6 nnabla.functions.pow2:8
#: nnabla.functions.pow2:11 nnabla.functions.prune:14
#: nnabla.functions.random_choice:61 nnabla.functions.random_crop:3
#: nnabla.functions.random_crop:15 nnabla.functions.random_flip:3
#: nnabla.functions.random_flip:15 nnabla.functions.reduce_mean:5
#: nnabla.functions.reduce_mean:8 nnabla.functions.reduce_sum:8
#: nnabla.functions.relu:6 nnabla.functions.relu6:7 nnabla.functions.selu:38
#: nnabla.functions.sin:6 nnabla.functions.sinc:6 nnabla.functions.sinh:6
#: nnabla.functions.slice:8 nnabla.functions.softplus:7 nnabla.functions.softsign:8
#: nnabla.functions.sort:29 nnabla.functions.split:6 nnabla.functions.sub2:6
#: nnabla.functions.sub2:8 nnabla.functions.sub2:11 nnabla.functions.tan:6
#: nnabla.functions.tanh:6 nnabla.functions.tanh_shrink:6
#: nnabla.functions.top_k_data:21 nnabla.functions.top_k_grad:9
#: nnabla.functions.transpose:3 nnabla.functions.vat_noise:39 of
msgid "N-D array"
msgstr "N-D 配列"

#: nnabla.functions.acos:9 nnabla.functions.acosh:9 nnabla.functions.add_scalar:13
#: nnabla.functions.asin:9 nnabla.functions.asinh:9 nnabla.functions.atan:9
#: nnabla.functions.atanh:9 nnabla.functions.ceil:17 nnabla.functions.cos:9
#: nnabla.functions.cosh:9 nnabla.functions.dropout:34 nnabla.functions.elu:21
#: nnabla.functions.equal_scalar:15 nnabla.functions.floor:17
#: nnabla.functions.gelu:20 nnabla.functions.greater_equal_scalar:16
#: nnabla.functions.greater_scalar:16 nnabla.functions.hard_sigmoid:10
#: nnabla.functions.hard_tanh:10 nnabla.functions.isinf:6 nnabla.functions.isnan:6
#: nnabla.functions.leaky_relu:18 nnabla.functions.less_equal_scalar:17
#: nnabla.functions.less_scalar:16 nnabla.functions.log_sigmoid:9
#: nnabla.functions.log_softmax:30 nnabla.functions.logical_and_scalar:14
#: nnabla.functions.logical_not:12 nnabla.functions.logical_or_scalar:13
#: nnabla.functions.logical_xor_scalar:15 nnabla.functions.maximum_scalar:12
#: nnabla.functions.minimum_scalar:12 nnabla.functions.mul_scalar:12
#: nnabla.functions.not_equal_scalar:15 nnabla.functions.pow_scalar:12
#: nnabla.functions.prune:20 nnabla.functions.r_div_scalar:12
#: nnabla.functions.r_pow_scalar:12 nnabla.functions.r_sub_scalar:12
#: nnabla.functions.relu:12 nnabla.functions.relu6:10 nnabla.functions.reset_inf:9
#: nnabla.functions.reset_nan:9 nnabla.functions.round:17 nnabla.functions.selu:47
#: nnabla.functions.sign:26 nnabla.functions.sin:9 nnabla.functions.sinc:9
#: nnabla.functions.sinh:9 nnabla.functions.softmax:14 nnabla.functions.softplus:10
#: nnabla.functions.softsign:11 nnabla.functions.tan:9 nnabla.functions.tanh:9
#: nnabla.functions.tanh_shrink:9 of
msgid "N-D array with the same shape as x"
msgstr "x と同じ形状の N-D 配列"

#: nnabla.functions.relu:1 of
msgid "Element-wise Rectified Linear Unit (ReLU) function."
msgstr "要素ごとの Rectified Linear Unit ( ReLU ) 関数。"

#: nnabla.functions.relu:3 of
msgid "y_i = \\max (0, x_i)"
msgstr ""

#: nnabla.functions.leaky_relu:14 nnabla.functions.random_erase:54
#: nnabla.functions.relu:8 of
msgid ""
"The output array is shared with the input array if True. [default=``False``]"
msgstr ""
"True の場合、出力の配列は入力の配列と共有されます。 [ デフォルト = ``False`` ]"

#: nnabla.functions.softmax:1 of
msgid "Softmax normalization. Calculates"
msgstr ""
"Softmax normalization。 `axis` によって指定される次元に沿って、以下のとおり計算し"
"ます。"

#: nnabla.functions.softmax:3 of
msgid "y_i = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}"
msgstr ""

#: nnabla.functions.softmax:6 of
msgid ""
"along the dimension specified by `axis`, where :math:`x_i` is the input and :"
"math:`y_i` is the output."
msgstr "ここでは、 :math:`x_i` は入力、 :math:`y_i` は出力です。"

#: nnabla.functions.log_softmax:24 nnabla.functions.softmax:8 of
msgid "N-D array. Typically indicates a score."
msgstr "N-D 配列。通常、スコアを表します。"

#: nnabla.functions.categorical_cross_entropy:14 nnabla.functions.log_softmax:26
#: nnabla.functions.softmax:10 nnabla.functions.softmax_cross_entropy:16 of
msgid "Axis normalization is taken. [default=``len(x.shape) - 1``]"
msgstr "軸の正規化が取得されます。[ デフォルト = ``len(x.shape) - 1`` ]"

#: nnabla.functions.log_softmax:1 of
msgid ""
"Fused operation of Softmax normalization followed by log, which is defined as"
msgstr "Softmax normalization から log に続く融合演算。次のように定義されます。"

#: nnabla.functions.log_softmax:3 of
msgid "y_i = \\log \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)},"
msgstr ""

#: nnabla.functions.log_softmax:6 of
msgid ""
"where :math:`y_i` is the input and :math:`x_i` is the output at i-th channel. An "
"advantage of this fusion is reducing the numerical instability due to the log "
"application."
msgstr ""
"ここでは、 :math:`y_i` は入力、 :math:`x_i` は i 番目のチャネルにおける出力です。"
"この融合の利点は、log アプリケーションによる数値の不安定性を軽減することです。"

#: nnabla.functions.log_softmax:9 of
msgid "The original definition can be rewritten as"
msgstr "上記の定義は、次のように再定義することができます。"

#: nnabla.functions.log_softmax:11 of
msgid ""
"y_i = x_i - \\max_j(x_j) - \\log\\left\\(\\sum_j \\exp(x_j - \\max_k(x_k))\\right"
"\\)."
msgstr ""
"y_i = x_i - \\max_j(x_j) - \\log\\left(\\sum_j \\exp(x_j - \\max_k(x_k))\\right)."

#: nnabla.functions.log_softmax:14 of
msgid ""
"It is more stable as a log is always applied to a value :math:`\\ge e`, while a "
"log can be evaluated for 0 in the non-fused operation."
msgstr ""
"非融合演算においては 0 に対する log の値を求めることができますが、ここでは log が"
"常に :math:`e` 以上の値に適用されるため、より安定します。"

#: nnabla.functions.log_softmax:16 of
msgid ""
"Also, backward gradient computation is more stable than the original one as it "
"doesn't perform division by x due to a gradient of log. The definition is as "
"following."
msgstr ""
"また、backward 勾配演算は log 勾配により、 x による除算を行わないため、元の勾配演"
"算よりも安定した演算となります。次のように定義されます。"

#: nnabla.functions.log_softmax:18 of
msgid "dx_i = dy_i - y_i * \\sum_j dy_j"
msgstr ""

#: nnabla.functions.log_softmax:21 of
msgid ""
"where :math:`dx_i` and :math:`dy_i` denote gradients of loss wrt :math:`x_i` "
"and :math:`y_i` respectively."
msgstr ""
"ここでは、 :math:`dx_i` および :math:`dy_i` はそれぞれ :math:`x_i`、 :math:`y_i` "
"に対する loss 勾配となります。"

#: nnabla.functions.elu:1 of
msgid "Element-wise Exponential Linear Unit (ELU) function."
msgstr "要素ごとの Exponential Linear Unit ( ELU ) 関数。"

#: nnabla.functions.elu:3 of
msgid ""
"y_i= \\left\\{ \\begin{array}{ll} x_i & (x > 0)\\\\ \\alpha (\\exp(x_i) - 1) & "
"(x \\leq 0) \\end{array} \\right.."
msgstr ""

#: nnabla.functions.elu:12 of
msgid ""
"`Clevart et al., Fast and Accurate Deep Network Learning by Exponential Linear "
"Units (ELUs). <http://arxiv.org/abs/1511.07289>`_"
msgstr ""

#: nnabla.functions.elu:17 of
msgid ""
"Coefficient for negative outputs. :math:`\\alpha` in definition [default=``1.0``]"
msgstr "マイナス出力に対する係数。定義で :math:`\\alpha` [ デフォルト = ``1.0`` ]"

#: nnabla.functions.selu:1 of
msgid ""
"Element-wise Scaled Exponential Linear Unit (SELU) function by Klambauer et al. "
"(2017)."
msgstr ""
"Klambauer 他 (2017) による要素ごとの Scaled Exponential Linear Unit ( SELU ) 関"
"数。"

#: nnabla.functions.selu:3 of
msgid ""
"y_i= \\lambda \\left\\{ \\begin{array}{ll} x_i & (x > 0)\\\\ \\alpha (\\exp(x_i) "
"- 1) & (x \\leq 0) \\end{array} \\right.."
msgstr ""

#: nnabla.functions.selu:10 of
msgid ""
"The coefficients :math:`\\lambda` and :math:`\\alpha` default to the following "
"values :math:`\\lambda_{01}` and :math:`\\alpha_{01}`, respectively, provided by "
"Klambauer et al. (2017):"
msgstr ""
"係数 :math:`\\lambda` と :math:`\\alpha` は、Klambauer 他 (2017) に記載のとおり、"
"次の値 :math:`\\lambda_{01}` と :math:`\\alpha_{01}` をそれぞれデフォルトとしま"
"す。"

#: nnabla.functions.selu:12 of
msgid ""
"\\begin{array}{lll}   \\lambda_{01} &=&  \\left(  1 - "
"\\operatorname{erfc}\\left( \\frac{1}{\\sqrt{2}} \\right) \\sqrt{e}  "
"\\right)               \\sqrt{2 \\pi} \\\\              && "
"\\left(                   2 \\operatorname{erfc} \\left( \\sqrt{2} \\right) "
"e^2                   + \\pi \\operatorname{erfc}\\left( \\frac{1}{\\sqrt{2}} "
"\\right)^2 e                   \\right. \\\\              && "
"\\left.                   - 2(2 + \\pi) \\operatorname{erfc} \\left( \\frac{1}"
"{\\sqrt{2}} \\right) \\sqrt{e}                   + \\pi + 2              "
"\\right)^{-1/2}  \\\\           &\\approx& 1.0507 \\\\   \\alpha_{01} &=&  - "
"\\frac                 {\\sqrt {\\frac {2}{\\pi}}}                 "
"{\\operatorname{erfc} \\left( \\frac{1}{\\sqrt{2}} \\right) \\exp \\left(\\frac "
"{1} {2} \\right) - 1} \\\\           &\\approx& 1.67326 \\end{array}"
msgstr ""

#: nnabla.functions.selu:34 of
msgid ""
"`Klambauer, G., Unterthiner, T., Mayr, A., & Hochreiter, S. (2017). Self-"
"Normalizing Neural Networks. In Advances in Neural Information Processing "
"Systems (NIPS). <https://arxiv.org/abs/1706.02515>`_"
msgstr ""

#: nnabla.functions.selu:40 of
msgid ""
"The coefficient :math:`\\lambda` in the definition. "
"[default=``1.05070098735548``]"
msgstr "定義における係数 :math:`\\lambda`。 [ デフォルト = ``1.05070098735548`` ]"

#: nnabla.functions.selu:43 of
msgid ""
"The coefficient :math:`\\alpha` in the definition. "
"[default=``1.673263242354377``]"
msgstr "定義における係数 :math:`\\alpha`。[ デフォルト = ``1.673263242354377`` ]"

#: nnabla.functions.crelu:1 of
msgid ""
"Element-wise Concatenated Rectified Linear Unit (CReLU) function. This function "
"calculates the ReLU of :math:`x` and :math:`-x` , then concatenates the results "
"together at a specified axis, and returns the resulting array."
msgstr ""
"要素ごとの Concatenated Rectified Linear Unit ( CReLU ) 関数。この関数は :math:"
"`x` と :math:`-x` の ReLU を計算し、その後、指定された軸における結果を連結し、そ"
"の結果の配列を返します。"

#: nnabla.functions.crelu:8 of
msgid ""
"`Wenling Shang, Kihyuk Sohn, Diogo Almeida, Honglak Lee. Understanding and "
"Improving Convolutional Neural Networks via Concatenated Rectified Linear Units. "
"<https://arxiv.org/abs/1603.05201>`_"
msgstr ""

#: nnabla.functions.absolute_error:6 nnabla.functions.absolute_error:8
#: nnabla.functions.absolute_error:11 nnabla.functions.celu:4
#: nnabla.functions.clip_by_norm:18 nnabla.functions.clip_by_value:18
#: nnabla.functions.clip_grad_by_norm:31 nnabla.functions.clip_grad_by_value:31
#: nnabla.functions.crelu:13 nnabla.functions.epsilon_insensitive_loss:10
#: nnabla.functions.epsilon_insensitive_loss:12
#: nnabla.functions.fixed_point_quantize:16 nnabla.functions.huber_loss:12
#: nnabla.functions.huber_loss:14 nnabla.functions.identity:6
#: nnabla.functions.image_augmentation:3 nnabla.functions.image_augmentation:54
#: nnabla.functions.interpolate:58 nnabla.functions.max:41 nnabla.functions.mean:11
#: nnabla.functions.mean_subtraction:30 nnabla.functions.min:41
#: nnabla.functions.pow2_quantize:18 nnabla.functions.prelu:17
#: nnabla.functions.prod:11 nnabla.functions.random_erase:34
#: nnabla.functions.random_erase:70 nnabla.functions.random_shift:3
#: nnabla.functions.random_shift:18 nnabla.functions.reduce_sum:5
#: nnabla.functions.reshape:8 nnabla.functions.shift:3 nnabla.functions.shift:12
#: nnabla.functions.squared_error:6 nnabla.functions.squared_error:8
#: nnabla.functions.squared_error:11 nnabla.functions.sum:11
#: nnabla.functions.tile:11 nnabla.functions.top_k_data:35
#: nnabla.functions.unlink:19 nnabla.functions.unlink:22 of
msgid "N-D array."
msgstr "N-D 配列。"

#: nnabla.functions.crelu:15 of
msgid ""
"The ReLU activations of positive inputs and negative inputs are concatenated at "
"axis. [default=``1``]"
msgstr ""
"プラス入力とマイナス入力の ReLU 活性化は軸で連結されます。[ デフォルト = ``1`` ]"

#: nnabla.functions.celu:13 nnabla.functions.crelu:19 of
msgid "N-D array where axis dimension is doubled by concatenating."
msgstr "連結によって軸の次元が 2 倍になった N-D 配列。"

#: nnabla.functions.celu:1 of
msgid ""
"Element-wise Concatenated Exponential Linear Unit (CELU) function. Concatenates "
"ELU outputs of positive and negative inputs together at specified axis."
msgstr ""
"要素ごとの Concatenated Exponential Linear Unit ( CELU ) 関数。指定された軸におけ"
"るプラスおよびマイナス入力の ELU 出力を連結します。"

#: nnabla.functions.celu:6 of
msgid ""
"Coefficient for negative outputs. :math:`\\alpha` in definition. "
"[default=``1.0``]"
msgstr ""
"マイナス出力に対する係数。定義における :math:`\\alpha`。 [ デフォルト = ``1.0`` ]"

#: nnabla.functions.celu:9 of
msgid ""
"The ELU activations of positive inputs and negative inputs are concatenated at "
"axis. [default=``1``]"
msgstr ""
"プラスのとマイナス入力の ELU 活性化は軸で連結されます。[ デフォルト = ``1`` ]"

#: nnabla.functions.gelu:1 of
msgid "Gaussian Error Unit (GELU) function."
msgstr "Gaussian Error Unit ( GELU ) 関数。"

#: nnabla.functions.gelu:3 of
msgid "GELU(x) = xP(X \\leq  x) = x \\Phi (x)"
msgstr ""

#: nnabla.functions.gelu:6 of
msgid "which is approximated by"
msgstr "上記は以下によって近似されます。"

#: nnabla.functions.gelu:8 of
msgid "GELU(x) = 0.5x (1 + \\tanh ( \\sqrt(2/\\pi)(x + 0.044715x^3) ))"
msgstr ""

#: nnabla.functions.gelu:13 of
msgid ""
"`Dan Hendrycks and Kevin Gimpel. Gaussian Error Linera Units (GELUs). <https://"
"arxiv.org/abs/1606.08415>`_"
msgstr ""

#: nnabla.functions.prelu:1 of
msgid "Element-wise Parametrized Rectified Linear Unit function. Calculates:"
msgstr "要素ごとの Parametrized Rectified Linear 関数。次のように計算します。"

#: nnabla.functions.prelu:3 of
msgid "y_i = \\max(0, x_i) + w_i \\min(0, x_i)"
msgstr ""

#: nnabla.functions.prelu:6 of
msgid ""
"where negative slope :math:`w` is learned and can vary across channels (an axis "
"specified with `base_axis`)."
msgstr ""
"ここでは、マイナス領域の傾き :math:`w` は学習され、チャネル ( `base_axis` で指定"
"される軸) 間で変更されます。"

#: nnabla.functions.prelu:9 of
msgid "(N-D array) Input"
msgstr "(N-D 配列) 入力"

#: nnabla.functions.prelu:11 of
msgid "(N-D array) Weights"
msgstr "(N-D 配列) 重み"

#: nnabla.functions.binary_connect_affine:48
#: nnabla.functions.binary_connect_convolution:49
#: nnabla.functions.binary_weight_affine:49
#: nnabla.functions.binary_weight_convolution:50 nnabla.functions.inq_affine:29
#: nnabla.functions.inq_convolution:29 nnabla.functions.kl_multinomial:10
#: nnabla.functions.prelu:13 nnabla.functions.random_erase:57
#: nnabla.functions.vat_noise:32 of
msgid "Dimensions up to base_axis is treated as sample dimension. [default=``1``]"
msgstr ""
"base_axis までの次元はサンプルの次元として扱われます。[ デフォルト = ``1`` ]"

#: nnabla.functions.leaky_relu:1 of
msgid "Element-wise Leaky Rectified Linear Unit (ReLU) function."
msgstr "要素ごとの Leaky Rectified Linear Unit (ReLU) 関数。"

#: nnabla.functions.leaky_relu:3 of
msgid "It is defined as:"
msgstr "次のように定義します。"

#: nnabla.functions.leaky_relu:5 of
msgid "y_i = \\alpha * \\min(0, x_i) + \\max (0, x_i)"
msgstr ""

#: nnabla.functions.leaky_relu:11 of
msgid ""
"The slope value multiplied to negative numbers. :math:`\\alpha` in the "
"definition. [default=``0.1``]"
msgstr ""
"負の数に掛けられた勾配の値。定義で :math:`\\alpha`。 [ デフォルト = ``0.1`` ]"

#: nnabla.functions.relu6:1 of
msgid ""
"Element-wise ReLU6 function. Capping ReLU activation to 6 is often observed to "
"learn sparse features earlier."
msgstr ""
"要素ごとの ReLU6 関数。 ReLU 活性化を 6 に制限することは、学習初期段階からスパー"
"スな特徴を学習することがあります。"

#: nnabla.functions.relu6:4 of
msgid "ReLU6(x) = \\min(\\max(0,x,),6)"
msgstr ""

#: nnabla.functions.hard_sigmoid:1 of
msgid ""
"Segment-wise linear approximation of sigmoid. Preferable when speed of "
"computation is more important than precision. Returns :math:`0` if :math:`x < "
"-2.5`. Returns :math:`1` if :math:`x> 2.5`. Returns :math:`0.2x + 0.5` if :math:"
"`-2.5 <= x <= 2.5`."
msgstr ""
"セグメントごとの sigmoid の線形の近似。精度より計算速度が重要である場合に適してい"
"ます。 :math:`x < -2.5` の場合は、 :math:`0` を返します。 :math:`x> 2.5` の場合"
"は、 :math:`1` を返します。 :math:`-2.5 <= x <= 2.5` の場合は、 :math:`0.2x + "
"0.5` を返します。"

#: nnabla.functions.hard_tanh:1 of
msgid ""
"Element-wise HardTanh function. Computationally cheaper than Tanh function. "
"Returns :math:`1` if :math:`x > 1`. Returns :math:`-1` if :math:`x < -1`. "
"Returns :math:`x` otherwise."
msgstr ""
"要素ごとの HardTanh 関数。Tanh 関数より計算量は少ないです。 :math:`x > 1` の場"
"合、 :math:`1` を返します。 :math:`x < -1` の場合、 :math:`-1` を返します。それ以"
"外は、 :math:`x` を返します。"

#: nnabla.functions.log_sigmoid:1 of
msgid "Element-wise LogSigmoid function."
msgstr "要素ごとの LogSigmoid 関数。"

#: nnabla.functions.log_sigmoid:3 of
msgid "LogSigmoid(x) = \\log(1/(1+\\exp(-x_i)))"
msgstr ""

#: nnabla.functions.softplus:1 of
msgid ""
"Element-wise SoftPlus function. Unlike Sigmoid and Tanh that have upper and "
"lower bound, SoftPlus is only lower-bounded by 0."
msgstr ""
"要素ごとの SoftPlus 関数。上限と下限のある Sigmoid や Tanh と異なり、SoftPlus は"
"下限のみが 0 に抑えられます。"

#: nnabla.functions.softplus:4 of
msgid "SoftPlus(x) = \\log(1+\\exp(x_i))"
msgstr ""

#: nnabla.functions.softsign:1 of
msgid ""
"Element-wise SoftSign. Can be used in place of Tanh function. While Tanh "
"converges exponentially, SoftSign converges polynomially."
msgstr ""
"要素ごとの SoftSign。Tanh 関数の代わりに使うことができます。Tanh は指数関数を扱い"
"ますが、 SoftSign は多項式を扱います。"

#: nnabla.functions.softsign:5 of
msgid "SoftSign(x) = x/(1+|x|)"
msgstr ""

#: nnabla.functions.tanh_shrink:1 of
msgid "Element-wies TanhShrink function."
msgstr "要素ごとの TanhShrink 関数。"

#: nnabla.functions.tanh_shrink:3 of
msgid "TanhShrink(x) = x - \\tanh(x)"
msgstr ""

#: nnabla.functions.sinc:1 of
msgid ""
"Element-wise Sinc function. Unlike other popular activation functions, it has "
"rises and falls. returns :math:`1` if :math:`x = 0`. returns :math:`\\sin(x)/x` "
"otherwise."
msgstr ""
"要素ごとの Sinc 関数。他の主な活性化関数と異なり、Sinc 関数は上がり下がりがありま"
"す。 :math:`x = 0` の場合、 :math:`1` を返します。それ以外は、 :math:`\\sin(x)/"
"x` を返します。"

#: ../../python/api/function.rst:83
msgid "Normalization"
msgstr "Normalization"

#: nnabla.functions.batch_normalization:1 of
msgid "Batch normalization."
msgstr "Batch normalization。"

#: nnabla.functions.batch_normalization:3 of
msgid ""
"\\begin{eqnarray}   \\mu &=& \\frac{1}{M} \\sum x_i \\\\   \\sigma^2 &=& "
"\\frac{1}{M} \\sum \\left(x_i - \\mu\\right)^2 \\\\   \\hat{x}_i &=& \\frac{x_i "
"- \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\\\   y_i &=& \\hat{x}_i \\gamma + "
"\\beta. \\end{eqnarray}"
msgstr ""

#: nnabla.functions.batch_normalization:12 of
msgid ""
"At testing time, the mean and variance values used are those that were computed "
"during training by moving average."
msgstr ""
"テスト中、使用される平均と分散の値は、学習中に変動する平均を使って計算される値と"
"なります。"

#: nnabla.functions.batch_normalization:16
#: nnabla.functions.fused_batch_normalization:5 of
msgid ""
"`Ioffe and Szegedy, Batch Normalization: Accelerating Deep Network Training by "
"Reducing Internal Covariate Shift. <https://arxiv.org/abs/1502.03167>`_"
msgstr ""

#: nnabla.functions.batch_normalization:19 nnabla.functions.clip_grad_by_norm:22
#: nnabla.functions.clip_grad_by_value:24
#: nnabla.functions.fused_batch_normalization:8
#: nnabla.functions.mean_subtraction:17
#: nnabla.functions.sync_batch_normalization:18 of
msgid "N-D array of input."
msgstr "入力の N-D 配列。"

#: nnabla.functions.batch_normalization:21
#: nnabla.functions.fused_batch_normalization:10
#: nnabla.functions.sync_batch_normalization:20 of
msgid "N-D array of beta which is learned. If None, the bias term is omitted."
msgstr "学習される betaの N-D 配列。None の場合、バイアス項を省きます。"

#: nnabla.functions.batch_normalization:23
#: nnabla.functions.fused_batch_normalization:12
#: nnabla.functions.sync_batch_normalization:22 of
msgid "N-D array of gamma which is learned. If None, the scale term is omitted."
msgstr "学習される gamma の N-D 配列。 None の場合、スケール項を省きます。"

#: nnabla.functions.batch_normalization:25 of
msgid ""
"N-D array of running mean (modified during forward execution). If None, dummy "
"variable is created and running mean is not updated. mean=None with "
"batch_stat=False is prohibited."
msgstr ""
"( forward 実行中に変更される) 実行平均の N-D 配列。 None ならば、ダミー変数が作ら"
"れ、実行の平均は更新されません。batch_stat=False で、mean=None は禁じられていま"
"す。"

#: nnabla.functions.batch_normalization:29
#: nnabla.functions.fused_batch_normalization:18 of
msgid ""
"N-D array of running variance (modified during forward execution). If None, "
"dummy variable is created and running variance is not updated. variance=None "
"with batch_stat=False is prohibited."
msgstr ""
"( forward 実行中に変更される ) 実行分散の N-D 配列。 None の場合、ダミー変数が生"
"成され、実行分散は更新されません。batch_stat=False の場合、variance=None は禁止さ"
"れています。"

#: nnabla.functions.batch_normalization:33
#: nnabla.functions.fused_batch_normalization:24
#: nnabla.functions.sync_batch_normalization:36 of
msgid "Mean and variance are calculated along these axes."
msgstr "これらの軸における平均および分散を計算します。"

#: nnabla.functions.batch_normalization:35
#: nnabla.functions.fused_batch_normalization:26
#: nnabla.functions.sync_batch_normalization:38 of
msgid "Decay rate of running mean and variance."
msgstr "実行の平均と分散の減衰率。"

#: nnabla.functions.batch_normalization:37
#: nnabla.functions.fused_batch_normalization:28
#: nnabla.functions.group_normalization:38
#: nnabla.functions.instance_normalization:31
#: nnabla.functions.layer_normalization:29
#: nnabla.functions.sync_batch_normalization:40
#: nnabla.functions.weight_standardization:20 of
msgid "Tiny value to avoid zero division by std."
msgstr "標準偏差によるゼロ除算を避けるための小さな値。"

#: nnabla.functions.batch_normalization:39
#: nnabla.functions.fused_batch_normalization:30
#: nnabla.functions.sync_batch_normalization:42 of
msgid ""
"Use mini-batch statistics rather than running ones. If False, mean and variance "
"must be `~nnabla.Variable`. (None is prohibited.)"
msgstr ""
"実行中の統計よりミニバッチの統計を使います。 False の場合、平均と分散は `~nnabla."
"Variable` である必要があります。 (None は禁止されています)"

#: nnabla.functions.batch_normalization:42
#: nnabla.functions.fused_batch_normalization:35
#: nnabla.functions.sync_batch_normalization:45 of
msgid ""
"It true, the batch statistics of mean and variance, will be returned as "
"Variables. They are also differentiable."
msgstr ""
"true の場合、平均と分散のバッチの統計を Variable として返します。また、これらは微"
"分可能です。"

#: nnabla.functions.batch_normalization:46
#: nnabla.functions.fused_batch_normalization:39
#: nnabla.functions.sync_batch_normalization:49 of
msgid ""
"Returns batch normalization output as :obj:`~nnabla.Variable`. If "
"``output_stat=True``, it also returns the mean and variance of the mini-batch  "
"* :obj:`~nnabla.Variable`: Output of the batch normalization * :obj:`~nnabla."
"Variable`: Mean (if ``output_stat=True`) * :obj:`~nnabla.Variable`: Variance (if "
"``output_stat=True`)"
msgstr ""

#: nnabla.functions.batch_normalization:46
#: nnabla.functions.fused_batch_normalization:39
#: nnabla.functions.sync_batch_normalization:49 of
msgid ""
"Returns batch normalization output as :obj:`~nnabla.Variable`. If "
"``output_stat=True``, it also returns the mean and variance of the mini-batch"
msgstr ""
"Batch normalization の出力を :obj:`~nnabla.Variable` として返します。 "
"``output_stat=True`` の場合、ミニバンの平均と分散も返します"

#: nnabla.functions.batch_normalization:50
#: nnabla.functions.fused_batch_normalization:43
#: nnabla.functions.sync_batch_normalization:53 of
msgid ":obj:`~nnabla.Variable`: Output of the batch normalization"
msgstr ":obj:`~nnabla.Variable`: batch normalization の出力"

#: nnabla.functions.batch_normalization:51
#: nnabla.functions.fused_batch_normalization:44
#: nnabla.functions.sync_batch_normalization:54 of
msgid ":obj:`~nnabla.Variable`: Mean (if ``output_stat=True`)"
msgstr ":obj:`~nnabla.Variable`: 平均( ``output_stat=True`` の場合 )"

#: nnabla.functions.batch_normalization:52
#: nnabla.functions.fused_batch_normalization:45
#: nnabla.functions.sync_batch_normalization:55 of
msgid ":obj:`~nnabla.Variable`: Variance (if ``output_stat=True`)"
msgstr ":obj:`~nnabla.Variable`: 分散 ( ``output_stat=True`` の場合 )"

#: nnabla.functions.batch_normalization:54
#: nnabla.functions.fused_batch_normalization:47
#: nnabla.functions.sync_batch_normalization:57 of
msgid "``nnabla.function_bases.batch_normalization``."
msgstr "``nnabla.function_bases.batch_normalization``."

#: nnabla.functions.fused_batch_normalization:1 of
msgid "Batch normalization fused with an add operation and an activation."
msgstr "追加操作および活性化と融合した Batch normalization。"

#: nnabla.functions.fused_batch_normalization:14
#: nnabla.functions.sync_batch_normalization:24 of
msgid ""
"N-D array of running mean (modified during forward execution). If None, dummy "
"variable is created and running mean is never updated. mean=None with "
"batch_stat=False is prohibited."
msgstr ""
"( forward 実行中に変更される) 実行平均の N-D 配列。 None ならば、ダミー変数が作ら"
"れ、実行の平均は更新されません。batch_stat=False で、mean=None は禁じられていま"
"す。"

#: nnabla.functions.fused_batch_normalization:33 of
msgid "Nonlinearity chosen from relu. Default is relu."
msgstr "relu から選択される非線形。デフォルトは relu です。"

#: nnabla.functions.sync_batch_normalization:1 of
msgid "Synchronized batch normalization."
msgstr "Synchronized batch normalization。"

#: nnabla.functions.sync_batch_normalization:3 of
msgid ""
"For some tasks (e.g., semantic segmentation), batch size will be too small and "
"BatchNormalization layer might not work well. SyncBatchNorlization layer solves "
"these problems by synchronizing batch stats (mean and var) between multiple "
"processes."
msgstr ""
"タスクによっては (例えば、意味論的セグメンテーション) 、バッチサイズが小さすぎ"
"て、 BatchNormalization 層がうまく動作しない場合があります。SyncBatchNorlization "
"層は、複数のプロセス間でバッチ統計 (平均と分散) を同期することによって、この問題"
"を解決します。"

#: nnabla.functions.sync_batch_normalization:6 of
msgid ""
"\\begin{eqnarray}   \\mu &=& \\frac{1}{M} \\sum x_i \\\\   \\sigma^2 &=& "
"\\frac{1}{M} \\left(\\sum x_i - \\mu\\right)^2 \\\\   \\hat{x}_i &=& \\frac{x_i "
"- \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\\\   y_i &=& \\hat{x}_i \\gamma + "
"\\beta. \\end{eqnarray}"
msgstr ""

#: nnabla.functions.sync_batch_normalization:16 of
msgid ""
"Implementing Synchronized Multi-GPU Batch Normalization https://hangzhang.org/"
"PyTorch-Encoding/notes/syncbn.html"
msgstr ""

#: nnabla.functions.sync_batch_normalization:28 of
msgid ""
"N-D array of running variance (modified during forward execution). If None, "
"dummy variable is created and running variance is never updated. variance=None "
"with batch_stat=False is prohibited."
msgstr ""
"( forward 実行中に変更される) 実行分散の N-D 配列。None の場合、ダミー変数が生成"
"され、実行分散は更新されません。 batch_stat=False の場合、variance=None は禁止さ"
"れています。"

#: nnabla.functions.sync_batch_normalization:32 of
msgid "The communicator"
msgstr "communicator"

#: nnabla.functions.sync_batch_normalization:34 of
msgid "The name of the communicator group"
msgstr "communicator グループの名前"

#: nnabla.functions.mean_subtraction:1 of
msgid ""
"It subtracts the mean of the elements of the input array, and normalizes it to :"
"math:`0`. Preprocessing arrays with this function has the effect of improving "
"accuracy in various tasks such as image classification."
msgstr ""
"入力配列の要素の平均を減算して、平均を :math:`0` に正規化します。この関数を使った"
"配列の前処理は、画像分類のような様々なタスクで精度向上に効果があります。"

#: nnabla.functions.mean_subtraction:5 of
msgid "At training time, this function is defined as"
msgstr "学習時、この関数は次のように定義されます。"

#: nnabla.functions.mean_subtraction:7 of
msgid ""
"\\begin{eqnarray}   \\mu &=& \\frac{1}{M} \\sum x_i \\\\   y_i &=& x_i - \\mu "
"\\end{eqnarray}"
msgstr ""

#: nnabla.functions.mean_subtraction:13 of
msgid ""
"At testing time, the mean values used are those that were computed during "
"training by moving average."
msgstr ""
"テスト中、使用される平均値は学習時に変動する平均によって計算されたものです。"

#: nnabla.functions.mean_subtraction:15 of
msgid ""
"The backward performs an approximated differentiation that takes into account "
"only the latest mini-batch."
msgstr "backward は、最新のミニバッチのみを考慮した近似微分を実行します。"

#: nnabla.functions.mean_subtraction:19 of
msgid "N-D array of running mean (modified during forward execution)."
msgstr "( forward 実行中に変更される ) 実行の平均の N-D 配列。"

#: nnabla.functions.mean_subtraction:21 of
msgid ""
"Scalar of num of iteration of running mean (modified during forward execution)."
msgstr "( forward 実行中に変更される ) 実行平均のイテレーション回数のスカラ。"

#: nnabla.functions.mean_subtraction:23 of
msgid ""
"Base axis of Mean Subtraction operation. Dimensions up to base_axis is treated "
"as sample dimension. [default=``1``]"
msgstr ""
"Mean Subtraction (平均の減算) 演算の基本軸。base_axis までの次元はサンプルの次元"
"として扱われます。[ デフォルト = ``1`` ]"

#: nnabla.functions.mean_subtraction:26 of
msgid "Update running mean during forward execution. [default=``True``]"
msgstr "forward 実行中の実行平均を更新します。 [ デフォルト = ``True`` ]"

#: nnabla.functions.mean_subtraction:33 of
msgid "``nnabla.function_bases.mean_subtraction``."
msgstr "``nnabla.function_bases.mean_subtraction``."

#: nnabla.functions.clip_by_value:1 of
msgid "Clip inputs by values."
msgstr "値によって入力をクリップします。"

#: nnabla.functions.clip_by_value:3 of
msgid ""
"y = \\begin{cases}         max & (x > max) \\\\         x & (otherwise) \\"
"\\         min & (x < min)     \\end{cases}."
msgstr ""

#: nnabla.functions.clip_by_norm:11 nnabla.functions.clip_by_value:11
#: nnabla.functions.fixed_point_quantize:3 nnabla.functions.group_normalization:26
#: nnabla.functions.instance_normalization:21
#: nnabla.functions.layer_normalization:21 nnabla.functions.max:29
#: nnabla.functions.mean:3 nnabla.functions.min:29 nnabla.functions.pow2_quantize:3
#: nnabla.functions.prod:3 nnabla.functions.sum:3 of
msgid "An input variable."
msgstr "入力変数。"

#: nnabla.functions.clip_by_value:13 of
msgid ""
"A min variable or float value by which `x` is clipped. Note that if Variable is "
"given, its shape must be the same as `x`'s."
msgstr ""
"`x` がクリップされる最小値。min の形状は `x` の形状と同じでなければならないことに"
"注意してください。"

#: nnabla.functions.clip_by_value:15 of
msgid ""
"A max variable or float value by which `x` is clipped. Note that if Variable is "
"given, its shape must be the same as `x`'s"
msgstr ""
"`x` がクリップされる最大値。max の形状は `x` の形状と同じでなければならないことに"
"注意してください"

#: nnabla.functions.clip_grad_by_value:1 of
msgid "In forward pass, the function behaves as the identity."
msgstr "forward パスでは、この関数は identity として動作します。"

#: nnabla.functions.clip_grad_by_value:3 of
msgid "In backward pass,"
msgstr "以下は、backward パスの場合です。"

#: nnabla.functions.clip_grad_by_value:5 of
msgid ""
"g_x = \\begin{cases}     max & (g_y > max) \\\\     g_y & (otherwise) \\\\     "
"min & (g_y < min)    \\end{cases}."
msgstr ""
"g_x = \\begin{cases}     max & (g_y > max) \\\\     g_y & (otherwise) \\\\     "
"min & (g_y < min)    \\end{cases}."

#: nnabla.functions.clip_grad_by_value:12 of
msgid ""
"A typical case for use is to prevent the gradient explosion through a whole "
"computational graph. For example, if you want to clip gradient values for each "
"feature map,"
msgstr ""
"一般的には、計算グラフ全体を通して、勾配の急激な増加を防ぐために使われます。例え"
"ば、以下は各特徴マップに対する勾配値をクリップしたい場合です。"

#: nnabla.functions.clip_grad_by_value:15 of
msgid ""
"x = nn.Variable([16, 3, 32, 32])\n"
"min = F.broadcast(nn.Variable.from_numpy_array(np.asarray([-1.0]).reshape((1, 1, "
"1, 1))), (16, 3, 32, 32))\n"
"max = F.broadcast(nn.Variable.from_numpy_array(np.asarray([1.0]).reshape((1, 1, "
"1, 1))), (16, 3, 32, 32))\n"
"c = F.clip_grad_by_value(x, min=min, max=max)\n"
"h = PF.convolution(c, 64, (3, 3), pad=(1, 1))"
msgstr ""

#: nnabla.functions.clip_grad_by_value:26 of
msgid ""
"N-D array of minimum input value by which the gradients of the `y` are clipped. "
"Note that the shape of `min` must be the same as `x`'s and the backward to `min` "
"is not performed."
msgstr ""
"`y` の勾配がクリップされる最小の入力値の N-D 配列。 `min` の形状は `x` の形状と同"
"じである必要があり、 `min` への backward は行われないということに注意してくださ"
"い。"

#: nnabla.functions.clip_grad_by_value:28 of
msgid ""
"N-D array of maximum input value by which the gradients of the `y` are clipped. "
"Note that the shape of `max` must be the same as `x`'s and the backward to `max` "
"is not performed."
msgstr ""
"`y` の勾配がクリップされる最大の入力値の N-D 配列。 `max` の形状は `x` の形状と同"
"じである必要があり、 `max` への逆方向は行われないということに注意してください。"

#: nnabla.functions.clip_by_norm:1 of
msgid ""
"Clip inputs by its L2 norm when the L2 norm is larger than the threshold value "
"(defined by clip_norm). If it is less than the threshold, inputs are not "
"modified. If it is applied, the operation is represented as"
msgstr ""
"L2 ノルムが ( clip_norm において定義 )閾値より大きい場合は、L2 ノルムにより入力を"
"クリップします。閾値より小さい場合は、入力は変更されません。そのような場合は、演"
"算は次のように表します。"

#: nnabla.functions.clip_by_norm:4 of
msgid "y = N \\times \\frac{x}{\\|x\\|_2}."
msgstr "y = N \\times \\frac{x}{\\|x\\|_2}."

#: nnabla.functions.clip_by_norm:7 of
msgid ""
"where :math:`x` is the input, :math:`y` is the output, and :math:`N` is "
"`clip_norm`. this is the case that `axes` is not set. When `axes` is set, the "
"norm is computed over `axes`."
msgstr ""
"ここでは、 :math:`x` は入力、 :math:`y` は出力、 :math:`N` は `clip_norm` です。"
"これは `axes` が指定されない場合です。 `axes` が指定される場合は、ノルムは "
"`axes` 上で計算されます。"

#: nnabla.functions.clip_by_norm:13 of
msgid "An input scalar variable or float value. Must be positive."
msgstr "入力スカラ変数または浮動小数点値。正の値である必要があります。"

#: nnabla.functions.clip_by_norm:15 of
msgid ""
"Axis or axes along which the reduction is performed. Passing the default value "
"`None` will reduce all dimensions."
msgstr ""
"軸、または削減が行われる軸。 デフォルト値 `None` を渡すことで、すべての次元を削減"
"します。"

#: nnabla.functions.clip_grad_by_norm:1 of
msgid "In the forward pass, the function behaves like the identity."
msgstr "forward パスでは、この関数は identity として動作します。"

#: nnabla.functions.clip_grad_by_norm:3 of
msgid "In the backward pass,"
msgstr "以下は、backward パスの場合です。"

#: nnabla.functions.clip_grad_by_norm:5 of
msgid "g_x = N \\times \\frac{g_y}{\\|g_y\\|_2}."
msgstr "g_x = N \\times \\frac{g_y}{\\|g_y\\|_2}."

#: nnabla.functions.clip_grad_by_norm:9 of
msgid ""
"where :math:`g_x` is the gradient w.r.t the input, :math:`g_y` is the gradient w."
"r.t. the output, and :math:`N` is `clip_norm` where the norm of :math:`g_y` "
"becomes. this is the case that `axes` is not set. When `axes` is set, the norm "
"is computed over `axes`."
msgstr ""
"ここでは、 :math:`g_x` は入力に対する勾配、 :math:`g_y` は出力に対する勾配、 :"
"math:`N` は :math:`g_y` のノルムとなる `clip_norm` です。これは `axes` が指定され"
"ない場合です。 `axes` が指定される場合は、ノルムは `axes` 上で計算されます。"

#: nnabla.functions.clip_grad_by_norm:13 of
msgid ""
"A typical case for use is to prevent the gradient explosion through a whole "
"computational graph. For example, if you want to normalize gradient values over "
"feature axis,"
msgstr ""
"一般的には、計算グラフ全体を通して、勾配の急激な増加を防ぐために使われます。例え"
"ば、以下は、特徴軸に対する勾配値を正規化したい場合です。"

#: nnabla.functions.clip_grad_by_norm:16 of
msgid ""
"x = nn.Variable([16, 3, 32, 32])\n"
"c = F.clip_grad_by_norm(x, axes=(1, ))\n"
"h = PF.convolution(c, 64, (3, 3), pad=(1, 1))"
msgstr ""

#: nnabla.functions.clip_grad_by_norm:24 of
msgid ""
"Clip to the norm of input to `clip_norm` in the backward pass. [default=``1.0``]"
msgstr ""
"backward パスで `clip_norm` に対する入力のノルムへのクリップ。[ デフォルト = "
"``1.0`` ]"

#: nnabla.functions.clip_grad_by_norm:27 of
msgid ""
"Axes to be reduced. If empty list is given, all dimensions are reduced to "
"scalar. This is used in the forward pass. [default=``range(x.ndim)``]"
msgstr ""
"削減する軸。空のリストが指定された場合は、すべての次元がスカラまで削減されます。"
"これは forward パスで使われます。[ デフォルト = ``range(x.ndim)`` ]"

#: nnabla.functions.layer_normalization:1 of
msgid "Applies Layer Normalization over an input tensor, which is defined as:"
msgstr ""
"入力テンソルに Layer Normalization を適用します。また、以下のように定義されます。"

#: nnabla.functions.layer_normalization:3 of
msgid ""
"\\begin{eqnarray}   \\mu^l &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^l \\\\   "
"\\sigma^l &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^l - \\mu^l"
"\\right)^2} \\\\   y &=& \\frac{x - \\mu^l}{\\sigma^l + \\epsilon} \\gamma + "
"\\beta \\end{eqnarray}"
msgstr ""
"\\begin{eqnarray}   \\mu^l &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^l \\\\   "
"\\sigma^l &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^l - \\mu^l"
"\\right)^2} \\\\   y &=& \\frac{x - \\mu^l}{\\sigma^l + \\epsilon} \\gamma + "
"\\beta \\end{eqnarray}"

#: nnabla.functions.layer_normalization:10 of
msgid ""
"where :math:`x` and :math:`y` are input and output variable, :math:`\\mu^l` and :"
"math:`\\sigma^l` are the mean and std of each layer which is separately "
"calculated for each batch, and :math:`\\beta` and :math:`\\gamma` are adaptive "
"biases and gains."
msgstr ""
"ここでは、 :math:`x` と :math:`y` は入力変数と出力変数で、 :math:`\\mu^l` と :"
"math:`\\sigma^l` は各層の平均および標準偏差でバッチごとに個別に計算されます。ま"
"た、 :math:`\\beta` と :math:`\\gamma` は適用バイアスとゲインです。"

#: nnabla.functions.layer_normalization:14 of
msgid ""
"If the input shape is [B, C, H, W] (= batch_axis=0), the shape of calculated "
"mean and std are [B, 1, 1, 1]"
msgstr ""
"入力の形状が [B, C, H, W] (= batch_axis=0) の場合は、計算される平均と標準偏差の形"
"状は [B, 1, 1, 1] です。"

#: nnabla.functions.layer_normalization:18 of
msgid ""
"`Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton, Layer Normalization. "
"<https://arxiv.org/abs/1607.06450>`_"
msgstr ""
"`Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton, Layer Normalization. "
"<https://arxiv.org/abs/1607.06450>`_"

#: nnabla.functions.group_normalization:28 nnabla.functions.layer_normalization:23
#: of
msgid "An Adaptive biases. If None, the bias term is omitted."
msgstr "適応バイアス。None の場合、バイアス項は省きます。"

#: nnabla.functions.group_normalization:30 nnabla.functions.layer_normalization:25
#: of
msgid "An Adaptive gains. If None, the scale term is omitted."
msgstr "適応ゲイン。None の場合、スケール項は省きます。"

#: nnabla.functions.layer_normalization:27 of
msgid "Axes mean and variance are taken."
msgstr "軸の平均と分散を取ります。"

#: nnabla.functions.layer_normalization:31 of
msgid "If true, calculated mean and variance are also returned."
msgstr "true の場合、計算される平均および分散も返します。"

#: nnabla.functions.layer_normalization:34 of
msgid ""
"output variable which is normalized its statics and rescaled by alpha and beta. "
"* :obj:`~nnabla.Variable`: Mean (if ``output_stat=True`). * :obj:`~nnabla."
"Variable`: Std (if ``output_stat=True`)"
msgstr ""
"統計を正規化し、アルファとベータによって再度スケールされた出力変数。 * :obj:"
"`~nnabla.Variable`: 平均 ( ``output_stat=True`` の場合) 。 * :obj:`~nnabla."
"Variable`: 標準偏差 ( ``output_stat=True`` の場合)。"

#: nnabla.functions.group_normalization:46
#: nnabla.functions.instance_normalization:39
#: nnabla.functions.layer_normalization:37
#: nnabla.functions.weight_standardization:28 of
msgid "* :obj:`~nnabla.Variable`"
msgstr "* :obj:`~nnabla.Variable`"

#: nnabla.functions.group_normalization:46
#: nnabla.functions.instance_normalization:39
#: nnabla.functions.layer_normalization:37
#: nnabla.functions.weight_standardization:28 of
msgid ":obj:`~nnabla.Variable`"
msgstr ":obj:`~nnabla.Variable`"

#: nnabla.functions.instance_normalization:1 of
msgid "Applies Instance Normalization over an input tensor, which is defined as:"
msgstr ""
"入力テンソルにインスタンスの正規化を適用します。それは次のように定義されます。"

#: nnabla.functions.instance_normalization:3 of
msgid ""
"\\begin{eqnarray}   \\mu^i &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^i \\\\   "
"\\sigma^i &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^i - \\mu^i"
"\\right)^2} \\\\   y &=& \\frac{x - \\mu^i}{\\sigma^i + \\epsilon} \\gamma + "
"\\beta \\end{eqnarray}"
msgstr ""
"\\begin{eqnarray}   \\mu^i &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^i \\\\   "
"\\sigma^i &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^i - \\mu^i"
"\\right)^2} \\\\   y &=& \\frac{x - \\mu^i}{\\sigma^i + \\epsilon} \\gamma + "
"\\beta \\end{eqnarray}"

#: nnabla.functions.instance_normalization:10 of
msgid ""
"where :math:`x` and :math:`y` are input and output variable, :math:`\\mu^i` and :"
"math:`\\sigma^i` are the mean and std of each instance which is separately "
"calculated for each batch and channel, and :math:`\\gamma` and :math:`\\beta` "
"are adaptive gains and biases."
msgstr ""
"ここでは、 :math:`x` と :math:`y` は入力変数と出力変数で、 :math:`\\mu^i` と :"
"math:`\\sigma^i` は各層の平均および標準偏差でバッチごとに個別に計算されます。ま"
"た、 :math:`\\gamma` と :math:`\\beta は適用ゲインとバイアスです。"

#: nnabla.functions.instance_normalization:14 of
msgid ""
"If the input shape is [B, C, H, W] (= channel_axis=1, batch_axis=0), the shape "
"of calculated mean and std are [B, C, 1, 1]"
msgstr ""
"入力の形状が [B, C, H, W] (= channel_axis=1, batch_axis=0) の場合、計算される平均"
"と標準偏差の形状は [B, C, 1, 1] です。"

#: nnabla.functions.instance_normalization:18 of
msgid ""
"`Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky, Instance Normalization: The "
"Missing Ingredient for Fast Stylization. <https://arxiv.org/abs/1607.08022>`_"
msgstr ""
"`Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky, Instance Normalization: The "
"Missing Ingredient for Fast Stylization. <https://arxiv.org/abs/1607.08022>`_"

#: nnabla.functions.instance_normalization:23 of
msgid "An Adaptive biases."
msgstr "適応バイアス。"

#: nnabla.functions.instance_normalization:25 of
msgid "An Adaptive gains."
msgstr "適応ゲイン。"

#: nnabla.functions.group_normalization:34
#: nnabla.functions.instance_normalization:27 of
msgid "Channel axis."
msgstr "チャネル軸。"

#: nnabla.functions.group_normalization:36
#: nnabla.functions.instance_normalization:29 of
msgid "Batch axes."
msgstr "バッチ軸。"

#: nnabla.functions.group_normalization:40
#: nnabla.functions.instance_normalization:33
#: nnabla.functions.weight_standardization:22 of
msgid "If true, the batch statistics of mean and variance."
msgstr "true の場合は、バッチの平均および分散の統計。"

#: nnabla.functions.group_normalization:43
#: nnabla.functions.instance_normalization:36 of
msgid ""
"Normalized output variable. * :obj:`~nnabla.Variable`: Mean (if "
"``output_stat=True`) * :obj:`~nnabla.Variable`: Std (if ``output_stat=True`)"
msgstr ""
"正規化された出力変数。 * :obj:`~nnabla.Variable`: 平均 ( ``output_stat=True`` の"
"場合)  * :obj:`~nnabla.Variable`: 標準偏差 ( ``output_stat=True`` の場合)"

#: nnabla.functions.group_normalization:1 of
msgid "Applies Group Normalization over an input tensor, which is defined as:"
msgstr "入力テンソルにグループの正規化を適用します。それは次のように定義されます。"

#: nnabla.functions.group_normalization:3 of
msgid ""
"\\begin{eqnarray}   \\mu^g &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^g \\\\   "
"\\sigma^g &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^g - \\mu^g"
"\\right)^2} \\\\   y &=& \\frac{x - \\mu^g}{\\sigma^g + \\epsilon} \\gamma + "
"\\beta \\end{eqnarray}"
msgstr ""
"\\begin{eqnarray}   \\mu^g &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^g \\\\   "
"\\sigma^g &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^g - \\mu^g"
"\\right)^2} \\\\   y &=& \\frac{x - \\mu^g}{\\sigma^g + \\epsilon} \\gamma + "
"\\beta \\end{eqnarray}"

#: nnabla.functions.group_normalization:10 of
msgid ""
"where :math:`x` and :math:`y` are input and output variable, :math:`\\mu^g` and :"
"math:`\\sigma^g` are the mean and std of each group which contains "
"`num_channels / num_groups` channels, and :math:`\\gamma` and :math:`\\beta` are "
"adaptive gains and biases."
msgstr ""
"ここでは、 :math:`x` と :math:`y` は入力変数と出力変数で、 :math:`\\mu^g` と :"
"math:`\\sigma^g` は `num_channels / num_groups` チャネルを含むグループごとの平均"
"と標準偏差で、 :math:`\\gamma` と :math:`\\beta` は適応ゲインとバイアスです。"

#: nnabla.functions.group_normalization:14 of
msgid ""
"The input channels, specified by :attr:`channel_axis`, are separated into :attr:"
"`num_groups` groups, and the mean and std are calculated over the each group. "
"For example, if the input shape is [B, C, H, W] (= channel_axis=1, "
"batch_axis=0), an input variable is once reshaped to [B, num_groups, C / "
"num_groups, H, W] and standardize by its mean and std whose shapes are [B, "
"num_groups, 1, 1, 1]. Finally, an output variable is reshaped again to the "
"original input shape (= [B, C, H, W] in the case above)."
msgstr ""
":attr:`channel_axis` によって指定される入力チャネルは :attr:`num_groups` グループ"
"に分けられ、平均と標準偏差はグループごとに計算されます。例えば、入力の形状が [B, "
"C, H, W] (= channel_axis=1, batch_axis=0) の場合、入力変数は一度 [B, num_groups, "
"C / num_groups, H, W] に再形成されて、形状が [B, num_groups, 1, 1, 1] である平均"
"と標準偏差によって標準化されます。最後に、出力変数は再び元の入力の形状 ( 上記の場"
"合は = [B, C, H, W] ) に再形成されます。"

#: nnabla.functions.group_normalization:23 of
msgid ""
"`Yuxin Wu, Kaiming He, Group Normalization. <https://arxiv.org/abs/1803.08494>`_"
msgstr ""
"`Yuxin Wu, Kaiming He, Group Normalization. <https://arxiv.org/abs/1803.08494>`_"

#: nnabla.functions.group_normalization:32 of
msgid ""
"A number of groups. The channel dim of 'x' must be integer multiple of "
"`num_groups`."
msgstr ""
"グループ数。チャネルの次元 ‘x’ は `num_groups` の整数倍でなければなりません。"

#: nnabla.functions.weight_standardization:1 of
msgid "Applies Weight Standardization over an input weight, which is defined as:"
msgstr ""
"入力の重みに、Weight Standardization を適用します。それは次のように定義されます。"

#: nnabla.functions.weight_standardization:3 of
msgid ""
"\\begin{eqnarray}   \\mu_{W_i} &=& \\frac{1}{I} \\sum_{j=1}^{I} W_{ij} \\\\   "
"\\sigma_{W_i} &=& \\sqrt{\\frac{1}{I} \\sum_{i=1}^{I} \\left(W_{ij} - "
"\\mu_{W_{i}}\\right)^2} \\\\   \\hat{W_{ij}} &=& \\frac{W_{ij} - \\mu_{W_i}}"
"{\\sigma_{W_i} + \\epsilon} \\\\   y &=& \\hat{W} \\ast x \\end{eqnarray}"
msgstr ""
"\\begin{eqnarray}   \\mu_{W_i} &=& \\frac{1}{I} \\sum_{j=1}^{I} W_{ij} \\\\   "
"\\sigma_{W_i} &=& \\sqrt{\\frac{1}{I} \\sum_{i=1}^{I} \\left(W_{ij} - "
"\\mu_{W_{i}}\\right)^2} \\\\   \\hat{W_{ij}} &=& \\frac{W_{ij} - \\mu_{W_i}}"
"{\\sigma_{W_i} + \\epsilon} \\\\   y &=& \\hat{W} \\ast x \\end{eqnarray}"

#: nnabla.functions.weight_standardization:13 of
msgid ""
"`Siyuan Qiao, Huiyu Wang, Chenxi Liu, Wei Shen, Alan Yuille, Weight "
"Standardization <https://arxiv.org/pdf/1903.10520v1.pdf>`_"
msgstr ""
"`Siyuan Qiao, Huiyu Wang, Chenxi Liu, Wei Shen, Alan Yuille, Weight "
"Standardization <https://arxiv.org/pdf/1903.10520v1.pdf>`_"

#: nnabla.functions.weight_standardization:16 of
msgid "A weight variable."
msgstr "重み変数。"

#: nnabla.functions.weight_standardization:18 of
msgid ""
"An axis for output channel. Default value is 0 which assumes the weights of "
"convolution."
msgstr ""
"出力チャネルに対する軸。convolution の重みを仮定して、デフォルト値は 0 です。"

#: nnabla.functions.weight_standardization:25 of
msgid ""
"Standardized output weight. * :obj:`~nnabla.Variable`: Mean (if "
"``output_stat=True`) * :obj:`~nnabla.Variable`: Std (if ``output_stat=True`)"
msgstr ""
"標準化された出力の重み。 * :obj:`~nnabla.Variable`: 平均 ( ``output_stat=True`` "
"の場合) * :obj:`~nnabla.Variable`: 標準偏差 ( ``output_stat=True`` の場合)"

#: ../../python/api/function.rst:100
msgid "Reduction"
msgstr "削減"

#: nnabla.functions.sum:1 of
msgid "Reduction along axes with sum operation."
msgstr "軸に沿った和を計算する関数。"

#: nnabla.functions.sum:5 of
msgid ""
"Axis or axes along which the sum is calculated. Passing the default value `None` "
"will reduce all dimensions."
msgstr ""
"軸、または合計が計算される対象軸。デフォルト値 `None` を渡すことで、すべての次元"
"を削減します。"

#: nnabla.functions.mean:8 nnabla.functions.prod:8 nnabla.functions.sum:8 of
msgid "Flag whether the reduced axes are kept as a dimension with 1 element."
msgstr "削減された軸が 1 つの要素をもつ次元として保持されているか否かのフラグ。"

#: nnabla.functions.mean:1 of
msgid "Reduction along axes with mean operation."
msgstr "軸に沿った平均を計算する関数。"

#: nnabla.functions.mean:5 of
msgid ""
"Axis or axes along which mean is calculated. Passing the default value `None` "
"will reduce all dimensions."
msgstr ""
"軸、または平均が計算される対応軸。デフォルト値 `None` を渡すことで、すべての次元"
"を削減します。"

#: nnabla.functions.max:1 of
msgid ""
"Reduce the input N-D array `x` along the given `axis` using the max operation. "
"The `axis` argument may be a single integer to reduce over one axis, a tuple of "
"integers to reduce over multiple axes, or ``None`` to reduce over all axes. If "
"`keepdims` is ``True``, the output will keep all reduced dimensions with size 1. "
"If `with_index` is True, result is a tuple ``(sorted, indices)`` or only "
"``indices`` if `only_index` is True. Setting `only_index` to True implies that "
"`with_index` is also True."
msgstr ""
"最大値演算を使って、指定された `axis` に従って入力 N-D 配列 `x` を削減します。 "
"`axis` の引数は、1 つの軸を削減する場合は単一整数、複数の軸を削減するため場合は整"
"数のタプル、もしくはすべての軸を削減する場合は ``None`` になります。 `keepdims` "
"が ``True`` の場合、出力はすべての削減次元を 1 とします。 `with_index` が True の"
"場合、結果はタプル ``(sorted, indices)`` 、または `only_index` が True の場合は単"
"に ``indices`` となります。`only_index` を True に設定すると、 `with_index` も "
"True になります。"

#: nnabla.functions.max:10 of
msgid ""
"import numpy as np\n"
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"\n"
"nn.set_auto_forward(True)\n"
"x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))\n"
"\n"
"maxval = F.max(x, axis=1)\n"
"assert np.allclose(maxval.d, np.max(x.d, axis=1))\n"
"\n"
"maxval, indices = F.max(x, axis=1, with_index=True)\n"
"assert np.allclose(maxval.d, np.max(x.d, axis=1))\n"
"assert np.all(indices.d == np.argmax(x.d, axis=1))\n"
"\n"
"indices = F.max(x, axis=1, only_index=True)\n"
"assert np.all(indices.d == np.argmax(x.d, axis=1))"
msgstr ""

#: nnabla.functions.max:31 of
msgid ""
"Axis or axes along which max is calculated. The default value `None` will reduce "
"all dimensions."
msgstr ""
"軸、または最大値の計算の対象軸。デフォルト値 `None` はすべての次元を削減します。"

#: nnabla.functions.max:34 nnabla.functions.min:34 of
msgid "Keep reduced axes as dimension with 1 element."
msgstr "削減された軸を 1 つの要素をもつ次元とします。"

#: nnabla.functions.max:36 of
msgid "Return tuple of max values and index."
msgstr "最大値とインデックスのタプルを返します。"

#: nnabla.functions.max:38 of
msgid "Return only the index of max values."
msgstr "最大値のインデックスのみを返します。"

#: nnabla.functions.min:1 of
msgid ""
"Reduce the input N-D array `x` along the given `axis` using the min operation. "
"The `axis` argument may be a single integer to reduce over one axis, a tuple of "
"integers to reduce over multiple axes, or ``None`` to reduce over all axes. If "
"`keepdims` is ``True``, the output will keep all reduced dimensions with size 1. "
"If `with_index` is True, result is a tuple ``(sorted, indices)`` or only "
"``indices`` if `only_index` is True. Setting `only_index` to True implies that "
"`with_index` is also True."
msgstr ""
"最小値演算を使って、指定された `axis` に従って入力 N-D 配列 `x` を削減します。 "
"`axis` の引数は、1 つの軸を削減する場合は単一整数、複数の軸を削減するため場合は整"
"数のタプル、もしくはすべての軸を削減する場合は ``None`` になります。 `keepdims` "
"が ``True`` の場合、出力はすべての削減次元を 1 とします。 `with_index` が True の"
"場合、結果はタプル ``(sorted, indices)`` 、または `only_index` が True の場合は単"
"に ``indices`` となります。 `only_index` を True に設定すると、 `with_index` も "
"True になります。"

#: nnabla.functions.min:10 of
msgid ""
"import numpy as np\n"
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"\n"
"nn.set_auto_forward(True)\n"
"x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))\n"
"\n"
"minval = F.min(x, axis=1)\n"
"assert np.allclose(minval.d, np.min(x.d, axis=1))\n"
"\n"
"minval, indices = F.min(x, axis=1, with_index=True)\n"
"assert np.allclose(minval.d, np.min(x.d, axis=1))\n"
"assert np.all(indices.d == np.argmin(x.d, axis=1))\n"
"\n"
"indices = F.min(x, axis=1, only_index=True)\n"
"assert np.all(indices.d == np.argmin(x.d, axis=1))"
msgstr ""

#: nnabla.functions.min:31 of
msgid ""
"Axis or axes along which min is calculated. The default value `None` will reduce "
"all dimensions."
msgstr ""
"軸、または最小値の計算対象の軸。デフォルト値 `None` はすべての次元を削減します。"

#: nnabla.functions.min:36 of
msgid "Return tuple of min values and index."
msgstr "最小値とインデックスのタプルを返します。"

#: nnabla.functions.min:38 of
msgid "Return only the index of min values."
msgstr "最小値のインデックスのみを返します。"

#: nnabla.functions.prod:1 of
msgid "Reduction along axes with product operation."
msgstr "軸に沿った積を計算する関数。"

#: nnabla.functions.prod:5 of
msgid ""
"Axis or axes along which product is calculated. Passing the default value `None` "
"will reduce all dimensions."
msgstr ""
"軸、または最小値の計算対象の軸。デフォルト値 `None` はすべての次元を削減します。"

#: nnabla.functions.prod:14 of
msgid "Backward computation is not accurate in a zero value input."
msgstr "backward の計算はゼロ値の入力では正確に行われません。"

#: nnabla.functions.reduce_sum:1 of
msgid "Reduction along an axis with sum operation."
msgstr "軸に沿った和を計算する関数。"

#: nnabla.functions.reduce_sum:3 of
msgid "This is deprecated. Use ``sum`` instead."
msgstr "これは推奨しません。代わりに ``sum`` を使用してください。"

#: nnabla.functions.reduce_mean:1 of
msgid "Reduction by mean along an axis."
msgstr "軸に沿った平均を計算する関数。"

#: nnabla.functions.reduce_mean:3 of
msgid "This is deprecated. Use ``mean`` instead."
msgstr "これは推奨されません。代わりに ``mean`` を使用してください。"

#: ../../python/api/function.rst:112
msgid "Arithmetic"
msgstr "計算"

#: nnabla.functions.add2:1 nnabla.functions.add_n:1 of
msgid "Element-wise addition."
msgstr "要素ごとの加算。"

#: nnabla.functions.add2:3 of
msgid "y_i = x^{(0)}_i + x^{(1)}_i"
msgstr "y_i = x^{(0)}_i + x^{(1)}_i"

#: nnabla.functions.add2:10 of
msgid ""
"The output array is shared with the 1st input array if True. [default=``False``]"
msgstr ""
"True の場合、出力配列は、第一入力配列と共有されます。[ デフォルト = ``False`` ]"

#: nnabla.functions.add_n:3 of
msgid "y_i = x^{(0)}_i + . . . + x^{(n-1)}_i"
msgstr ""

#: nnabla.functions.add_n:6 nnabla.functions.mul_n:6 of
msgid "N-D arrays [variadic]"
msgstr "N-D 配列。 [variadic]"

#: nnabla.functions.sub2:1 of
msgid "Element-wise subtraction."
msgstr "要素ごとの減算。"

#: nnabla.functions.sub2:3 of
msgid "y_i = x^{(0)}_i - x^{(1)}_i"
msgstr "y_i = x^{(0)}_i - x^{(1)}_i"

#: nnabla.functions.mul2:1 nnabla.functions.mul_n:1 of
msgid "Element-wise multiplication."
msgstr "要素ごとの乗算。"

#: nnabla.functions.mul2:3 of
msgid "y_i = x^{(0)}_i x^{(1)}_i"
msgstr "y_i = x^{(0)}_i x^{(1)}_i"

#: nnabla.functions.mul_n:3 of
msgid "y_i = x^{(0)}_i . . . x^{(n-1)}_i"
msgstr ""

#: nnabla.functions.div2:1 of
msgid "Element-wise division."
msgstr "要素ごとの除算。"

#: nnabla.functions.div2:3 of
msgid "y_i = \\frac{x^{(0)}_i} {x^{(1)}_i}"
msgstr "y_i = \\frac{x^{(0)}_i} {x^{(1)}_i}"

#: nnabla.functions.pow2:1 of
msgid "Element-wise power function."
msgstr "要素ごとのべき乗関数。"

#: nnabla.functions.pow2:3 of
msgid "y_i = {(x^{(0)}_i)} ^ {x^{(1)}_i}"
msgstr "y_i = {(x^{(0)}_i)} ^ {x^{(1)}_i}"

#: nnabla.functions.add_scalar:1 of
msgid "Element-wise scalar addition."
msgstr "要素ごとのスカラ加算。"

#: nnabla.functions.add_scalar:3 of
msgid "y_i = x_i + v"
msgstr "y_i = x_i + v"

#: nnabla.functions.abs:6 nnabla.functions.add_scalar:7 nnabla.functions.ceil:14
#: nnabla.functions.equal_scalar:9 nnabla.functions.exp:6 nnabla.functions.floor:14
#: nnabla.functions.greater_equal_scalar:10 nnabla.functions.greater_scalar:10
#: nnabla.functions.isinf:3 nnabla.functions.isnan:3
#: nnabla.functions.less_equal_scalar:11 nnabla.functions.less_scalar:10
#: nnabla.functions.log:6 nnabla.functions.logical_and_scalar:9
#: nnabla.functions.logical_not:9 nnabla.functions.logical_or_scalar:8
#: nnabla.functions.logical_xor_scalar:10 nnabla.functions.maximum_scalar:6
#: nnabla.functions.minimum_scalar:6 nnabla.functions.mul_scalar:6
#: nnabla.functions.not_equal_scalar:9 nnabla.functions.pow_scalar:6
#: nnabla.functions.r_div_scalar:6 nnabla.functions.r_pow_scalar:6
#: nnabla.functions.r_sub_scalar:6 nnabla.functions.reset_inf:3
#: nnabla.functions.reset_nan:3 nnabla.functions.round:14 of
msgid "Input variable"
msgstr "入力変数"

#: nnabla.functions.add_scalar:9 nnabla.functions.equal_scalar:11
#: nnabla.functions.greater_equal_scalar:12 nnabla.functions.greater_scalar:12
#: nnabla.functions.less_equal_scalar:13 nnabla.functions.less_scalar:12
#: nnabla.functions.mul_scalar:8 nnabla.functions.not_equal_scalar:11
#: nnabla.functions.pow_scalar:8 nnabla.functions.r_div_scalar:8
#: nnabla.functions.r_pow_scalar:8 nnabla.functions.r_sub_scalar:8 of
msgid "Value of the scalar [default=``1``]"
msgstr "スカラ値 [ デフォルト = ``1`` ]"

#: nnabla.functions.mul_scalar:1 of
msgid "Element-wise scalar multiplication."
msgstr "要素ごとのスカラ乗算。"

#: nnabla.functions.mul_scalar:3 of
msgid "y_i = v x_i"
msgstr "y_i = v x_i"

#: nnabla.functions.pow_scalar:1 nnabla.functions.r_pow_scalar:1 of
msgid "Element-wise scalar power function."
msgstr "要素ごとのスカラべき乗関数。"

#: nnabla.functions.pow_scalar:3 of
msgid "y_i = (x_i) ^ v"
msgstr "y_i = (x_i) ^ v"

#: nnabla.functions.r_sub_scalar:1 of
msgid "Element-wise scalar subtraction."
msgstr "要素ごとのスカラ減算。"

#: nnabla.functions.r_sub_scalar:3 of
msgid "y_i = v - x_i"
msgstr "y_i = v - x_i"

#: nnabla.functions.r_div_scalar:1 of
msgid "Element-wise scalar division."
msgstr "要素ごとのスカラ除算。"

#: nnabla.functions.r_div_scalar:3 of
msgid "y_i = \\frac{v}{x_i}"
msgstr "y_i = \\frac{v}{x_i}"

#: nnabla.functions.r_pow_scalar:3 of
msgid "y_i = v ^ {x_i}"
msgstr "y_i = v ^ {x_i}"

#: ../../python/api/function.rst:129
msgid "Logical"
msgstr "論理"

#: nnabla.functions.equal:1 of
msgid "Element wise 'equal'"
msgstr "要素ごとの ‘equal’"

#: nnabla.functions.equal:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1 & (x^{(0)}_i = x^{(1)}_i) \\\\     "
"0 & otherwise \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1 & (x^{(0)}_i = x^{(1)}_i) \\\\     "
"0 & otherwise \\end{cases}."

#: nnabla.functions.equal:14 nnabla.functions.greater:15
#: nnabla.functions.greater_equal:15 nnabla.functions.less:16
#: nnabla.functions.less_equal:16 nnabla.functions.logical_and:14
#: nnabla.functions.logical_and_scalar:11 nnabla.functions.logical_or:13
#: nnabla.functions.logical_or_scalar:10 nnabla.functions.logical_xor:15
#: nnabla.functions.logical_xor_scalar:12 nnabla.functions.not_equal:14 of
msgid "No Description"
msgstr "記述なし"

#: nnabla.functions.equal_scalar:1 of
msgid "Element wise 'equal' with a scalar"
msgstr "要素ごとのスカラの ‘equal’"

#: nnabla.functions.equal_scalar:3 of
msgid ""
"f(x_i,v) = \\begin{cases}     1 & (x_i = v) \\\\     0 & otherwise \\end{cases}."
msgstr ""
"f(x_i,v) = \\begin{cases}     1 & (x_i = v) \\\\     0 & otherwise \\end{cases}."

#: nnabla.functions.greater:1 nnabla.functions.greater_equal:1
#: nnabla.functions.less:1 nnabla.functions.less_equal:1 of
msgid "Element wise comparison. The :math:`i^{th}` element of the output is:"
msgstr "要素ごとの比較。出力の :math:`i` 番目の要素は以下の通りです。"

#: nnabla.functions.greater:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i > x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i \\leq x^{(1)}_i) \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i > x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i \\leq x^{(1)}_i) \\end{cases}."

#: nnabla.functions.greater_equal:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i \\geq x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i < x^{(1)}_i) \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i \\geq x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i < x^{(1)}_i) \\end{cases}."

#: nnabla.functions.greater_equal_scalar:1 nnabla.functions.greater_scalar:1
#: nnabla.functions.less_equal_scalar:1 nnabla.functions.less_scalar:1 of
msgid ""
"Element wise comparison with a scalar. The :math:`i^{th}` element of the output "
"is:"
msgstr "要素ごとのスカラの比較。出力の :math:`i` 番目の要素は以下の通りです。"

#: nnabla.functions.greater_equal_scalar:3 of
msgid ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i \\geq v \\\\     0 & (x^{(0)}"
"_i < v \\end{cases}."
msgstr ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i \\geq v \\\\     0 & (x^{(0)}"
"_i < v \\end{cases}."

#: nnabla.functions.greater_scalar:3 of
msgid ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i > v \\\\     0 & (x^{(0)}_i "
"\\leq v \\end{cases}."
msgstr ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i > v \\\\     0 & (x^{(0)}_i "
"\\leq v \\end{cases}."

#: nnabla.functions.less:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i < x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i \\geq x^{(1)}_i) \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i < x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i \\geq x^{(1)}_i) \\end{cases}."

#: nnabla.functions.less_equal:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i \\leq x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i > x^{(1)}_i) \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1  & (x^{(0)}_i \\leq x^{(1)}_i) \\"
"\\     0 & (x^{(0)}_i > x^{(1)}_i) \\end{cases}."

#: nnabla.functions.less_equal_scalar:3 of
msgid ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i \\leq v) \\\\     0 & "
"(x^{(0)}_i > v) \\end{cases}."
msgstr ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i \\leq v) \\\\     0 & "
"(x^{(0)}_i > v) \\end{cases}."

#: nnabla.functions.less_scalar:3 of
msgid ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i < v) \\\\     0 & (x^{(0)}_i "
"\\geq v) \\end{cases}."
msgstr ""
"f(x^{(0)}_i,v) = \\begin{cases}     1  & (x^{(0)}_i < v) \\\\     0 & (x^{(0)}_i "
"\\geq v) \\end{cases}."

#: nnabla.functions.logical_and:1 of
msgid "Elementwise logical AND."
msgstr "要素ごとの論理 AND 。"

#: nnabla.functions.logical_and:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1 & (x^{(0)}_i \\neq 0 \\;\\&\\; "
"x^{(1)}_i \\neq 0) \\\\     0 & otherwise \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1 & (x^{(0)}_i \\neq 0 \\;\\&\\; "
"x^{(1)}_i \\neq 0) \\\\     0 & otherwise \\end{cases}."

#: nnabla.functions.logical_and_scalar:1 of
msgid "Elementwise logical AND with scalar."
msgstr "要素ごとのスカラの論理 AND 。"

#: nnabla.functions.logical_and_scalar:3 of
msgid ""
"f(x_i,v) = \\begin{cases}     1 & (x_i \\neq 0 \\;\\&\\; v \\neq 0) \\\\     0 & "
"otherwise \\end{cases}."
msgstr ""
"f(x_i,v) = \\begin{cases}     1 & (x_i \\neq 0 \\;\\&\\; v \\neq 0) \\\\     0 & "
"otherwise \\end{cases}."

#: nnabla.functions.logical_not:1 of
msgid "Element-wise logical NOT operation"
msgstr "要素ごとの論理 NOT 演算"

#: nnabla.functions.logical_not:3 of
msgid ""
"f(x_i) = \\begin{cases}     1 & (x_i = 0) \\\\     0 & otherwise \\end{cases}."
msgstr ""
"f(x_i) = \\begin{cases}     1 & (x_i = 0) \\\\     0 & otherwise \\end{cases}."

#: nnabla.functions.logical_or:1 of
msgid "Elementwise logical OR."
msgstr "要素ごとの論理 OR 。"

#: nnabla.functions.logical_or:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     0 & (x^{(0)}_i = 0 \\;\\&\\; x^{(1)}"
"_i = 0) \\\\     1 & otherwise \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     0 & (x^{(0)}_i = 0 \\;\\&\\; x^{(1)}"
"_i = 0) \\\\     1 & otherwise \\end{cases}."

#: nnabla.functions.logical_or_scalar:1 of
msgid "Elementwise logical OR with scalar."
msgstr "要素ごとのスカラの論理 OR 。"

#: nnabla.functions.logical_or_scalar:3 of
msgid ""
"f(x_i,v) = \\begin{cases}     0 & (x_i = 0 \\;\\&\\; v = 0) \\\\     1 & "
"otherwise \\end{cases}."
msgstr ""
"f(x_i,v) = \\begin{cases}     0 & (x_i = 0 \\;\\&\\; v = 0) \\\\     1 & "
"otherwise \\end{cases}."

#: nnabla.functions.logical_xor:1 of
msgid "Elementwise logical XOR."
msgstr "要素ごとの論理 XOR 。"

#: nnabla.functions.logical_xor:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1 & (x^{(0)}_i = 0 \\;\\&\\; x^{(1)}"
"_i = 0) \\\\     1 & (x^{(0)}_i \\neq 0 \\;\\&\\; x^{(1)}_i \\neq 0) \\\\     0 "
"& otherwise \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     1 & (x^{(0)}_i = 0 \\;\\&\\; x^{(1)}"
"_i = 0) \\\\     1 & (x^{(0)}_i \\neq 0 \\;\\&\\; x^{(1)}_i \\neq 0) \\\\     0 "
"& otherwise \\end{cases}."

#: nnabla.functions.logical_xor_scalar:1 of
msgid "Elementwise logical XOR with scalar."
msgstr "要素ごとのスカラの論理 XOR 。"

#: nnabla.functions.logical_xor_scalar:3 of
msgid ""
"f(x_i,v) = \\begin{cases}     1 & (x_i = 0 \\;\\&\\; v = 0) \\\\     1 & (x_i "
"\\neq 0 \\;\\&\\; v \\neq 0) \\\\     0 & otherwise \\end{cases}."
msgstr ""
"f(x_i,v) = \\begin{cases}     1 & (x_i = 0 \\;\\&\\; v = 0) \\\\     1 & (x_i "
"\\neq 0 \\;\\&\\; v \\neq 0) \\\\     0 & otherwise \\end{cases}."

#: nnabla.functions.not_equal:1 of
msgid "Element wise 'not equal'"
msgstr "要素ごとの ‘not equal’"

#: nnabla.functions.not_equal:3 of
msgid ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     0 & (x^{(0)}_i = x^{(1)}_i) \\\\     "
"1 & otherwise \\end{cases}."
msgstr ""
"f(x^{(0)}_i,x^{(1)}_i) = \\begin{cases}     0 & (x^{(0)}_i = x^{(1)}_i) \\\\     "
"1 & otherwise \\end{cases}."

#: nnabla.functions.not_equal_scalar:1 of
msgid "Element wise 'not equal' with a scalar"
msgstr "要素ごとのスカラの ‘not equal’"

#: nnabla.functions.not_equal_scalar:3 of
msgid ""
"f(x_i,v) = \\begin{cases}     0 & (x_i = v) \\\\     1 & otherwise \\end{cases}."
msgstr ""
"f(x_i,v) = \\begin{cases}     0 & (x_i = v) \\\\     1 & otherwise \\end{cases}."

#: nnabla.functions.sign:1 of
msgid "Element-wise sign function."
msgstr "要素ごとの sign 関数。"

#: nnabla.functions.sign:3 of
msgid "In the forward pass, it is defined as"
msgstr "forward パスでは、次のように定義されます。"

#: nnabla.functions.sign:5 of
msgid ""
"f(x) = \\begin{cases}     1  & (x > 0) \\\\     -1 & (x < 0) \\\\     \\alpha & "
"(x = 0) \\end{cases}."
msgstr ""
"f(x) = \\begin{cases}     1  & (x > 0) \\\\     -1 & (x < 0) \\\\     \\alpha & "
"(x = 0) \\end{cases}."

#: nnabla.functions.sign:13 of
msgid "In the backward pass, it is defined as"
msgstr "backward パスでは、次のように定義されます。"

#: nnabla.functions.sign:15 of
msgid "\\frac{\\partial f(x)}{\\partial x} = 1,"
msgstr "\\frac{\\partial f(x)}{\\partial x} = 1,"

#: nnabla.functions.sign:18 of
msgid ""
"or in other words, it behaves as the identity function for the gradient in the "
"backward pass."
msgstr "つまり、backward パスでは勾配に対して identity 関数として動作します。"

#: nnabla.functions.sign:22 of
msgid "Value in case of :math:`x = 0`. [default=``1.0``]"
msgstr ":math:`x = 0` の場合の値。 [ デフォルト = ``1.0`` ]"

#: nnabla.functions.minimum2:1 of
msgid "Element-wise minimum."
msgstr "要素ごとの最小値。"

#: nnabla.functions.minimum2:3 of
msgid "y_i = \\min(x^{(0)}_i, x^{(1)}_i)"
msgstr "y_i = \\min(x^{(0)}_i, x^{(1)}_i)"

#: nnabla.functions.minimum2:11 of
msgid "N-D array of min value"
msgstr "最小値の N-D 配列"

#: nnabla.functions.maximum2:1 of
msgid "Element-wise maximum."
msgstr "要素ごとの最大値。"

#: nnabla.functions.maximum2:3 of
msgid "y_i = \\max(x^{(0)}_i, x^{(1)}_i)"
msgstr "y_i = \\max(x^{(0)}_i, x^{(1)}_i)"

#: nnabla.functions.maximum2:11 of
msgid "N-D array of max value"
msgstr "最大値の N-D 配列"

#: nnabla.functions.minimum_scalar:1 of
msgid "Element-wise scalar minimum."
msgstr "要素ごとのスカラ最小値。"

#: nnabla.functions.minimum_scalar:3 of
msgid "y_i = \\min(x_i, v)"
msgstr "y_i = \\min(x_i, v)"

#: nnabla.functions.maximum_scalar:8 nnabla.functions.minimum_scalar:8 of
msgid "Value of the scalar [default=``1.0``]"
msgstr "スカラ値 [ デフォルト = ``1.0`` ]"

#: nnabla.functions.maximum_scalar:1 of
msgid "Element-wise scalar maximum."
msgstr "要素ごとのスカラ最大値。"

#: nnabla.functions.maximum_scalar:3 of
msgid "y_i = \\max (x_i, v)"
msgstr "y_i = \\max (x_i, v)"

#: nnabla.functions.isnan:1 of
msgid "Test element-wise for NaN and return a ``0/1`` array."
msgstr "要素ごとに NaN のテストを行い、 ``0/1`` 配列を返します。"

#: nnabla.functions.isinf:1 of
msgid "Test element-wise for ``inf/-inf`` and return a ``0/1`` array."
msgstr "要素ごとに ``inf/-inf`` のテストを行い、 ``0/1`` 配列を返します。"

#: nnabla.functions.reset_nan:1 of
msgid "Replace NaNs with a scalar value specified by ``val``."
msgstr "NaNs を ``val`` で指定されたスカラ値に置換します。"

#: nnabla.functions.reset_inf:5 nnabla.functions.reset_nan:5 of
msgid "Value of the scalar [default=``0``]"
msgstr "スカラ値 [ デフォルト = ``0`` ]"

#: nnabla.functions.reset_inf:1 of
msgid "Replace ``-inf/inf`` with a scalar value specified by ``val``."
msgstr "``-inf/inf`` を ``val`` で指定されたスカラ値に置換します。"

#: nnabla.functions.where:1 of
msgid ""
"Return elements, either from ``x_true`` or ``x_false``, depending on "
"``condition``."
msgstr ""
"``condition`` によって、 ``x_true`` または ``x_false`` からの要素を返します。"

#: nnabla.functions.where:3 of
msgid ""
"If rank of ``condition`` is higher than those of ``x_true`` and ``x_false``, the "
"first dimensions of ``x_true`` and ``x_false`` must match the dimensions of "
"``condition``."
msgstr ""
"``condition`` のランクが ``x_true`` および ``x_false`` のランクより高い場合は、 "
"``x_true`` および ``x_false`` の最初の次元は ``condition`` の次元と一致する必要が"
"あります。"

#: nnabla.functions.fft:18 nnabla.functions.interpolate:14
#: nnabla.functions.one_hot:3 nnabla.functions.where:5 of
msgid "Example:"
msgstr "例 :"

#: nnabla.functions.where:7 of
msgid ""
"import numpy as np\n"
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"\n"
"a = nn.Variable.from_numpy_array(np.random.rand(2, 3))\n"
"x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))\n"
"y = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))\n"
"z = F.where(F.greater_scalar(a, 0.5), x, y)\n"
"z.forward()\n"
"\n"
"# Numpy equivalent\n"
"z_numpy = np.where(a.d > 0.5, x.d, y.d)\n"
"assert np.allclose(z_numpy, z.d)"
msgstr ""

#: nnabla.functions.where:23 of
msgid ""
"N-d array. For all i, when ``condition[i] == true``, yield ``x_true[i]``, "
"otherwise ``x_false[i]``."
msgstr ""
"N-d 配列。すべての i において、 ``condition[i] == true`` の場合は、 "
"``x_true[i]`` となります。それ以外の場合は、 ``x_false[i]`` となります。"

#: nnabla.functions.where:25 nnabla.functions.where:27 of
msgid "N-d array with higher or equal rank to ``condition``."
msgstr "``condition`` のランク以上の N-d 配列。"

#: nnabla.functions.where:30 of
msgid "N-D array with the same shape as condition"
msgstr "condition と同じ形状をもつ N-D 配列"

#: ../../python/api/function.rst:163
msgid "Math"
msgstr "数学"

#: nnabla.functions.constant:1 of
msgid "Generate a constant-valued array."
msgstr "定数値配列を生成します。"

#: nnabla.functions.constant:3 of
msgid "Constant value. [default=``0``]"
msgstr "一定数値。 [ デフォルト = ``0`` ]"

#: nnabla.functions.constant:6 of
msgid "Shape of the output array. [default=``[]``]"
msgstr "出力配列の形状。 [ デフォルト = ``[]`` ]"

#: nnabla.functions.constant:10 of
msgid "N-D array where all values are the specified constant."
msgstr "すべての値が指定された定数である N-D 配列。"

#: nnabla.functions.arange:1 of
msgid ""
"Generate a range of values within the half-open interval ``[start, stop)`` (the "
"interval including start but excluding stop) with `step` increments."
msgstr ""
"半開区間 ``[start, stop]`` (始まりを含み、終わりは含まない区間) 内の値の範囲を "
"`step` 増分で生成します。"

#: nnabla.functions.arange:5 of
msgid "Start value."
msgstr "始まりの値。"

#: nnabla.functions.arange:7 of
msgid "End value."
msgstr "終わりの値。"

#: nnabla.functions.arange:9 of
msgid "Step value. [default=``1``]"
msgstr "ステップの値。 [ デフォルト = ``1`` ]"

#: nnabla.functions.arange:13 of
msgid "1-D array with the generated values."
msgstr "生成された値をもつ 1-D 配列。"

#: nnabla.functions.abs:1 of
msgid "Element-wise absolute value function."
msgstr "要素ごとの絶対値関数。"

#: nnabla.functions.abs:3 of
msgid "y_i = |x_i|"
msgstr "y_i = |x_i|"

#: nnabla.functions.abs:9 of
msgid "Element-wise absolute variable"
msgstr "要素ごとの絶対値"

#: nnabla.functions.exp:1 of
msgid "Element-wise natural exponential function."
msgstr "要素ごとの自然指数関数。"

#: nnabla.functions.exp:3 of
msgid "y_i = \\exp(x_i)."
msgstr "y_i = \\exp(x_i)."

#: nnabla.functions.exp:9 of
msgid "Element-wise exp variable"
msgstr "要素ごとの指数変数"

#: nnabla.functions.log:1 of
msgid "Element-wise natural logarithm function."
msgstr "要素ごとの log (自然対数) 関数。"

#: nnabla.functions.log:3 of
msgid "y_i = \\ln(x_i)."
msgstr "y_i = \\ln(x_i)."

#: nnabla.functions.log:9 of
msgid "Element-wise log variable"
msgstr "要素ごとのlog (対数) 変数"

#: nnabla.functions.round:1 of
msgid "Element-wise round function."
msgstr "要素ごとの round (端数処理) 関数。"

#: nnabla.functions.round:3 of
msgid ""
"In the forward pass, this function simply computes `round` to the nearest "
"integer value."
msgstr ""
"forward パスでは、この関数は単に最も近い整数値に `round` を行う計算を行います。"

#: nnabla.functions.round:5 of
msgid "y_i = round(x_i)."
msgstr "y_i = round(x_i)."

#: nnabla.functions.ceil:8 nnabla.functions.floor:8 nnabla.functions.round:8 of
msgid ""
"In the backward pass, the simple Straight-Through Estimator (STE) is applied,"
msgstr ""
"backward パスでは、以下の通り、単純な Straight-Through Estimator (STE) が適用され"
"ます。"

#: nnabla.functions.ceil:10 nnabla.functions.floor:10 nnabla.functions.round:10 of
msgid "\\frac{\\partial y_i}{\\partial x_i} = 1."
msgstr "\\frac{\\partial y_i}{\\partial x_i} = 1."

#: nnabla.functions.ceil:1 of
msgid "Element-wise ceil function."
msgstr "要素ごとの ceil (切り上げ) 関数。"

#: nnabla.functions.ceil:3 of
msgid ""
"In the forward pass, this function simply returns the smallest integer which is "
"not less than the input."
msgstr "forward パスでは、この関数は単に入力以上の最小の整数を返します。"

#: nnabla.functions.ceil:5 of
msgid "y_i = ceil(x_i)."
msgstr "y_i = ceil(x_i)."

#: nnabla.functions.floor:1 of
msgid "Element-wise floor function."
msgstr "要素ごとの floor (切り捨て) 関数。"

#: nnabla.functions.floor:3 of
msgid ""
"In the forward pass, this function simply returns the largest integer which is "
"not greater than the input."
msgstr "forward パスでは、この関数は単に入力以下の最大の整数を返します。"

#: nnabla.functions.floor:5 of
msgid "y_i = floor(x_i)."
msgstr "y_i = floor(x_i)."

#: nnabla.functions.identity:1 of
msgid "Identity function."
msgstr "恒等関数。"

#: nnabla.functions.identity:3 of
msgid "y = x"
msgstr "y = x"

#: nnabla.functions.matrix_diag:1 of
msgid ""
"Returns an array where the last two dimensions consist of the diagonal matrix."
msgstr "最後の2 次元が対角行列になる配列を返します。"

#: nnabla.functions.matrix_diag:3 nnabla.functions.matrix_diag_part:7 of
msgid "N-D array with shape (:math:`M_0 \\times \\ldots \\times M_N`)."
msgstr "(:math:`M_0 \\times \\ldots \\times M_N`) の形状をもつ N-D 配列。"

#: nnabla.functions.matrix_diag:6 nnabla.functions.matrix_diag_part:4 of
msgid "N-D array with shape (:math:`M_0 \\times \\ldots \\times M_N \\times M_N`)."
msgstr ""
"(:math:`M_0 \\times \\ldots \\times M_N \\times M_N`) の形状をもつ N-D 配列。"

#: nnabla.functions.matrix_diag_part:1 of
msgid ""
"Returns an array in which the values of the last dimension consist of the "
"diagonal elements of the last two dimensions of an input array."
msgstr "最後の次元の値が入力配列の最後の 2 次元の対角要素からなる配列を返します。"

#: nnabla.functions.batch_matmul:1 of
msgid "Batch matrix multiplication."
msgstr "バッチの行列乗算。"

#: nnabla.functions.batch_matmul:3 of
msgid ""
"Two of batchs of matrices are multiplied for each sample in a batch. A batch of "
"matrices is composed as [..., P, Q] where the last two dimensions compose matrix "
"dimensions, and the first dimensions up to the third last dimension are "
"considered as batch samples."
msgstr ""
"バッチの各サンプルにおいて 2 つの行列のバッチの乗算が行われます。行列のバッチは "
"[…, P, Q] のように構成され、最後の 2 次元が行列次元を構成し、第 1 次元から第 3 次"
"元までをバッチサンプルと見なします。"

#: nnabla.functions.batch_matmul:5 of
msgid ""
"N-D array with >= 2-dim. The last two dimensions will be treated as a matrix."
msgstr "2 次元以上の N-D 配列。最後の 2 次元は行列として扱われます。"

#: nnabla.functions.batch_matmul:7 of
msgid ""
"N-D array with >= 2-dim. The last two dimensions will be treated as a matrix. "
"The product of the size of 0-th dimension through the size of the third last "
"dimension must be same as that of the input ``a``."
msgstr ""
"2 次元以上の N-D 配列。最後の2 次元は行列として扱われます。第 0 次元のサイズから"
"最後から 3 番目までの次元のサイズの積は入力 ``a`` の積と同じでなくてはなりませ"
"ん。"

#: nnabla.functions.batch_matmul:9 of
msgid ""
"Transpose the last two axes of ``a`` in matrix multiplication. "
"[default=``False``]"
msgstr ""
"行列乗算で ``a`` の最後の 2 つの軸を入れ替えます。 [ デフォルト = ``False`` ]"

#: nnabla.functions.batch_matmul:12 of
msgid ""
"Transpose the last two axes of ``b`` in matrix multiplication. "
"[default=``False``]"
msgstr ""
"行列の掛け算で ``b`` の最後の 2 つの軸を入れ替えます。 [ デフォルト = ``False`` ]"

#: nnabla.functions.batch_matmul:16 of
msgid ""
"Output of sample-wise matrix multiplication in a batch. When ``a`` is of a shape "
"of [N, P, Q], ``b`` is of a shape of [N, Q, R], and transpose options are all "
"False, the output will be a shape of [N, P, R]."
msgstr ""
"バッチにおけるサンプルごとの行列乗算の出力。 ``a`` は [N, P, Q] の形状であり、 "
"``b`` は [N, Q, R] の形状であり、transpose オプションがすべて False の場合は、出"
"力は [N, P, R] の形状になります。"

#: nnabla.functions.sin:1 of
msgid "Element-wise sine (sin) function."
msgstr "要素ごとの sin (正弦) 関数。"

#: nnabla.functions.sin:3 of
msgid "y_i = \\sin (x_i)"
msgstr "y_i = \\sin (x_i)"

#: nnabla.functions.cos:1 of
msgid "Element-wise cosine (cos) function."
msgstr "要素ごとの cos (余弦) 関数。"

#: nnabla.functions.cos:3 of
msgid "y_i = \\cos (x_i)"
msgstr "y_i = \\cos (x_i)"

#: nnabla.functions.tan:1 of
msgid "Element-wise tangent (tan) function."
msgstr "要素ごとの正接 (tan) 関数。"

#: nnabla.functions.tan:3 of
msgid "y_i = \\tan (x_i)"
msgstr "y_i = \\tan (x_i)"

#: nnabla.functions.sinh:1 of
msgid "Element-wise hyperbolic sine (sinh) function."
msgstr "要素ごとの双曲正弦 (sinh) 関数。"

#: nnabla.functions.sinh:3 of
msgid "y_i = \\sinh (x_i)"
msgstr "y_i = \\sinh (x_i)"

#: nnabla.functions.cosh:1 of
msgid "Element-wise hyperbolic cosine (cosh) function."
msgstr "要素ごとの cosh (双曲余弦) 関数。"

#: nnabla.functions.cosh:3 of
msgid "y_i = \\cosh (x_i)"
msgstr "y_i = \\cosh (x_i)"

#: nnabla.functions.asin:1 of
msgid "Element-wise arcsine (asin) function."
msgstr "要素ごとの逆正弦 (asin) 関数。"

#: nnabla.functions.asin:3 of
msgid "y_i = \\arcsin (x_i)"
msgstr "y_i = \\arcsin (x_i)"

#: nnabla.functions.acos:1 of
msgid "Element-wise arccosine (acos) function."
msgstr "要素ごとの acos (逆余弦) 関数。"

#: nnabla.functions.acos:3 of
msgid "y_i = \\arccos (x_i)"
msgstr "y_i = \\arccos (x_i)"

#: nnabla.functions.atan:1 of
msgid "Element-wise arctangent (atan) function."
msgstr "要素ごとの atan (逆正接) 関数。"

#: nnabla.functions.atan:3 of
msgid "y_i = \\arctan (x_i)"
msgstr "y_i = \\arctan (x_i)"

#: nnabla.functions.atan2:1 of
msgid "Element-wise arctangent (atan) function with 2 input variables."
msgstr "2 つの入力変数をもつ、要素ごとの atan (逆正接) 関数。"

#: nnabla.functions.atan2:3 of
msgid "y_i = \\arctan2 (x_{i1}, x_{i2})"
msgstr "y_i = \\arctan2 (x_{i1}, x_{i2})"

#: nnabla.functions.atan2:11 of
msgid "N-D array with the same shape as input variables"
msgstr "入力変数と同じ形状をもつ N-D 配列"

#: nnabla.functions.asinh:1 of
msgid "Element-wise hyperbolic arcsine (asinh) function."
msgstr "要素ごとの asinh (逆双曲線正弦) 関数。"

#: nnabla.functions.asinh:3 of
msgid "y_i = \\text{arcsinh} (x_i)"
msgstr "y_i = \\text{arcsinh} (x_i)"

#: nnabla.functions.acosh:1 of
msgid "Element-wise hyperbolic arccosine (acosh) function."
msgstr "要素ごとの逆双曲線余弦 (acosh) 関数。"

#: nnabla.functions.acosh:3 of
msgid "y_i = \\text{arccosh} (x_i)"
msgstr "y_i = \\text{arccosh} (x_i)"

#: nnabla.functions.atanh:1 of
msgid "Element-wise hyperbolic arctangent (atanh) function."
msgstr "要素ごとの atanh (逆双曲線正接) 関数。"

#: nnabla.functions.atanh:3 of
msgid "y_i = \\text{arctanh} (x_i)"
msgstr "y_i = \\text{arctanh} (x_i)"

#: ../../python/api/function.rst:193
msgid "Array Manipulation"
msgstr "配列操作"

#: nnabla.functions.concatenate:1 of
msgid "Concatenate a variable number of input arrays along the specified axis."
msgstr "指定された軸に沿って、可変長個数の入力配列を連結します。"

#: nnabla.functions.concatenate:3 of
msgid "N-D arrays. [variadic]"
msgstr "N-D 配列。 [variadic]"

#: nnabla.functions.concatenate:6 of
msgid "Axis [default=``len(x[0].shape) - 1``]"
msgstr "軸 [ デフォルト = ``len(x[0].shape) - 1`` ]"

#: nnabla.functions.concatenate:10 of
msgid "Concatenate variable"
msgstr "連結する変数"

#: nnabla.functions.split:1 of
msgid "Split arrays at the specified axis."
msgstr "指定された軸における配列を分割します。"

#: nnabla.functions.split:3 of
msgid ""
"It returns a number corresponding the size of the given axis (i.e ``x."
"shape[axis]``) of :obj:`~nnabla.Variable` s."
msgstr ""
":obj:`~nnabla.Variable` の指定された軸 (すなわち ``x.shape[axis]`` ) のサイズと一"
"致する数の Variable を返します。"

#: nnabla.functions.split:8 of
msgid "Axis"
msgstr "軸"

#: nnabla.functions.split:11 of
msgid "Returns: A :obj:`tuple` of :obj:`~nnabla.Variable` s"
msgstr ":obj:`~nnabla.Variable` の :obj:`tuple` 返します"

#: nnabla.functions.split:13 of
msgid ":func:`nnabla.function_bases.split`."
msgstr ":func:`nnabla.function_bases.split`。"

#: nnabla.functions.stack:1 of
msgid "Joins two or more arrays on a new axis."
msgstr "新しい軸上に 2 つ、またはそれ以上の配列を結合します。"

#: nnabla.functions.stack:5 of
msgid ""
"Unlike :meth:`nnabla.functions.concatenate` , which joins arrays on an existing "
"axis, Stack joins arrays on a new axis."
msgstr ""
"既存の軸上に配列を結合する :meth:`nnabla.functions.concatenate` とは異なり、"
"Stack は新しい軸上に配列を結合します。"

#: nnabla.functions.stack:8 of
msgid ""
"N-D arrays. The sizes of all the arrays to be stacked must be the same. "
"[variadic]"
msgstr "N-D 配列。スタックされる配列のサイズは同じでなければなりません。[variadic]"

#: nnabla.functions.stack:11 of
msgid ""
"The axis on which to concatenate arrays. Axis indices take on values 0, 1, 2, "
"and so on from the left. For example, to stack four (3,28,28) inputs on the "
"second axis, specify 1. In this case, the output size will be (3,4,28,28). "
"[default=``0``]"
msgstr ""
"配列を連結する軸。軸のインデックスには、左から 0、1、2 などの値を取ります。例え"
"ば、2番目の軸に 4 つの ( 3, 28, 28 ) 入力をスタックする場合は、1 を指定します。こ"
"の場合、出力サイズは ( 3, 4, 28, 28 ) となります。[default= ``0`` ]"

#: nnabla.functions.slice:1 of
msgid ""
"Slice arrays along specified axis. This function complies with python slice "
"wherre `slice(None, None, -1)` and `slice(-1, None, -1)` are the special case, "
"which flips the input array and results in the output array from the end to the "
"beginning of the input array along the corresponding dimension."
msgstr ""
"指定された軸に沿って配列をスライスします。この関数は、Python のスライスに準拠して"
"います。 `slice(None, None, -1)` と `slice(-1, None, -1)` は特殊なケースであり、"
"入力配列を反転し、対応する次元に沿って入力配列の最後から先頭までを出力配列に結果"
"として出力します。"

#: nnabla.functions.slice:10 of
msgid "Start indices for each axis [default=``(0,) * len(x.shape)``]"
msgstr "各軸の開始インデックス [ default = ``(0,) * len(x.shape)`` ]"

#: nnabla.functions.slice:13 of
msgid "Stop indices for each axis [default=``tuple(x.shape)``]"
msgstr "各軸の停止インデックス [ default = ``tuple(x.shape)`` ]"

#: nnabla.functions.slice:16 of
msgid "Step indices for each axis [default=``(1,) * len(x.shape)``]"
msgstr "各軸の増分インデックス [ default = ``(1,) * len(x.shape)`` ]"

#: nnabla.functions.slice:20 of
msgid "Sliced N-D array"
msgstr "スライスされた N-D 配列"

#: nnabla.functions.gather_nd:1 of
msgid ""
"Gather elements or slices from `data` according to `indices`, which must be at "
"least two-dimensional with the first dimension :math:`M` being less or equal to "
"the :math:`N` dimensions of `data`. Given `data` with shape :math:`(X_0, "
"X_1, ..., X_{N-1})` and indices with shape :math:`(M, Y_0, ..., Y_{K-1})` output "
"has shape :math:`(Y_0, ..., Y_{K-1}, X_M, ..., X_{N-1})`. If :math:`M == N`, "
"output shape is simply :math:`(Y_0, ..., Y_{K-1})`."
msgstr ""
"`indices` にしたがって `data` から要素またはスライスを収集します。これは少なくと"
"も2次元で、最初の次元である :math:`M` 次元は `data` の :math:`N` 次元より低い次元"
"であるか同じでなければなりません。 :math:`(X_0, X_1, ..., X_{N-1})` 形状の指定さ"
"れた `data` と :math:`(M, Y_0, ..., Y_{K-1})` 出力の形状をした indices は :math:"
"`(Y_0, ..., Y_{K-1}, X_M, ..., X_{N-1})` の形状になります。 :math:`M == N` の場合"
"は、出力形状は単に :math:`(Y_0, ..., Y_{K-1})` となります。"

#: nnabla.functions.gather_nd:8 of
msgid "The forward of :func:`~nnabla.functions.gather_nd` is equivalent to:"
msgstr ":func:`~nnabla.functions.gather_nd` の forward は以下と同等です。"

#: nnabla.functions.gather_nd:10 of
msgid ""
"def gather_nd(data, index):\n"
"    import numpy as np\n"
"    tmp_index = index.reshape(index.shape[0], -1)\n"
"    tmp_index = (idx + (Ellipsis,) for idx in zip(*new_index))\n"
"    out_shape = index.shape[1:] + data.shape[index.shape[0]:]\n"
"    return np.vstack(data[idx] for idx in tmp_index).reshape(*out_shape)"
msgstr ""

#: nnabla.functions.gather_nd:19 nnabla.functions.scatter_nd:22 of
msgid "Examples:"
msgstr "例 :"

#: nnabla.functions.gather_nd:38 of
msgid ""
"When `indices` is provided as a :obj:`~nnabla.Variable` it will be possible to "
"change the actual index values after function creation. It is important to note "
"that out-of-bound indices raise errors when running on CPU but are ignored when "
"using an accelerated computation context."
msgstr ""
"`indices` が :obj:`~nnabla.Variable` として提供された場合、関数作成後、実際のイン"
"デックス値を変更することが可能となります。CPU上で実行する場合は範囲外の indices "
"はエラーとなりますが、高速演算コンテキストを使用する場合はエラーとならずに無視さ"
"れますので留意してください。"

#: nnabla.functions.gather_nd:53 nnabla.functions.scatter_nd:34 of
msgid "input data"
msgstr "入力データ"

#: nnabla.functions.gather_nd:55 of
msgid "gather indices"
msgstr "収集インデックス"

#: nnabla.functions.gather_nd:58 of
msgid "Returns: ~nnabla.Variable or ~nnabla.NdArray of gathered elements."
msgstr "戻り値：収集された要素の ~nnabla.Variable または ~nnabla.NdArray。"

#: nnabla.functions.scatter_nd:1 of
msgid ""
"Scatter `data` according to `indices` into a new array of given `shape` or an "
"existing array provided as `out`. Exactly one of the `shape` or `out` argument "
"must be given. Given output `shape`, or shape of `out` array, :math:`(X_0,X_1,"
"\\ldots,X_{N-1})` and `indices` shape :math:`(M,Y_0,\\ldots,Y_{K-1})` the input "
"`data` shape is :math:`(Y_0,\\ldots,Y_{K-1},X_M,\\ldots,X_{N-1})`, where :math:"
"`M<=N`. If :math:`M==N` the `data` shape is simply :math:`(Y_0,\\ldots,"
"Y_{K-1})`. Note that `indices` are treated as integers and potentially converted."
msgstr ""
"`indices` にしたがって `data` を、指定された `shape` の新しい配列または `out` と"
"して提供される既存の配列に散布します。 `shape` または `out` 引数の内のどちらか 1 "
"つを指定する必要があります。出力の `shape` または `out` 配列の形状が :math:`(X_0,"
"X_1,\\ldots,X_{N-1})` と、 `indices` の形状 :math:`(M,Y_0,\\ldots,Y_{K-1})` が指"
"定された場合、入力 `data` の形状は :math:`(Y_0,\\ldots,Y_{K-1},X_M,\\ldots,"
"X_{N-1})` となります。 :math:`M==N` の場合、`data` の形状は単純に :math:`(Y_0,"
"\\ldots,Y_{K-1})` となります。 `indices` は整数として扱われ、変換される可能性があ"
"ることに留意してください。"

#: nnabla.functions.scatter_nd:10 of
msgid "The forward of :func:`~nnabla.functions.scatter_nd` is equivalent to:"
msgstr ":func:`~nnabla.functions.scatter_nd` の forward は以下と同等になります。"

#: nnabla.functions.scatter_nd:12 of
msgid ""
"def scatter_nd(data, indices, shape=None, out=None):\n"
"    assert (shape and not out) or (out and not shape)\n"
"    if isinstance(indices, numpy.ndarray)\n"
"        indices = indices.tolist()\n"
"    result = out if out else numpy.zeros(shape)\n"
"    result[indices] = data\n"
"    return result"
msgstr ""

#: nnabla.functions.scatter_nd:36 of
msgid "scatter indices"
msgstr "散布インデックス"

#: nnabla.functions.scatter_nd:38 of
msgid "shape of new output array"
msgstr "新しい出力配列の形状"

#: nnabla.functions.scatter_nd:40 of
msgid "existing output array"
msgstr "既存の出力配列"

#: nnabla.functions.scatter_nd:43 of
msgid "Returns: ~nnabla.Variable or ~nnabla.NdArray of given `shape`."
msgstr "戻り値：指定された `shape` の ~nnabla.Variable または ~nnabla.NdArray。"

#: nnabla.functions.pad:1 of
msgid ""
"Pad the input N-D array `x` over the number of dimensions given by half the "
"length of the `pad_width` iterable, where every two values in `pad_width` "
"determine the before and after pad size of an axis. The `pad_width` iterable "
"must hold an even number of positive values which may cover all or fewer "
"dimensions of the input variable `x`. If `pad_width` covers fewer dimensions "
"then it applies to the innermost dimensions of `x`."
msgstr ""
"入力 N-D 配列 `x` を、イテレーション可能な `pad_width` の半分の要素数とする次元数"
"に対してパディングします。ある軸の前後のパディングサイズは `pad_width` の各 2 つ"
"の値によって決まります。イテレーション可能な `pad_width` は、入力変数 `x` のすべ"
"ての次元または少ない次元数となる正の値の偶数を保持する必要があります。 "
"`pad_width` がより少ない次元数である場合は、 `x` の最も深い次元に適用されます。"

#: nnabla.functions.pad:9 of
msgid ""
"x = nn.Variable.from_numpy_array(np.ones((2, 3, 4)))\n"
"assert F.pad(x, (1, 1, 2, 2)).shape == (2, 5, 8)"
msgstr ""

#: nnabla.functions.pad:14 of
msgid "Padding is performed according to the requested `mode`:"
msgstr "パディングは、要求された `mode` にしたがって実行されます。"

#: nnabla.functions.pad:24 of
msgid "constant"
msgstr "constant"

#: nnabla.functions.pad:17 of
msgid "Pads with a value given by the keyword argument `constant_value`."
msgstr "キーワード引数である `constant_value` で指定された値でパディングします。"

#: nnabla.functions.pad:19 of
msgid ""
"x = nn.Variable.from_numpy_array(np.array([1, 2, 3, 4], dtype=np.int))\n"
"y = F.pad(x, (3, 3), 'constant', constant_value = -1)\n"
"y.forward()\n"
"assert np.all(y.d == np.array([-1, -1, -1, 1, 2, 3, 4, -1, -1, -1]))"
msgstr ""

#: nnabla.functions.pad:35 of
msgid "reflect"
msgstr "reflect"

#: nnabla.functions.pad:27 of
msgid ""
"Pads with the reflection of the vector mirrored on the first and last values of "
"the vector along each axis."
msgstr ""
"各軸に沿ったベクトルの最初と最後の値でミラー化されたベクトルを反転してパディング"
"します。"

#: nnabla.functions.pad:30 of
msgid ""
"x = nn.Variable.from_numpy_array(np.array([1, 2, 3, 4], dtype=np.int))\n"
"y = F.pad(x, (3, 3), 'reflect')\n"
"y.forward()\n"
"assert np.all(y.d == np.array([4, 3, 2, 1, 2, 3, 4, 3, 2, 1]))"
msgstr ""

#: nnabla.functions.pad:39 of
msgid "Iterable of *before* and *after* pad values."
msgstr "*前後* のイテレーション可能なパディング値。"

#: nnabla.functions.pad:41 of
msgid "Padding mode string. [default=``'constant'``]"
msgstr "パディングモードの文字列。 [ default = ``'constant'`` ]"

#: nnabla.functions.pad:44 of
msgid "Fill value if mode is `constant`. [default=``0``]"
msgstr "mode が `constant` の場合に値を入力します。[ default = ``0`` ]"

#: nnabla.functions.pad:48 of
msgid ""
"Padded N-D array with the same number of dimensions as the input.  .. code-"
"block:: python    x = nn.Variable((3, 3, 4, 2))  # a shape like (B, C, H, W)   # "
"1-D padding: last dim by 1 left and 2 on the right side   assert F.pad(x, (1, "
"2)).shape == (3, 3, 4, 5)   # 2-D padding: last dim by (1, 1) and 2nd to last by "
"(2, 2)   assert F.pad(x, (2, 2, 1, 1)).shape == (3, 3, 8, 4)   # 3-D padding: "
"dims C by (0, 1), H by (2, 1), and W by (3, 3)   assert F.pad(x, (0, 1, 2, 1, 3, "
"3)).shape == (3, 4, 7, 8)"
msgstr ""

#: nnabla.functions.pad:48 of
msgid "Padded N-D array with the same number of dimensions as the input."
msgstr "入力と同じ次元数をもつパディングされた N-D 配列。"

#: nnabla.functions.pad:50 of
msgid ""
"x = nn.Variable((3, 3, 4, 2))  # a shape like (B, C, H, W)\n"
"# 1-D padding: last dim by 1 left and 2 on the right side\n"
"assert F.pad(x, (1, 2)).shape == (3, 3, 4, 5)\n"
"# 2-D padding: last dim by (1, 1) and 2nd to last by (2, 2)\n"
"assert F.pad(x, (2, 2, 1, 1)).shape == (3, 3, 8, 4)\n"
"# 3-D padding: dims C by (0, 1), H by (2, 1), and W by (3, 3)\n"
"assert F.pad(x, (0, 1, 2, 1, 3, 3)).shape == (3, 4, 7, 8)"
msgstr ""

#: nnabla.functions.transpose:1 of
msgid "Transposes tensor dimensions."
msgstr "テンソル次元を転置します。"

#: nnabla.functions.transpose:5 of
msgid "Source axis indices for each axis."
msgstr "各軸のソース軸インデックス。"

#: nnabla.functions.transpose:8 of
msgid "Transposed N-D array."
msgstr "転置された N-D 配列。"

#: nnabla.functions.broadcast:1 of
msgid "Broadcasting ND-array to the specified shape."
msgstr "指定された形状に ND 配列をブロードキャストします。"

#: nnabla.functions.broadcast:5 of
msgid ""
"Shape broadcasted to. The size must be the same in axis where ``x``'s shape is "
"not 1."
msgstr ""
"ブロードキャストされる形状。サイズは ``x`` の形状が1ではない軸において、同じでな"
"ければなりません。"

#: nnabla.functions.broadcast:8 nnabla.functions.broadcast_to:14 of
msgid "Broadcasted N-D array"
msgstr "ブロードキャストされた N-D 配列"

#: nnabla.functions.broadcast_to:4 of
msgid "Broadcasting ND-array to the specified buffer."
msgstr "指定されたバッファに ND 配列をブロードキャストします。"

#: nnabla.functions.broadcast_to:10 of
msgid ""
"Target axis to start broadcasting. If this is not set, broadcast will try to fit "
"y to x starting from the last dimension [default=``-1``]"
msgstr ""
"ブロードキャストを開始するターゲット軸。これが設定されていない場合、ブロードキャ"
"ストは最後の次元から開始して、y を x に合わせようとします。[ default = ``-1`` ]"

#: nnabla.functions.tile:1 of
msgid ""
"Forward `x` repeated the number of times given by `reps`. If `reps` is a "
"sequence, the output has dimension of ``d = max(len(reps), x.ndim)`` and either "
"`x` is promoted to be d-dimensional by prepending new axes or `reps` is promoted "
"to x.ndim by prepending 1's."
msgstr ""
"`x` が `reps` で与えられた回数分、繰り返し送られます。もし `reps` がシーケンスで"
"ある場合、出力は ``d = max(len(reps), x.ndim)`` の次元を有し、且つ `x` はいくつか"
"の新しい軸を前方に付け加えられたことで d 次元に生成されるか、 `reps` が x.ndim と"
"同じ長さになるように、1 を前方に付け加えられることで x.ndim 次元になります。"

#: nnabla.functions.min_max_quantize:83 nnabla.functions.tile:6 of
msgid "Input N-D array."
msgstr "入力 N-D 配列。"

#: nnabla.functions.tile:8 of
msgid "Repetitions of `x` along each axis."
msgstr "各軸に沿った `x` の繰り返し。"

#: nnabla.functions.flip:1 of
msgid "Reverses the order of elements of the specified dimension of an array."
msgstr "配列の指定された次元の要素の順序を逆にします。"

#: nnabla.functions.flip:5 of
msgid ""
"The index of the dimension to reverse the order of the elements. Axis indices "
"take on values 0, 1, 2, and so on from the left. For example, to flip a 32 (W) "
"by 24 (H) 100 RGB image (100,3,24,32) vertically and horizontally, specify "
"(2,3). [default=``[len(x.shape) - 1]``]"
msgstr ""
"要素の順序を逆にする次元のインデックス。軸インデックスは、 0、1、2 のように左から"
"値を取ります。例えば、32（W）x 24（H）100 RGB イメージ ( 100, 3, 24, 32 ) を垂直"
"および水平に反転するには、 ( 2, 3 ) を指定します。 [ default = ``[len(x.shape) - "
"1]`` ]"

#: nnabla.functions.shift:1 of
msgid "Shifts the array elements by the specified amount."
msgstr "指定された量だけ配列要素をずらします。"

#: nnabla.functions.shift:5 of
msgid ""
"The amount to shift elements. For example, to shift image data to the right by 2 "
"pixels and up 3 pixels, specify (-3,2). [default=``(0,) * len(x.shape)``]"
msgstr ""
"要素をずらす量。例えば、画像データを 2 ピクセル右に、 3 ピクセル上にシフトするに"
"は、 ( -3, 2 ) を指定します。 [ default = ``(0,) * len(x.shape)`` ]"

#: nnabla.functions.shift:8 of
msgid ""
"Specify how to process the ends of arrays whose values will be undetermined as a "
"result of shifting. nearest: The data at the ends of the original      array is "
"copied and used. reflect: Original data reflected      at the ends of the "
"original array is used. [default=``'nearest'``]"
msgstr ""
"シフトの結果として値が決定されない配列の末尾を処理する方法を指定します。nearest "
"：元の配列の末尾のデータがコピーされて使用されます。reflect ：元の配列の末尾に反"
"映された元のデータが使用されます。 [ default = ``'nearest'`` ]"

#: nnabla.functions.sort:1 of
msgid ""
"Sorts the elements of `x` along a given `axis` in ascending order by value. A "
"negative `axis` counts from the last dimension of `x`, so the default of -1 "
"sorts along the last dimension. If `reverse` is True, then the elements are "
"soreted in descending order."
msgstr ""
"`x` の要素を、特定の `axis` における値の昇順で並べ替えます。負の `axis` は `x` の"
"最後の次元からカウントされるため、デフォルトの -1 は最後の次元に沿ってソートされ"
"ます。 もし、 `reverse` が True の場合、要素は降順で並べ替えられます。"

#: nnabla.functions.sort:6 of
msgid ""
"If `with_index` is True, result is a tuple ``(sorted, indices)`` or only "
"``indices`` if `only_index` is True. Setting `only_index` to True implies that "
"`with_index` is also True."
msgstr ""
"もし `with_index` が True の場合、結果はタプル ``(sorted, indices)`` 、または "
"`only_index` が True の場合は ``indices`` のみです。 `only_index` を True に設定"
"すると、 `with_index` も True になります。"

#: nnabla.functions.sort:10 of
msgid ""
"import numpy as np\n"
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"\n"
"nn.set_auto_forward(True)\n"
"x = nn.Variable.from_numpy_array(np.random.rand(2, 3, 4))\n"
"\n"
"sorted = F.sort(x)\n"
"assert np.allclose(sorted.d, np.sort(x.d))\n"
"\n"
"sorted, indices = F.sort(x, with_index=True)\n"
"assert np.allclose(sorted.d, np.sort(x.d))\n"
"assert np.all(indices.d == np.argsort(x.d))\n"
"\n"
"indices = F.sort(x, only_index=True)\n"
"assert np.all(indices.d == np.argsort(x.d))"
msgstr ""

#: nnabla.functions.sort:31 of
msgid "Axis along which to sort."
msgstr "並べ替える軸。"

#: nnabla.functions.sort:33 of
msgid "Sort in descending order."
msgstr "降順でソートします。"

#: nnabla.functions.sort:35 of
msgid "Return sorted values and index."
msgstr "ソートされた値とインデックスを返します。"

#: nnabla.functions.sort:37 of
msgid "Return only the sort index."
msgstr "ソートされたインデックスのみを返します。"

#: nnabla.functions.sort:40 of
msgid ""
"Returns: ~nnabla.Variable `sorted` or ~nnabla.Variable `indices` or (~nnabla."
"Variable `sorted`, ~nnabla.Variable `indices`)"
msgstr ""
"戻り値 : ~nnabla.Variable `sorted` または ~nnabla.Variable `indices` または "
"(~nnabla.Variable `sorted` , ~nnabla.Variable `indices` )"

#: nnabla.functions.reshape:1 of
msgid ""
"Reshapes the input variable in-place. It does not create a copy of the variable. "
"The output variable (y) has a new shape but points to the same data as the input "
"variable (x). This means that if the data in the output variable (y) is "
"modified, the data in the input variable (x) also gets modified since the "
"reshape was done in-place."
msgstr ""
"入力変数を in-place で変形します。変数のコピーは作成されません。出力変数（y）は新"
"しい形状を持ちますが、入力変数（x）と同じデータを指します。これは、もし出力変数"
"（y）のデータが変更されると、整形が in-place で行われるため、入力変数（x）のデー"
"タも変更されることを意味します。"

#: nnabla.functions.reshape:6 of
msgid ""
"This function has the same behavior as the :meth:`nnabla.Variable.reshape` "
"method."
msgstr "この関数は、 :meth:`nnabla.Variable.reshape` メソッドと同じ動作をします。"

#: nnabla.functions.reshape:10 of
msgid ""
"Dimensions for each axis. ``-1`` can be specified only in one shape dimension. "
"The value is calculated from the size of the array and remaining dimensions."
msgstr ""
"各軸の次元。 ``-1`` は、1つの形状次元でのみ指定できます。値は、配列のサイズと残り"
"の次元から計算されます。"

#: nnabla.functions.reshape:12 of
msgid "The output array is shared with the input array if True. [default=``True``]"
msgstr "True の場合、出力配列は入力配列と共有されます。 [ default = ``True`` ]"

#: nnabla.functions.reshape:16 of
msgid "Reshaped N-D array"
msgstr "整形された N-D 配列"

#: nnabla.functions.one_hot:1 of
msgid "This function creates one-hot vector based on input indices."
msgstr "この関数は、入力インデックスに基づいて one-hot ベクトルを作成します。"

#: nnabla.functions.one_hot:5 of
msgid ""
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"import numpy as np\n"
"\n"
"labels = nn.Variable.from_numpy_array(np.array([[9], [4], [5], [1], [0]]))\n"
"print(labels.shape)  # (5, 1)\n"
"\n"
"num_class = 10\n"
"\n"
"y_train = F.one_hot(labels, shape=(num_class, ))\n"
"y_train.forward()\n"
"\n"
"print(y_train.shape)  # (5, 10)\n"
"print(y_train.d)\n"
"\n"
"# [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
"#  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
"#  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
"#  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
"\n"
"# Can also be used for ndarray.\n"
"\n"
"labels = nn.Variable.from_numpy_array(np.array([[1, 7], [4, 7], [8, 6], [5, 0], "
"[2, 6]]))\n"
"print(labels.shape)  # (5, 2)\n"
"\n"
"num_class_1, num_class_2  = 10, 8\n"
"\n"
"y_train = F.one_hot(labels, shape=(num_class_1, num_class_2))\n"
"y_train.forward()\n"
"\n"
"print(y_train.shape)  # (5, 10, 8)\n"
"print(y_train.d)\n"
"\n"
"# [[[0. 0. 0. 0. 0. 0. 0. 0.]          [[0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 1.]           [0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]           [0. 0. 0. 0. 0. 0. 1. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]           [0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]           [0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]    ...    [0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]           [0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]           [0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]           [0. 0. 0. 0. 0. 0. 0. 0.]\n"
"#   [0. 0. 0. 0. 0. 0. 0. 0.]],         [0. 0. 0. 0. 0. 0. 0. 0.]]]"
msgstr ""

#: nnabla.functions.one_hot:52 of
msgid "N-D array representing label's indice."
msgstr "ラベルのインデックスを表す N-D 配列。"

#: nnabla.functions.one_hot:54 of
msgid ""
"Number of classes. Note that it must be exactly the same as the number of "
"classes included in label data. Passing incorrect numbers might cause an "
"unexpected error and currently this function doesn't check if the input is valid "
"or not. Also, when nd-labels are given, dimensions must match. See the example "
"above."
msgstr ""
"クラスの数。ラベルデータに含まれるクラスの数と正確に同じでなければならないことに"
"注意してください。間違った数値を渡すと、予期しないエラーが発生する可能性があり、"
"現在この関数は入力が有効かどうかをチェックしていません。また、 nd-labels が指定さ"
"れている場合、次元数が一致する必要があります。上記の例を参照してください。"

#: nnabla.functions.one_hot:57 of
msgid "N-D array one-hot vector/tensor."
msgstr "ベクトル / テンソルの N-D 配列。"

#: nnabla.functions.batch_inv:1 of
msgid "Returns an array of inverted matrix"
msgstr "入力配列の行列式を返します"

#: nnabla.functions.batch_det:3 nnabla.functions.batch_inv:3 of
msgid "batched N-D array"
msgstr "バッチ化されたN-D配列"

#: nnabla.functions.batch_inv:6 of
msgid "batched N-D array of inverted matrix"
msgstr "行列式のバッチN-D配列"

#: nnabla.functions.batch_det:1 of
msgid "Returns determinant of an input array"
msgstr "入力配列の行列式を返します"

#: nnabla.functions.batch_det:6 of
msgid "batched N-D array of determinant"
msgstr "行列式のバッチN-D配列"

#: nnabla.functions.assign:1 of
msgid ""
"Assign source array to destination array just like `tf.assign`. This is useful "
"to synchronize or manually update parameters."
msgstr ""
"`tf.assign` と同じように、ソース配列を宛先配列に割り当てます。これは、パラメータ"
"を同期、または手動で更新するのに役立ちます。"

#: nnabla.functions.assign:4 of
msgid ""
"dst = nn.Variable((2, 3, 4))\n"
"src = nn.Variable((2, 3, 4))\n"
"assign = F.assign(dst, src)\n"
"\n"
"assign.forward()\n"
"assert np.allclose(dst.d, src.d) # dst and src have identical values.\n"
"assert np.allclose(assign.d dst.d) # returned Variable is also identical to dst."
msgstr ""

#: nnabla.functions.assign:14 of
msgid "Unlike TensorFlow, the returned Variable has a backward path to `dst`:"
msgstr ""
"TensorFlow とは異なり、返される変数には `dst` への backward パスがあります。"

#: nnabla.functions.assign:16 of
msgid "g_{dst} = g_{y}"
msgstr "g_{dst} = g_{y}"

#: nnabla.functions.assign:20 of
msgid "A destination N-D array"
msgstr "宛先 N-D 配列"

#: nnabla.functions.assign:22 of
msgid "A source N-D array"
msgstr "ソース N-D 配列"

#: nnabla.functions.assign:25 of
msgid "An assigned array"
msgstr "代入された配列"

#: nnabla.functions.top_k_data:1 of
msgid ""
"Select the `k` largest values from each sample in `x` to propagate unmodified "
"and set all other values to 0. If `abs` is True, the `k` largest values are "
"selected by magnitude. If `reduce` is True (the default), all feature dimensions "
"are reduced to a single dimension of size `k` that propagates only the `k` "
"largest values. Otherwise, if `reduce` is False, input and output dimensions are "
"identical. Dimensions before `base_axis` are treated as number of sample "
"dimensions and `k` values get selected from all elements of a sample (dimensions "
"from `base_axis`) regardless of shape."
msgstr ""
"`x` の各サンプルから `k` 個の最大値を選択します。 `k` 個の値は変更されず、それ以"
"外の値は 0 になります。 `abs` が True の場合、 `k` 個の最大値が大きさによって選択"
"されます。 `reduce` が True（デフォルト）の場合、すべての特徴次元は、 `k` 個の最"
"大値のみを伝達するサイズ `k` の単一次元に縮小されます。それ以外の場合、 `reduce` "
"が False の場合、入力と出力の次元は同じです。 `base_axis` の前の次元はサンプルの"
"次元数として扱われ、形状に関係なくサンプルのすべての要素（ `base_axis` からの次"
"元）から `k` 値が選択されます。"

#: nnabla.functions.top_k_data:23 of
msgid "Number of largest data values to propagate."
msgstr "伝達する最大データ値の数。"

#: nnabla.functions.top_k_data:25 of
msgid "Determine largest data values by magnitude. [default=``False``]"
msgstr "大きさによる最大データ値の決定 [ default = ``False`` ]"

#: nnabla.functions.top_k_data:28 of
msgid "Reduce feature size to one dimension of size `k`. [default=``True``]"
msgstr "特徴サイズをサイズ `k` の 1 次元に縮小。 [ default = ``True`` ]"

#: nnabla.functions.top_k_data:31 nnabla.functions.top_k_grad:16 of
msgid "First dimension of the sample shape. [default=``1``]"
msgstr "サンプル形状の最初の次元。 [ default = ``1`` ]"

#: nnabla.functions.top_k_grad:1 of
msgid ""
"Select the `k` largest gradients for each sample in `x` to back-propagate "
"unmodified and set all other gradients to 0. If `abs` is True, the `k` largest "
"gradients are selected by magnitude. Dimensions before `base_axis` are treated "
"as number of sample dimensions and `k` gradients get selected from all gradients "
"of a sample (dimensions from `base_axis`) regardless of shape."
msgstr ""
"`x` の各サンプルに対して `k` 個の最大勾配を選択します。 `k` 個の値は変更されず、"
"それ以外の値は0になります。 `abs` が True の場合、 `k` 個の最大勾配が大きさによっ"
"て選択されます。 `base_axis` の前の次元はサンプル次元の数として扱われ、形状に関係"
"なくサンプルのすべての勾配（ `base_axis` からの次元）から `k` 個の勾配が選択され"
"ます。"

#: nnabla.functions.top_k_grad:11 of
msgid "Number of largest gradients to propagate."
msgstr "伝達する最大勾配の数。"

#: nnabla.functions.top_k_grad:13 of
msgid "Determine largest gradients by magnitude. [default=``False``]"
msgstr "大きさによる最大勾配の決定。 [ default = ``False`` ]"

#: nnabla.functions.top_k_grad:20 of
msgid "N-D array with same shape and data as `x`."
msgstr "`x` と同じ形状とデータを持つ N-D 配列。"

#: ../../python/api/function.rst:219
msgid "Stochasticity"
msgstr "確率論"

#: nnabla.functions.rand:1 of
msgid ""
"Samples numbers from a uniform distribution :math:`x \\sim U(low, high)` given "
"lowest value :math:`low`, upper bound :math:`high`, and shape of the returned "
"Variable."
msgstr ""
"下限の :math:`low` 、 上限の :math:`high` 、返される変数の形状によって定められ"
"る :math:`x \\sim U(low, high)` の一様分布から数を抽出します。"

#: nnabla.functions.rand:5 nnabla.functions.randint:5 of
msgid ":math:`low` in definition. [default=``0``]"
msgstr "定義における :math:`low`。 [ default = ``0`` ]"

#: nnabla.functions.rand:8 nnabla.functions.randint:8 of
msgid ":math:`high` in definition. [default=``1``]"
msgstr "定義における :math:`high` 。 [ default = ``1`` ]"

#: nnabla.functions.rand:11 nnabla.functions.randint:11 nnabla.functions.randn:11
#: of
msgid "Shape of returned variable. [default=``[]``]"
msgstr "返される変数の形状。 [ default = ``[]`` ]"

#: nnabla.functions.dropout:30 nnabla.functions.image_augmentation:50
#: nnabla.functions.inq_affine:41 nnabla.functions.inq_convolution:53
#: nnabla.functions.rand:14 nnabla.functions.randint:14 nnabla.functions.randn:14
#: nnabla.functions.random_crop:11 nnabla.functions.random_erase:60
#: nnabla.functions.random_flip:11 nnabla.functions.random_shift:14 of
msgid ""
"Random seed. When -1, seed is sampled from global random number generator. "
"[default=``-1``]"
msgstr ""
"ランダムシード。-1 の場合、シードはグローバル乱数ジェネレーターから抽出されま"
"す。 [ default = ``-1`` ]"

#: nnabla.functions.rand:18 nnabla.functions.randn:18 of
msgid "Variable with the shape specified in the argument."
msgstr "引数で定められた形状の変数。"

#: nnabla.functions.randint:1 of
msgid ""
"Samples integer numbers from a uniform distribution :math:`x \\sim U(low, high)` "
"given lowest value :math:`low`, upper bound :math:`high`, and shape of the "
"returned Variable."
msgstr ""
"下限の :math:`low` 、 上限の :math:`high` 、返される変数の形状によって定められ"
"る :math:`x \\sim U(low, high)` の一様分布から整数を抽出します。"

#: nnabla.functions.randint:18 of
msgid "Variable with the shape specified in the argument. The dtype is int32."
msgstr "引数で定められた形状の変数。 dtype は int32 です。"

#: nnabla.functions.randn:1 of
msgid ""
"Samples numbers from a normal distribution :math:`x \\sim N(\\mu, \\sigma)` "
"given mean :math:`\\mu`, standard deviation :math:`\\sigma`, and shape of the "
"returned Variable."
msgstr ""
"平均 :math:`\\mu` 、 標準偏差 :math:`\\sigma` 、返される変数の形状によって定めら"
"れた :math:`x \\sim N(\\mu, \\sigma)` の正規分布から数を抽出します。"

#: nnabla.functions.randn:5 of
msgid ":math:`\\mu` in definition. [default=``0``]"
msgstr "定義における :math:`\\mu` 。 [ default = ``0`` ]"

#: nnabla.functions.randn:8 of
msgid ":math:`\\sigma` in definition. [default=``1``]"
msgstr "定義における :math:`\\sigma` 。 [ default = ``1`` ]"

#: nnabla.functions.dropout:1 of
msgid ""
"Dropout. Samples a number :math:`u` from a uniform distribution in :math:`[0, "
"1]` , and ignores the input if :math:`u \\leq p`."
msgstr ""
"ドロップアウト。サンプル数 :math:`u` を :math:`[0, 1]` の一様分布から抽出しま"
"す。 :math:`u \\leq p` の場合は入力を無視します。"

#: nnabla.functions.dropout:5 of
msgid ""
"y = \\left\\{ \\begin{array}{ll}   \\frac{x}{1 - p} & (u > p) \\\\   0 & ({\\rm "
"otherwise}) \\end{array} \\right."
msgstr ""
"y = \\left\\{ \\begin{array}{ll}   \\frac{x}{1 - p} & (u > p) \\\\   0 & ({\\rm "
"otherwise}) \\end{array} \\right."

#: nnabla.functions.dropout:14 of
msgid ""
"Usually dropout only applied during training as below (except `Bayesian "
"dropout`_)."
msgstr ""
"通常、ドロップアウトは以下のように学習中にのみ適用されます（ `Bayesian dropout`_ "
"を除く）。"

#: nnabla.functions.dropout:17 of
msgid ""
"h = PF.affine(x, num_hidden)\n"
"if train:\n"
"    h = F.dropout(h, 0.5)"
msgstr ""

#: nnabla.functions.dropout:27 of
msgid ":math:`p` in definition. [default=``0.5``]"
msgstr "定義における :math:`p` [ default = ``0.5`` ]"

#: nnabla.functions.random_choice:1 of
msgid ""
"Generate random samples from population `x` with selection probabilities "
"determined by the relative weights `w`. The number of samples to draw is given "
"by the product of `shape`s dimensions, and the samples are returned with the "
"given `shape`. By default, samples are drawn with replacement, i.e. selection of "
"a specific population member is solely determined by its associated weight. "
"Sampling without replacement, where any population member may be drawn only "
"once, is used if `replace` is set to False."
msgstr ""
"相対的重み `w` によって決定される選択確率を使用して、母集団 `x` からランダムサン"
"プルを生成します。生成するサンプルの数は、 `shape` の次元の積で指定され、サンプル"
"は指定された `shape` で返されます。デフォルトでは、サンプルは重複ありで生成されま"
"す。つまり、特定の母集団メンバーの選択は、関連する重みによってのみ決定されます。 "
"`replace` が False に設定されている場合、任意の母集団メンバーが1回だけ生成される"
"といった重複のないサンプリングが使用されます。"

#: nnabla.functions.random_choice:9 of
msgid ""
"For both `x` and `w` the innermost dimension corresponds to the individual "
"populations and their weights from which samples are returned with the requested "
"`shape` following all outermost dimensions of the input."
msgstr ""
"`x` と `w` の両方について、最後の次元は、個々の母集団とその重みに対応し、要求され"
"た `shape` 分のサンプルが生成されます。それ以外の次元は `shape` の前に付きます。"

#: nnabla.functions.random_choice:13 of
msgid ""
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"import numpy as np\n"
"nn.set_auto_forward(True)\n"
"\n"
"# x holds two populations\n"
"x = nn.Variable.from_numpy_array(np.array([[11, 22, 33], [110, 220, 330]]))\n"
"# w holds the weights for each population\n"
"w = nn.Variable.from_numpy_array(np.array([[10, 20, 70], [70, 20, 10]]))\n"
"\n"
"# draw one sample from each population\n"
"y = F.random_choice(x, w)  # y.shape => (2, 1)\n"
"\n"
"# draw 12 samples with shape (3, 4) from each population\n"
"y = F.random_choice(x, w, shape=(3, 4))  # y.shape => (2, 3, 4)"
msgstr ""

#: nnabla.functions.random_choice:31 of
msgid ""
"Note that weights must not be less than zero and for each population the sum of "
"weights must be greater than zero. Additionally, sampling without replacement "
"requires that the number of non-zero weights is not less than the number of "
"samples to be drawn. These conditions are verified in \"cpu\" computation "
"context but not when using \"cuda\" or \"cudnn\" acceleration (this would "
"require additional device synchronization steps penalizing performance)."
msgstr ""
"重みはゼロより小さくてはいけません。母集団ごとに重みの合計はゼロより大きくなけれ"
"ばならないことに留意してください。さらに、重複なしのサンプリングでは、ゼロ以外の"
"重みの数が、生成されるサンプルの数以上でなければなりません。これらの条件は “cpu” "
"計算コンテキストで検証されますが、 “cuda” または “cudnn” アクセラレーションを使用"
"する場合は検証されません（パフォーマンスに悪影響を与える追加のデバイス同期ステッ"
"プが必要になるからです）。"

#: nnabla.functions.random_choice:39 of
msgid ""
"Random sampling from an implicit array of index values (like categorical or "
"multinomial) can be realized with input `x` constructed as indices."
msgstr ""
"（カテゴリ別または多項のような）インデックス値の暗黙的な配列からのランダムサンプ"
"リングは、インデックスとして構築された入力 `x` を使用して実現できます。"

#: nnabla.functions.random_choice:42 of
msgid ""
"w = nn.Variable.from_numpy_array(np.array([1, 2, 3, 2, 1]))\n"
"y = F.random_choice(F.arange(0, 5), w)"
msgstr ""

#: nnabla.functions.random_choice:47 of
msgid "N-D array from which a random sample is generated."
msgstr "ランダムサンプルの生成元の N-D 配列。"

#: nnabla.functions.random_choice:49 of
msgid "N-D array of associated weights of elements in `x`."
msgstr "`x` の要素の関連する重みのN-D配列。"

#: nnabla.functions.random_choice:51 of
msgid "Number and shape of generated samples. [default=``[]``]"
msgstr "生成されたサンプルの数と形状。 [ default = ``[]`` ]"

#: nnabla.functions.random_choice:54 of
msgid "Whether sampling is with or without replacement. [default=``True``]"
msgstr "サンプリングの置換の有無。 [ default = ``True`` ]"

#: nnabla.functions.random_choice:57 of
msgid "Random seed. [default=``-1``]"
msgstr "ランダムなシード。 [ default = ``-1`` ]"

#: nnabla.functions.random_crop:1 of
msgid "RandomCrop randomly extracts a portion of an array."
msgstr "RandomCropは、配列の一部をランダムに切り抜きます。"

#: nnabla.functions.random_crop:5 of
msgid ""
"The data size to extract. For example, to randomly extract a portion of the "
"image (3,48,48) from a 3,64,64 image, specify (3,48,48). [default=``x.shape``]"
msgstr ""
"切り抜くデータサイズ。例えば、 3, 64, 64 イメージからイメージの一部 ( 3, 48, "
"48 ) をランダムに抽出するには、( 3, 48, 48 ) を指定します。[default=``x.shape``]"

#: nnabla.functions.random_crop:8 nnabla.functions.random_flip:8
#: nnabla.functions.random_shift:11 of
msgid "No Description [default=``1``]"
msgstr "説明なし [ default = ``1`` ]"

#: nnabla.functions.random_erase:1 of
msgid "Randomly erase patches of the inputs and replace with random values."
msgstr "入力のパッチをランダムに消去し、ランダムな値で置き換えます。"

#: nnabla.functions.random_erase:3 of
msgid ""
"Erasing is applied for each sample and for each `n` with the given probability, "
"the randomly selected area ratio and aspect ratio if `share` is `True`; "
"otherwise (`share`=`False`), for each feature additionally."
msgstr ""
"`share` が `True` の場合、指定された確率、ランダムに選択された面積比およびアスペ"
"クト比で各サンプルおよび各 `n` に対して消去を行います。それ以外の場合 ( `share` "
"= `False` ) は、さらに各特徴マップに対して消去を行います。"

#: nnabla.functions.random_erase:7 of
msgid "Random patch are selected by random coordinates as the following,"
msgstr "ランダムパッチは以下のようにランダム座標によって選択されます。"

#: nnabla.functions.random_erase:9 of
msgid ""
"S_e &&= Uniform(s_l, s_h) \\times S \\\\ r_e &&= Uniform(r_l, r_h) \\\\ H_e &&= "
"\\sqrt{S_e \\times r_e} \\\\ W_e &&= \\sqrt{S_e / r_e} \\\\ y_e &&= Uniform(0, H "
"- H_e) \\\\ x_e &&= Uniform(0, W - W_e),"
msgstr ""
"S_e &&= Uniform(s_l, s_h) \\times S \\\\ r_e &&= Uniform(r_l, r_h) \\\\ H_e &&= "
"\\sqrt{S_e \\times r_e} \\\\ W_e &&= \\sqrt{S_e / r_e} \\\\ y_e &&= Uniform(0, H "
"- H_e) \\\\ x_e &&= Uniform(0, W - W_e),"

#: nnabla.functions.random_erase:18 of
msgid ""
"where :math:`S` is the area, :math:`s_l` and :math:`s_h` are the low and high "
"values of the area ratio range, :math:`r_l` and :math:`r_h` are the low and high "
"values of the aspect ratio range, :math:`H_e` and :math:`W_e` are height and "
"width of a patch, and :math:`y_e` and :math:`x_e` are the start coordinates of a "
"patch. If a pixel of the inputs falls in this patch, the value of that pixel is "
"replaced with a random value in `replacements` range."
msgstr ""
"ここでは、 :math:`S` は面積、 :math:`s_l` および :math:`s_h` は面積比の範囲の低値"
"および高値、 :math:`r_l` および :math:`r_h` はアスペクト比の範囲の低値および高"
"値、 :math:`H_e` および :math:`W_e` はパッチの高さおよび幅、 :math:`y_e` および :"
"math:`x_e` はパッチの開始座標です。入力のピクセルがこのパッチに該当する場合は、そ"
"のピクセル値は `replacements` 範囲のランダムな値に置き換えられます。"

#: nnabla.functions.random_erase:25 of
msgid ""
"Backward is implemented as passing gradients if `ste_fine_grained` is False; "
"otherwise, the backward only occurs in regions not erased."
msgstr ""
"`ste_fine_grained` が False の場合、backward は勾配を渡すように実装されます。それ"
"以外の場合は、backward は消去されていない領域のみで実行されます。"

#: nnabla.functions.random_erase:30 of
msgid ""
"`Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, Yi Yang, Random Erasing Data "
"Augmentation, <https://arxiv.org/abs/1708.04896>`_"
msgstr ""
"`Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, Yi Yang, Random Erasing Data "
"Augmentation, <https://arxiv.org/abs/1708.04896>`_"

#: nnabla.functions.random_erase:36 of
msgid "Probability to erase. [default=``0.5``]"
msgstr "消去の確率。 [ default = ``0.5`` ]"

#: nnabla.functions.random_erase:39 of
msgid "Low and high of the area ratio range. [default=``(0.02, 0.4)``]"
msgstr "面積比の範囲の低値および高値。 [ default = ``(0.02, 0.4)`` ]"

#: nnabla.functions.random_erase:42 of
msgid "Low and high of the aspect ratios range. [default=``(0.3, 3.3333)``]"
msgstr "アスペクト比の範囲の低値および高値。 [ default = ``(0.3, 3.3333)`` ]"

#: nnabla.functions.random_erase:45 of
msgid "Low and high of the replacement value range. [default=``(0.0, 255.0)``]"
msgstr "置換値の範囲の低値および高値。 [ default = ``(0.0, 255.0)`` ]"

#: nnabla.functions.random_erase:48 of
msgid "Max number of patches to be erased. [default=``1``]"
msgstr "消去するパッチの最大数。 [ default = ``1`` ]"

#: nnabla.functions.random_erase:51 of
msgid ""
"Use a same bounding box randomly picked over the feature dimension when being "
"True. Default is False. [default=``True``]"
msgstr ""
"True の場合、特徴次元でランダムに選択された同じ境界ボックスを使用します。デフォル"
"トは False です。 [ default = ``True`` ]"

#: nnabla.functions.random_erase:66 of
msgid ""
"Straight Through Estimator is fine-grained or not. Default is True. "
"[default=``True``]"
msgstr ""
"Straight Through Estimator がfine-grained か否かのフラグ。デフォルトは True で"
"す。 [ default = ``True`` ]"

#: nnabla.functions.random_flip:1 of
msgid ""
"Reverses the order of elements of the specified dimension of an array at 50% "
"probability."
msgstr "配列の指定された次元の要素の順序を 50％ の確率で逆にします。"

#: nnabla.functions.random_flip:5 of
msgid ""
"The index of the axis to reverse the order of the elements. Axis indices take on "
"values 0, 1, 2, and so on from the left. For example, to flip a 32 (W) by 24 (H) "
"100 RGB images (100, 3,24,32) vertically and horizontally at random, specify "
"(2,3). [default=``[len(x.shape) - 1]``]"
msgstr ""
"要素の順序を逆にする軸のインデックス。軸インデックスは、左から 0、1、2 などの値を"
"取ります。例えば、32（W）x 24（H）の100 RGB画像（100、3、24、32）をランダムに垂直"
"および水平に反転するには、（2, 3）を指定します。[ default = ``[len(x.shape) - "
"1]`` ]"

#: nnabla.functions.random_shift:1 of
msgid "Randomly shifts the array elements within the specified range."
msgstr "指定された範囲内で配列要素をランダムにずらします。"

#: nnabla.functions.random_shift:5 of
msgid ""
"Max absolute amount to shift elements. For example, to shift image data "
"horizontally by :math:`\\pm 2` pixels and vertically by :math:`\\pm 3` pixels, "
"specify (3,2). [default=``(0,) * len(x.shape)``]"
msgstr ""
"シフト要素の最大絶対量。例えば、画像データを水平方向に :math:`\\pm 2` ピクセルと"
"垂直 :math:`\\pm 3` ピクセルシフトするには（3, 2）を指定します。 [ default = "
"``(0,) * len(x.shape)`` ]"

#: nnabla.functions.random_shift:8 of
msgid ""
"Specify how to process the ends of arrays whose values will be undetermined as a "
"result of shifting. nearest: The data at the ends of the   original array is "
"copied and used. reflect: Original data reflected at   the ends of the original "
"array is used. [default=``'nearest'``]"
msgstr ""
"シフトの結果として値が決定されない配列の端を処理する方法を指定します。nearest：元"
"の配列の端のデータがコピーされて使用されます。 reflect：元の配列の端で反転した元"
"のデータが使用されます。 [ default = ``’nearest’`` ]"

#: nnabla.functions.image_augmentation:1 of
msgid "ImageAugmentation randomly alters the input image."
msgstr "ImageAugmentation は、入力画像をランダムに変更します。"

#: nnabla.functions.image_augmentation:5 of
msgid "The output image data size. [default=``x.shape``]"
msgstr "出力画像データのサイズ。[ default = ``x.shape`` ]"

#: nnabla.functions.image_augmentation:8 of
msgid ""
"Border padding values for each spatial axis. Padding will be added both sides of "
"the dimension. [default=``(0, 0)``]"
msgstr ""
"各空間軸の境界パディング値。次元の両側にパディングが追加されます。[ default = "
"``(0, 0)`` ]"

#: nnabla.functions.image_augmentation:11 of
msgid ""
"The minimum scale ratio when randomly scaling the image. For example, to scale "
"down to 0.8 times the size of the original image, specify \"0.8\". To not apply "
"random scaling, set both min_scale and max_scale to \"1.0\". [default=``1.0``]"
msgstr ""
"画像をランダムに拡大縮小するときの最小比率。例えば、元の画像のサイズの 0.8 に縮小"
"するには、 “0.8” を指定します。ランダムスケーリングを適用しないようにするには、"
"min_scaleとmax_scaleの両方を “1.0” に設定します。[ default = ``1.0`` ]"

#: nnabla.functions.image_augmentation:14 of
msgid ""
"The maximum scale ratio when randomly scaling the image. For example, to scale "
"down to 2 times the size of the original image, specify \"2.0\". "
"[default=``1.0``]"
msgstr ""
"画像をランダムに拡大縮小するときの最大比率。例えば、元の画像のサイズの2倍に縮小す"
"るには、 “2.0” を指定します。 [ default = ``1.0`` ]"

#: nnabla.functions.image_augmentation:17 of
msgid ""
"The rotation angle range in radians when randomly rotating the image. The image "
"is randomly rotated in the -Angle to +Angle range. For example, to rotate in a "
"+-15 degree range, specify \"0.26\" (15 degrees/360 degrees * 2PI). To not apply "
"random rotation, specify \"0.0\". [default=``0.0``]"
msgstr ""
"画像をランダムに回転させるときの回転角度範囲（ラジアン単位）。画像は -Angle から "
"+Angle の範囲でランダムに回転します。例えば、+-15度の範囲で回転するには、 "
"“0.26” （15度/ 360度* 2PI）を指定します。ランダム回転を適用しない場合は、 “0.0” "
"を指定します。[ default = ``0.0`` ]"

#: nnabla.functions.image_augmentation:20 of
msgid ""
"The aspect ratio range when randomly deforming the image. For example, to deform "
"aspect ratio of image from 1:1.3 to 1.3:1, specify \"1.3\". To not apply random "
"deforming, specify \"1.0\". [default=``1.0``]"
msgstr ""
"画像をランダムに変形するときの縦横比の範囲。例えば、画像のアスペクト比を 1：1.3 "
"から 1.3：1 に変形するには、 “1.3” を指定します。ランダムな変形を適用しない場合"
"は、“1.0” を指定します。[ default = ``1.0`` ]"

#: nnabla.functions.image_augmentation:23 of
msgid ""
"The distortion range when randomly distorting the image. To not apply "
"distortion, specify \"0.0\". [default=``0.0``]"
msgstr ""
"画像をランダムに歪ませるときの歪みの範囲。歪みを適用しない場合は、 “0.0” を指定し"
"ます。[ default = ``0.0`` ]"

#: nnabla.functions.image_augmentation:26 of
msgid ""
"Whether to randomly flip the image horizontally at 50% probability. "
"[default=``False``]"
msgstr ""
"50％ の確率で画像を水平方向にランダムに反転させるかどうか。 [ default = "
"``False`` ]"

#: nnabla.functions.image_augmentation:29 of
msgid ""
"Whether to randomly flip the image vertically at 50% probability. "
"[default=``False``]"
msgstr ""
"50％ の確率で画像をランダムに垂直に反転させるかどうか。 [ default = ``False`` ]"

#: nnabla.functions.image_augmentation:32 of
msgid ""
"The absolute range of values to randomly add to the brightness. A random value "
"in the -Brightness to +Brightness range is added to the brightness. For example, "
"to vary the brightness in the -0.05 to +0.05 range, specify \"0.05\". To not "
"apply random addition to brightness, specify \"0.0\". [default=``0.0``]"
msgstr ""
"輝度にランダムに追加する値の絶対範囲。 -Brightness から +Brightness の範囲のラン"
"ダムな値が明るさに追加されます。例えば、明るさを -0.05 〜 +0.05 の範囲で変更する"
"には、 “0.05” を指定します。明るさにランダムな加算を適用しない場合は、 “0.0” を指"
"定します。 [ default=``0.0`` ]"

#: nnabla.functions.image_augmentation:35 of
msgid ""
"Whether to apply the random addition to brightness (as specified by brightness) "
"to each color channel. True: brightness is added based on a different random "
"number for each channel. False: brightness is added based on a random number "
"common to all channels. [default=``False``]"
msgstr ""
"各カラーチャンネルに（明るさで指定された）明るさのランダム加算を適用するかどう"
"か。True：チャンネルごとに異なる乱数に基づいて明るさが追加されます。False：すべて"
"のチャンネルに共通の乱数に基づいて明るさが追加されます。 [ default = ``False`` ]"

#: nnabla.functions.image_augmentation:38 of
msgid ""
"The range in which to randomly vary the image contrast. The contrast is varied "
"in the 1/Contrast times to Contrast times range. The output brightness is equal "
"to (input - contrast_center) * contrast + contrast_center. For example, to vary "
"the contrast in the 0.91 times to 1.1 times range, specify \"1.1\". To not apply "
"random contrast variation, specify \"1.0\". [default=``1.0``]"
msgstr ""
"画像のコントラストをランダムに変化させる範囲。コントラストは、1÷コントラスト時間"
"からコントラスト時間の範囲で変化します。出力輝度は（input-contrast_center）* "
"contrast + contrast_centerに等しくなります。例えば、0.91倍から1.1倍の範囲でコント"
"ラストを変更するには、 “1.1” を指定します。ランダムなコントラスト変動を適用しない"
"場合は、 “1.0” を指定します。[ default = ``1.0`` ]"

#: nnabla.functions.image_augmentation:41 of
msgid "Intensity center used for applying contrast. [default=``0.0``]"
msgstr "コントラストの適用に使用される強度センター。[ default = ``0.0`` ]"

#: nnabla.functions.image_augmentation:44 of
msgid ""
"Whether to apply the random contrast variation (as specified by contrast) to "
"each color channel. True: contrast is varied based on a different random number "
"for each channel. False: contrast is varied based on a random number common to "
"all channels. [default=``False``]"
msgstr ""
"ランダムなコントラスト変動（コントラストで指定）を各カラーチャンネルに適用するか"
"どうか。True：コントラストは、チャンネルごとに異なる乱数に基づいて変化します。"
"False：すべてのチャンネルに共通の乱数に基づいてコントラストが変化します。"
"[ default = ``False`` ]"

#: nnabla.functions.image_augmentation:47 of
msgid "Sigma of normal random number to be added. [default=``0.0``]"
msgstr "追加される通常の乱数のシグマ。 [ default = ``0.0`` ]"

#: ../../python/api/function.rst:234
msgid "Loss Functions"
msgstr "Loss 関数"

#: nnabla.functions.sigmoid_cross_entropy:1 of
msgid ""
"Element-wise cross entropy between `x` and the target variables, passed to a "
"sigmoid function."
msgstr ""
"sigmoid 関数に渡される、 `x` とターゲット変数間の要素ごとのクロスエントロピー。"

#: nnabla.functions.sigmoid_cross_entropy:3 of
msgid ""
"y_i = - \\left(x^{(1)}_i \\ln \\left(\\sigma \\left(x^{(0)}_i \\right)\\right) + "
"\\ \\left(1 - x^{(1)}_i\\right) \\ln \\left(1 - \\sigma \\left(x^{(0)}_i \\ "
"\\right)\\right)\\right)"
msgstr ""
"y_i = - \\left(x^{(1)}_i \\ln \\left(\\sigma \\left(x^{(0)}_i \\right)\\right) + "
"\\ \\left(1 - x^{(1)}_i\\right) \\ln \\left(1 - \\sigma \\left(x^{(0)}_i \\ "
"\\right)\\right)\\right)"

#: nnabla.functions.sigmoid_cross_entropy:8 of
msgid "where :math:`\\sigma(s)=\\frac{1}{1+\\exp(-s)}`."
msgstr "ここで、 :math:`\\sigma(s)=\\frac{1}{1+\\exp(-s)}` とします。"

#: nnabla.functions.sigmoid_cross_entropy:10 of
msgid ""
"SigmoidCrossEntropy is equivalent to Sigmoid+BinaryCrossEntropy, but computing "
"them at once has the effect of reducing computational error."
msgstr ""
"SigmoidCrossEntropy は Sigmoid + BinaryCrossEntropy と同等ですが、一度に計算する"
"と計算エラーを減らす効果があります。"

#: nnabla.functions.sigmoid_cross_entropy:12 of
msgid ""
"N-D array. Typically indicates a score. The value lies in :math:`[-\\infty, "
"\\infty]` [parameter]"
msgstr ""
"N-D 配列。 通常はスコアを示します。値は :math:`[-\\infty, \\infty]` [パラメータ] "
"にあります。"

#: nnabla.functions.sigmoid_cross_entropy:15 of
msgid "N-D array of labels. Only 0 or 1 value is allowed. [parameter]"
msgstr "ラベルの N-D 配列。許可される値は 0 または 1 のみです。 [パラメータ]"

#: nnabla.functions.binary_cross_entropy:12
#: nnabla.functions.epsilon_insensitive_loss:17 nnabla.functions.huber_loss:20
#: nnabla.functions.sigmoid_cross_entropy:19 of
msgid "N-D array of element-wise losses."
msgstr "要素ごとの損失の N-D 配列。"

#: nnabla.functions.binary_cross_entropy:1 of
msgid "Element-wise cross entropy between `x` and the target variables."
msgstr "`x` とターゲット変数間の要素ごとのクロスエントロピー。"

#: nnabla.functions.binary_cross_entropy:3 of
msgid ""
"y_i = - \\left(x^{(1)}_i * \\ln \\left(x^{(0)}_i\\right) + \\left(1 - \\ x^{(1)}"
"_i\\right) * \\ln \\left(1 - x^{(0)}_i\\right)\\right)."
msgstr ""
"y_i = - \\left(x^{(1)}_i * \\ln \\left(x^{(0)}_i\\right) + \\left(1 - \\ x^{(1)}"
"_i\\right) * \\ln \\left(1 - x^{(0)}_i\\right)\\right)."

#: nnabla.functions.binary_cross_entropy:7 of
msgid "Probabilities N-D array. :math:`-\\infty` to :math:`\\infty`."
msgstr "N-D 配列の確率。 :math:`-\\infty` から :math:`\\infty` 。"

#: nnabla.functions.binary_cross_entropy:9 of
msgid ""
"N-D array of labels. Usually set as 0 or 1, but, unlike SigmoidCrossEntropy, it "
"allows probability (0 to 1) as inputs and backpropagation can be done."
msgstr ""
"ラベルの N-D 配列。通常は 0 または 1 に設定されますが、SigmoidCrossEntropy とは異"
"なり、入力と逆伝播を行うことができるため、確率（0〜1）が可能です。"

#: nnabla.functions.softmax_cross_entropy:1 of
msgid ""
"Element-wise cross entropy between the variables and the variables of a label "
"given by a category index with Softmax normalization."
msgstr ""
"Softmax normalization を使用したカテゴリインデックスによって与えられる変数と、ラ"
"ベルの変数間の要素単位のクロスエントロピー。"

#: nnabla.functions.softmax_cross_entropy:3 of
msgid ""
"y_{j} = -\\ln \\left(\\frac{\\exp(x_{j,t_j})}{\\sum_{i'} \\exp(x_{j,i'})}\\right)"
msgstr ""
"y_{j} = -\\ln \\left(\\frac{\\exp(x_{j,t_j})}{\\sum_{i'} \\exp(x_{j,i'})}\\right)"

#: nnabla.functions.categorical_cross_entropy:6
#: nnabla.functions.softmax_cross_entropy:6 of
msgid ""
"along dimension specified by axis (:math:`i` is the axis where normalization is "
"performed on)."
msgstr "軸で指定された次元に沿って (:math:`i` は正規化が実行される軸です ) 。"

#: nnabla.functions.softmax_cross_entropy:8 of
msgid ""
"SoftmaxCrossEntropy is equivalent to Softmax+CategoricalCrossEntropy, but "
"computing them at once has the effect of reducing computational error."
msgstr ""
"SoftmaxCrossEntropy は Softmax + CategoricalCrossEntropy と同等ですが、一度に計算"
"すると計算エラーを減らす効果があります。"

#: nnabla.functions.categorical_cross_entropy:8
#: nnabla.functions.softmax_cross_entropy:10 of
msgid ""
"N-D array. Typically indicates a score. :math:`(D_1 \\times ... \\times D_i "
"\\times ... \\times D_N)` [parameter]"
msgstr ""
"N-D 配列。 通常はスコアを示します。 :math:`(D_1 \\times ... \\times D_i "
"\\times ... \\times D_N)` [パラメータ]"

#: nnabla.functions.categorical_cross_entropy:11
#: nnabla.functions.softmax_cross_entropy:13 of
msgid ""
"N-D array of labels. :math:`(D_1 \\times ... \\times 1 \\times ... \\times D_N)` "
"[parameter]"
msgstr ""
"ラベルの N-D 配列。 :math:`(D_1 \\times ... \\times 1 \\times ... \\times D_N)` "
"[パラメータ]"

#: nnabla.functions.categorical_cross_entropy:18
#: nnabla.functions.softmax_cross_entropy:20 of
msgid ""
"N-D array of element-wise losses. :math:`(D_1 \\times ... \\times 1 \\times ... "
"\\times D_N)`"
msgstr ""
"要素ごとの損失の N-D 配列。 :math:`(D_1 \\times ... \\times 1 \\times ... "
"\\times D_N)`"

#: nnabla.functions.categorical_cross_entropy:1 of
msgid ""
"Element-wise cross entropy between `x` and the target `t` where targets are "
"given by a category index."
msgstr ""
"`x` とターゲット `t` の要素ごとのクロスエントロピー。ターゲットはカテゴリインデッ"
"クスによって指定されます。"

#: nnabla.functions.categorical_cross_entropy:3 of
msgid "y_{j} = -\\ln \\left( x_{j, t_j} \\right)"
msgstr "y_{j} = -\\ln \\left( x_{j, t_j} \\right)"

#: nnabla.functions.squared_error:1 of
msgid "Element-wise squared error"
msgstr "要素ごとの二乗誤差"

#: nnabla.functions.squared_error:3 of
msgid "y_i = \\left(x^{(0)}_i - x^{(1)}_i\\right)^2."
msgstr "y_i = \\left(x^{(0)}_i - x^{(1)}_i\\right)^2."

#: nnabla.functions.absolute_error:1 of
msgid "Element-wise absolute error"
msgstr "要素ごとの絶対誤差"

#: nnabla.functions.absolute_error:3 of
msgid "y_i = | x^{(0)}_i - x^{(1)}_i |."
msgstr "y_i = | x^{(0)}_i - x^{(1)}_i |."

#: nnabla.functions.huber_loss:1 of
msgid "Element-wise Huber loss"
msgstr "要素ごとの Huber loss"

#: nnabla.functions.huber_loss:3 of
msgid ""
"y_i= \\left\\{ \\begin{array}{ll}   d^2 & (|d| < \\delta)\\\\   \\delta (2 |d| - "
"\\delta) & ({\\rm otherwise}) \\end{array} \\right."
msgstr ""
"y_i= \\left\\{ \\begin{array}{ll}   d^2 & (|d| < \\delta)\\\\   \\delta (2 |d| - "
"\\delta) & ({\\rm otherwise}) \\end{array} \\right."

#: nnabla.functions.huber_loss:10 of
msgid "where :math:`d = x^{(0)}_i - x^{(1)}_i`"
msgstr ":math:`d = x^{(0)}_i - x^{(1)}_i` の箇所"

#: nnabla.functions.huber_loss:16 of
msgid "Delta [default=``1.0``]"
msgstr "デルタ [ default = ``1.0`` ]"

#: nnabla.functions.epsilon_insensitive_loss:1 of
msgid "Element-wise Epsilon Insensitive Loss"
msgstr "要素ごとの Epsilon Insensitive loss"

#: nnabla.functions.epsilon_insensitive_loss:3 of
msgid ""
"y_i= \\left\\{ \\begin{array}{ll}   | x^{(0)}_i - x^{(1)}_i | - \\epsilon & if "
"\\ \\ | x^{(0)}_i - x^{(1)}_i | > \\epsilon \\\\                 0 & otherwise "
"\\end{array} \\right."
msgstr ""
"y_i= \\left\\{ \\begin{array}{ll}   | x^{(0)}_i - x^{(1)}_i | - \\epsilon & if "
"\\ \\ | x^{(0)}_i - x^{(1)}_i | > \\epsilon \\\\                 0 & otherwise "
"\\end{array} \\right."

#: nnabla.functions.epsilon_insensitive_loss:14 of
msgid "Insensitive parameter."
msgstr "影響を受けないパラメータ。"

#: nnabla.functions.kl_multinomial:1 of
msgid "The Kullback Leibler Divergence for multinomial distributions."
msgstr "多項分布の Kullback Leibler Divergence。"

#: nnabla.functions.kl_multinomial:3 of
msgid "D = \\sum_i p_i \\log \\left( \\frac{p_i}{q_i} \\right)"
msgstr "D = \\sum_i p_i \\log \\left( \\frac{p_i}{q_i} \\right)"

#: nnabla.functions.kl_multinomial:6 of
msgid "N-D array of the source categorical probabilities"
msgstr "ソース・カテゴリカル確率の N-D 配列"

#: nnabla.functions.kl_multinomial:8 of
msgid "N-D array of the target categorical probabilities"
msgstr "ターゲット・カテゴリカル確率の N-D 配列"

#: nnabla.functions.kl_multinomial:14 of
msgid "Kullback Leibler divergence :math:`KL(p \\parallel q)`."
msgstr "Kullback Leibler divergence :math:`KL(p \\parallel q)` 。"

#: ../../python/api/function.rst:247
msgid "Signal Processing"
msgstr "信号処理"

#: nnabla.functions.interpolate:1 of
msgid "Resize an ND array with interpolation."
msgstr "補間で ND 配列のサイズを変更します。"

#: nnabla.functions.interpolate:3 of
msgid ""
"Scaling factors for spatial dimensions are determined by either ``scale`` or "
"``output_size``."
msgstr ""
"空間次元のスケーリング係数は、 ``scale`` または ``output_size`` のいずれかによっ"
"て決定されます。"

#: nnabla.functions.interpolate:6 of
msgid ""
"``nd = len(scale)`` or ``nd = len(output_size)`` determines the number of "
"spatial dimensions, and the last ``nd`` dimensions of the input ``x`` are "
"considered as the spatial dimensions to be resized."
msgstr ""
"``nd = len(scale)`` か ``nd = len(output_size)`` が空間次元を決定します。 入力 "
"``x`` の最後の数 ``nd`` 次元が空間次元とされます。"

#: nnabla.functions.interpolate:11 of
msgid ""
"If ``scale`` is given, the ``output_size`` is calculated by ``output_size[i] = "
"floor(scale[i] * x.shape[i - len(scale)])``."
msgstr ""
"``scale`` が指定された場合、 ``output_size`` は ``output_size[i] = "
"floor(scale[i] * x.shape[i - len(scale)])`` によって計算されます。"

#: nnabla.functions.interpolate:16 of
msgid ""
"import numpy as np\n"
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"\n"
"x_data = np.random.rand(64, 3, 224, 224)\n"
"x = nn.Variable.from_numpy_array(x_data)\n"
"\n"
"# Resize by scales\n"
"y = F.interpolate(x, scale=(2, 2), mode='linear')\n"
"print(y.shape)  # (64, 3, 448, 448)\n"
"y.forward()\n"
"print(y.d)  # Print output\n"
"\n"
"# Resize to a size\n"
"y2 = F.interpolate(x, output_size=(320, 257), mode='linear')\n"
"print(y2.shape)  # (64, 3, 320, 257)\n"
"y2.forward()\n"
"print(y2.d)  # Print output"
msgstr ""

#: nnabla.functions.interpolate:37 of
msgid "N-D array with an arbitrary number of dimensions."
msgstr "任意の次元数の N-D 次元配列。"

#: nnabla.functions.interpolate:39 of
msgid ""
"Scale factors along axes. The default is ``None``, and if this is omitted, "
"``output_size`` must be specified."
msgstr ""
"軸に沿った倍率。 デフォルトは ``None`` です。これを省略する場合は、 "
"``output_size`` を指定する必要があります。"

#: nnabla.functions.interpolate:42 of
msgid ""
"The output sizes for axes. If this is given, the scale factors are determined by "
"the output sizes and the input sizes. The default is ``None``, and if this is "
"omitted, ``scale`` must be specified."
msgstr ""
"軸の出力サイズ。 これが与えられている場合、スケール係数は出力サイズと入力サイズに"
"よって決定されます。 デフォルトは ``None`` です。これを省略する場合は、 "
"``scale`` を指定する必要があります。"

#: nnabla.functions.interpolate:47 of
msgid ""
"Interpolation mode chosen from ('linear'|'nearest'). The default is 'linear'."
msgstr ""
"(‘linear’|’nearest’) から選択された補間モード。デフォルトは ``linear`` です。"

#: nnabla.functions.interpolate:50 of
msgid ""
"If true, the corner pixels of input and output arrays are aligned, such that the "
"output corner pixels have the same values with the input corner pixels. The "
"default is ``None``, and it becomes ``True`` if mode is 'linear', otherwise "
"``False``."
msgstr ""
"true の場合、入力および出力配列のコーナーピクセルは、出力コーナーピクセルが入力"
"コーナーピクセルと同じ値になるように配置されます。デフォルトは ``None`` で、モー"
"ドが ‘linear’の場合 ``True`` になり、それ以外は ``False`` になります。"

#: nnabla.functions.fft:1 of
msgid "Complex-to-complex Discrete Fourier Transform,"
msgstr "Complex-to-complex 離散フーリエ変換。"

#: nnabla.functions.fft:3 of
msgid ""
"X_{k_1, \\ldots, k_d} = \\sum_{n_1=0}^{N_1-1} \\dots \\sum_{n_d=0}^{N_d-1} "
"x_{n_1, \\ldots, n_d} \\exp\\left(-2 \\pi j \\left( \\sum_{i=0}^{d} \\frac{k_i "
"n_i}{N_i} \\right) \\right),"
msgstr ""
"X_{k_1, \\ldots, k_d} = \\sum_{n_1=0}^{N_1-1} \\dots \\sum_{n_d=0}^{N_d-1} "
"x_{n_1, \\ldots, n_d} \\exp\\left(-2 \\pi j \\left( \\sum_{i=0}^{d} \\frac{k_i "
"n_i}{N_i} \\right) \\right),"

#: nnabla.functions.fft:7 nnabla.functions.ifft:7 nnabla.functions.pow2_quantize:37
#: nnabla.functions.pow2_quantize:59 of
msgid "where"
msgstr "ここでは、"

#: nnabla.functions.fft:9 nnabla.functions.ifft:9 of
msgid "k_i = 0, \\ldots, N_i - 1."
msgstr "k_i = 0, \\ldots, N_i - 1 となります。"

#: nnabla.functions.fft:13 nnabla.functions.ifft:13 of
msgid ""
"This function now supports 1-D, 2-D, and 3-D DFT with or without the leading "
"batch dimension(s)."
msgstr ""
"この関数は、現在、主要なバッチ次元の有無にかかわらず、 1-D、 2-D、および 3-D DFT "
"をサポートしています。"

#: nnabla.functions.fft:15 nnabla.functions.ifft:15 of
msgid ""
"The input is expected to be complex-valued with at least signal_ndim + 1 "
"dimensions. The last dimension has a shape of two where x[..., 0] is the real "
"part and x[..., 1] the imaginary part."
msgstr ""
"入力は、少なくとも signal_ndim + 1 次元の複素数値であることが期待されています。 "
"最後の次元は2つの形状をしており、 x […、0] は実数部であり、 x […、1] は虚数部で"
"す。"

#: nnabla.functions.fft:20 of
msgid ""
"import numpy as np\n"
"import nnabla as nn\n"
"import nnabla.functions as F\n"
"from nnabla.ext_utils import get_extension_context\n"
"\n"
"ctx = get_extension_context(\"cudnn\")\n"
"nn.set_default_context(ctx)\n"
"\n"
"# Example for a batched 2D-FFT and 2D-IFFT (batch-size: 2, data-size: 4x3)\n"
"x_data = np.random.rand(2, 4, 3) + 1j * np.random.rand(2, 4, 3)\n"
"x = nn.Variable.from_numpy_array(np.stack([np.real(x_data), np.imag(x_data)], "
"axis=3))\n"
"y = F.fft(x, signal_ndim=2, normalized=True)\n"
"z = F.ifft(y, signal_ndim=2, normalized=True)\n"
"z.forward()\n"
"\n"
"np.allclose(z.d[..., 0] + 1j*z.d[...,1], x_data)"
msgstr ""

#: nnabla.functions.binary_connect_convolution:38
#: nnabla.functions.binary_weight_convolution:36 nnabla.functions.fft:40
#: nnabla.functions.ifft:19 nnabla.functions.inq_convolution:18 of
msgid "Input."
msgstr "入力。"

#: nnabla.functions.fft:42 nnabla.functions.ifft:21 of
msgid "The number of dimensions for each signal. It must be 1, 2, or 3."
msgstr "各信号の次元数。 1、2、または3でなければなりません。"

#: nnabla.functions.fft:44 of
msgid ""
"Use unitary normalization. If `True`, the normalization constant :math:`"
"\\sqrt{\\frac{1}{\\prod_{i=1}^{d} N_i}}` is multiplied. [default=``False``]"
msgstr ""
"単一正規化を使用します。 `True` の場合、正規化定数 :math:`\\sqrt{\\frac{1}"
"{\\prod_{i=1}^{d} N_i}}` は乗算されます。 [ default = ``False`` ]"

#: nnabla.functions.fft:48 of
msgid "FFT transformed signal."
msgstr "FFT変換された信号。"

#: nnabla.functions.ifft:1 of
msgid "Complex-to-complex inverse Discrete Fourier Transform,"
msgstr "Complex-to-complex 逆離散フーリエ変換、"

#: nnabla.functions.ifft:3 of
msgid ""
"X_{k_1, \\ldots, k_d} = \\frac{1}{\\prod_{i=1}^{d} N_i} \\sum_{n_1=0}^{N_1-1} "
"\\dots \\sum_{n_d=0}^{N_d-1} x_{n_1, \\ldots, n_d} \\exp\\left(2 \\pi j "
"\\left( \\sum_{i=0}^{d} \\frac{k_i n_i}{N_i} \\right) \\right),"
msgstr ""
"X_{k_1, \\ldots, k_d} = \\frac{1}{\\prod_{i=1}^{d} N_i} \\sum_{n_1=0}^{N_1-1} "
"\\dots \\sum_{n_d=0}^{N_d-1} x_{n_1, \\ldots, n_d} \\exp\\left(2 \\pi j "
"\\left( \\sum_{i=0}^{d} \\frac{k_i n_i}{N_i} \\right) \\right),"

#: nnabla.functions.ifft:23 of
msgid ""
"Use unitary normalization. If `True`, the normalization constant :math:`\\frac{1}"
"{\\prod_{i=1}^{d} N_i}` becomes :math:`\\sqrt{\\frac{1}{\\prod_{i=1}^{d} N_i}}`. "
"[default=``False``]"
msgstr ""
"単一正規化を使用します。 `True` の場合、正規化定数 :math:`\\frac{1}{\\prod_{i=1}"
"^{d} N_i}` は :math:`\\sqrt{\\frac{1}{\\prod_{i=1}^{d} N_i}}` になります。 "
"[ default = ``False`` ]"

#: nnabla.functions.ifft:27 of
msgid "IFFT transformed signal."
msgstr "IFFT 変換された信号。"

#: nnabla.functions.stft:1 of
msgid "Computes the short-time Fourier transform"
msgstr "短時間フーリエ変換を計算します"

#: nnabla.functions.istft:23 nnabla.functions.stft:3 of
msgid "Time domain sequence of size `batch_size x sample_size`."
msgstr "`batch_size x sample_size` サイズの時間領域列。"

#: nnabla.functions.istft:11 nnabla.functions.stft:5 of
msgid "Size of STFT analysis window."
msgstr "STFT 分析ウィンドウのサイズ。"

#: nnabla.functions.istft:13 nnabla.functions.stft:7 of
msgid "Number of samples that we shift the window, also called `hop size`."
msgstr "`hop size` とも呼ばれる、ウィンドウをシフトするサンプルの数。"

#: nnabla.functions.stft:9 of
msgid "Size of the FFT, the output will have `fft_size // 2+ 1` frequency bins."
msgstr "FFT のサイズ。出力には `fft_size // 2+ 1` の周波数ビンがあります。"

#: nnabla.functions.istft:17 nnabla.functions.stft:11 of
msgid ""
"Analysis window, can be either `hanning`, `hamming` or `rectangular`. For "
"convenience, also `window_type=None` is supported which is equivalent to "
"`window_type='rectangular'`."
msgstr ""
"分析ウィンドウは、 `hanning` 、 `hamming` 、または `rectangular` のいずれかになり"
"ます。便宜上、 `window_type='rectangular'` と同等の `window_type=None` もサポート"
"されています。"

#: nnabla.functions.stft:14 of
msgid ""
"If `True`, then the signal `x` is padded by half the FFT size using reflection "
"padding."
msgstr ""
"`True` の場合、信号 `x` は、反射パディングを使用して FFT サイズの半分でパディング"
"されます。"

#: nnabla.functions.stft:16 of
msgid ""
"Padding mode, which can be `'constant'` or `'reflect'`. `'constant'` pads with "
"`0`."
msgstr ""
"`'constant'` または `'reflect'` のパディングモード。 `0` の `'constant'` パッド。"

#: nnabla.functions.stft:19 of
msgid ""
"Returns real and imaginary parts of STFT result.  * :obj:`~nnabla.Variable`: "
"Real part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`. * :obj:"
"`~nnabla.Variable`: Imaginary part of STFT of size `batch x fft_size//2 + 1 x "
"frame_size`."
msgstr ""

#: nnabla.functions.stft:19 of
msgid "Returns real and imaginary parts of STFT result."
msgstr "STFT 結果の実数部と虚数部を戻します。"

#: nnabla.functions.stft:21 of
msgid ""
":obj:`~nnabla.Variable`: Real part of STFT of size `batch_size x fft_size//2 + 1 "
"x frame_size`."
msgstr ""
":obj:`~nnabla.Variable`: `batch_size x fft_size//2 + 1 x frame_size` サイズの "
"STFT　の実部。"

#: nnabla.functions.stft:22 of
msgid ""
":obj:`~nnabla.Variable`: Imaginary part of STFT of size `batch x fft_size//2 + 1 "
"x frame_size`."
msgstr ""
":obj:`~nnabla.Variable`: `batch x fft_size//2 + 1 x frame_size` サイズの STFT の"
"架空の部分。"

#: nnabla.functions.istft:1 of
msgid "Computes the inverse shoft-time Fourier transform"
msgstr "逆短時間フーリエ変換を計算します"

#: nnabla.functions.istft:3 of
msgid ""
"Note: We use a constant square inverse window for the reconstruction of the time-"
"domain signal, therefore, the first and last `window_size - stride` are not "
"perfectly reconstructed."
msgstr ""
"注意: 時間領域信号の再構成には、定数二乗逆ウィンドウを使用するため、最初と最後の "
"`window_size - stride` は完全には再構成されません。"

#: nnabla.functions.istft:7 of
msgid "Real part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`."
msgstr "`batch_size x fft_size//2 + 1 x frame_size` サイズのSTFT の実部。"

#: nnabla.functions.istft:9 of
msgid "Imaginary part of STFT of size `batch_size x fft_size//2 + 1 x frame_size`."
msgstr "`batch_size x fft_size//2 + 1 x frame_size` サイズの STFT の架空の部分。"

#: nnabla.functions.istft:15 of
msgid "Size of the FFT, (STFT has `fft_size // 2 + 1` frequency bins)."
msgstr "FFT のサイズ、 (STFT は `fft_size // 2 + 1` 周波数ビンがあります)。"

#: nnabla.functions.istft:20 of
msgid ""
"If `True`, then it is assumed that the time-domain signal has centered frames."
msgstr "`True` の場合、時間領域信号が中心にあるフレームであると想定されます。"

#: ../../python/api/function.rst:256
msgid "Quantized Neural Network Layers"
msgstr "量子化ニューラルネットワーク層"

#: nnabla.functions.binary_sigmoid:1 of
msgid "Element-wise binary sigmoid function. In the forward pass, it computes"
msgstr "要素ごとのバイナリ sigmoid 関数。forward パスでは"

#: nnabla.functions.binary_sigmoid:3 of
msgid ""
"f(x) = \\begin{cases}     1 & (x > 0) \\\\     0 & ({\\rm "
"otherwise})\\end{cases},"
msgstr ""
"f(x) = \\begin{cases}     1 & (x > 0) \\\\     0 & ({\\rm "
"otherwise})\\end{cases},"

#: nnabla.functions.binary_sigmoid:8 nnabla.functions.binary_tanh:9 of
msgid ""
"but in the backward pass, a straight-through approximation of the gradient is "
"used, i.e.,"
msgstr ""
"を計算しますが、backward パスでは勾配の直線近似が使用され、すなわち、以下のように"
"なります。"

#: nnabla.functions.binary_sigmoid:11 of
msgid ""
"\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}     0 & (|x| \\geq 1) \\"
"\\     \\frac{1}{2} & ({\\rm otherwise}) \\end{cases}."
msgstr ""
"\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}     0 & (|x| \\geq 1) \\"
"\\     \\frac{1}{2} & ({\\rm otherwise}) \\end{cases}."

#: nnabla.functions.binary_sigmoid:20 nnabla.functions.binary_tanh:20 of
msgid ""
"`Courbariaux, Matthieu, and Yoshua Bengio. Binarynet: Training deep neural "
"networks with weights and activations constrained to+ 1 or-1. <https://arxiv.org/"
"abs/1602.02830>`_"
msgstr ""
"`Courbariaux, Matthieu, and Yoshua Bengio. Binarynet: Training deep neural "
"networks with weights and activations constrained to+ 1 or-1. <https://arxiv.org/"
"abs/1602.02830>`_"

#: nnabla.functions.binary_connect_affine:37 nnabla.functions.binary_sigmoid:24
#: nnabla.functions.binary_tanh:24 nnabla.functions.binary_weight_affine:35
#: nnabla.functions.inq_affine:18 of
msgid "Input ."
msgstr "入力。"

#: nnabla.functions.binary_connect_affine:55 nnabla.functions.binary_sigmoid:27
#: nnabla.functions.binary_tanh:27 nnabla.functions.binary_weight_affine:56
#: nnabla.functions.inq_affine:45 of
msgid "Output."
msgstr "出力。"

#: nnabla.functions.binary_tanh:1 of
msgid "Element-wise binary tanh function. In the forward pass, it computes"
msgstr "要素ごとのバイナリ tanh 関数。forward パスでは、以下の計算をします。"

#: nnabla.functions.binary_tanh:3 of
msgid ""
"f(x) = \\begin{cases}     1 & (x > 0) \\\\     -1 & ({\\rm otherwise}) "
"\\end{cases},"
msgstr ""
"f(x) = \\begin{cases}     1 & (x > 0) \\\\     -1 & ({\\rm otherwise}) "
"\\end{cases},"

#: nnabla.functions.binary_tanh:12 of
msgid ""
"\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}     0 & (|x| \\geq 1) \\"
"\\     1 & ({\\rm otherwise}) \\end{cases}."
msgstr ""
"\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}     0 & (|x| \\geq 1) \\"
"\\     1 & ({\\rm otherwise}) \\end{cases}."

#: nnabla.functions.binary_connect_affine:1 of
msgid ""
"This function provides a BinaryConnect affine layer. It computes in the forward "
"pass"
msgstr ""
"この関数は BinaryConnect affine 層を提供します。forward パスでは以下の計算しま"
"す。"

#: nnabla.functions.binary_connect_affine:4 of
msgid "y_j = \\sum_{i} sign(w_{j,i}) x_i,"
msgstr "y_j = \\sum_{i} sign(w_{j,i}) x_i,"

#: nnabla.functions.binary_connect_affine:8 of
msgid ""
"i.e., the weights :math:`w_{j,i}` are binarized to :math:`sign(w_{j,i})` and, "
"hence, each weight is in :math:`\\{-1,\\,1\\}`. By this weight binarization, the "
"inner product computations do not require any multiplications anymore as they "
"turn into additions/subtractions."
msgstr ""
"つまり、重み :math:`w_{j,i}` は :math:`sign(w_{j,i})` に 2 値化されるため、各重み"
"は :math:`\\{-1,\\,1\\}` になります。この重みの 2 値化により、内積の計算は、加算"
"／減算になるため、乗算を必要としません。"

#: nnabla.functions.binary_connect_affine:13
#: nnabla.functions.binary_connect_convolution:14 of
msgid ""
"This function should be used together with :meth:`~nnabla.functions."
"batch_normalization`."
msgstr ""
"この関数は、 :meth:`~nnabla.functions.batch_normalization` と併せて使用される必要"
"があります。"

#: nnabla.functions.binary_connect_affine:18
#: nnabla.functions.binary_connect_convolution:25 of
msgid ""
"1) If you would like to share the binary weights between other layers, please "
"use the standard, floating value weights (`weight`) and not the binary weights "
"(`binary_weight`)."
msgstr ""
"1) 他の標準層の間でバイナリ重みを共有する場合は、バイナリ重み "
"( `binary_weight` ) ではなく、標準の浮動小数点値重み ( `weight` ) を使用してくだ"
"さい。"

#: nnabla.functions.binary_connect_affine:22
#: nnabla.functions.binary_connect_convolution:29
#: nnabla.functions.binary_weight_affine:26
#: nnabla.functions.binary_weight_convolution:26 of
msgid ""
"2) The weights and the binary weights become in sync only after a call to :meth:"
"`~nnabla.Variable.forward`, and not after a call to :meth:`~nnabla.Variable."
"backward`. If you wish to store the parameters of the network, remember to call :"
"meth:`~nnabla.Variable.forward`, once before doing so, otherwise the weights and "
"the binary weights will not be in sync."
msgstr ""
"2) 重みとバイナリの重みは、 :meth:`~nnabla.Variable.forward` の呼び出し後にのみ同"
"期し、 :meth:`~nnabla.Variable.backward` の呼び出し後には同期しません。ネットワー"
"クのパラメータを保存したい場合は、必ず :meth:`~nnabla.Variable.forward` を呼び出"
"してから行ってください。そうしないと、重みとバイナリの重みが同期しなくなります。"

#: nnabla.functions.binary_connect_affine:28
#: nnabla.functions.binary_connect_convolution:35
#: nnabla.functions.binary_weight_affine:32
#: nnabla.functions.binary_weight_convolution:33 of
msgid ""
"3) CPU and GPU implementations now use floating values for `binary_weight`, "
"since this function is for simulation purposes."
msgstr ""
"3) CPU と GPU の実装では、この関数はシミュレーションを目的としているため、 "
"`binary_weight` に浮動小数点値を使用するようになりました。"

#: nnabla.functions.binary_connect_affine:33
#: nnabla.functions.binary_connect_convolution:18 of
msgid ""
"`M. Courbariaux, Y. Bengio, and J.-P. David. BinaryConnect: Training Deep Neural "
"Networks with binary weights during propagations. <https://arxiv.org/"
"abs/1511.00363>`_"
msgstr ""
"`M. Courbariaux, Y. Bengio, and J.-P. David. BinaryConnect: Training Deep Neural "
"Networks with binary weights during propagations. <https://arxiv.org/"
"abs/1511.00363>`_"

#: nnabla.functions.binary_connect_affine:39 nnabla.functions.inq_affine:20 of
msgid "Weight . [parameter]"
msgstr "重み。 [パラメータ]"

#: nnabla.functions.binary_connect_affine:42 of
msgid "Binarized weight . [parameter]"
msgstr "2 値化された重み。 [パラメータ]"

#: nnabla.functions.binary_connect_affine:45
#: nnabla.functions.binary_connect_convolution:46
#: nnabla.functions.binary_weight_affine:46
#: nnabla.functions.binary_weight_convolution:47 nnabla.functions.inq_affine:26
#: nnabla.functions.inq_convolution:26 of
msgid "Bias. [optional][parameter]"
msgstr "バイアス。[オプション][パラメータ]"

#: nnabla.functions.binary_connect_affine:51
#: nnabla.functions.binary_connect_convolution:64
#: nnabla.functions.binary_weight_affine:52
#: nnabla.functions.binary_weight_convolution:65 of
msgid "Input value at zero is quantized to this value. [default=``1.0``]"
msgstr "ゼロでの入力値は、この値に量子化されます。 [ default = ``1.0`` ]"

#: nnabla.functions.binary_connect_convolution:1 of
msgid ""
"This function provides a BinaryConnect convolution layer. It computes in the "
"forward pass"
msgstr ""
"この関数は BinaryConnect convolution 層を提供します。forward パスでは以下の計算し"
"ます。"

#: nnabla.functions.binary_connect_convolution:4 of
msgid ""
"y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b "
"+ j},"
msgstr ""
"y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b "
"+ j},"

#: nnabla.functions.binary_connect_convolution:8 of
msgid ""
"i.e., the weights :math:`w_{n, m, i, j}` are binarized to :math:`sign(w_{n, m, "
"i, j})` and, hence, each weight is in :math:`\\{-1,\\,1\\}`. By this weight "
"binarization, the inner product computations do not require any multiplications "
"anymore as they turn into additions/subtractions."
msgstr ""
"つまり、重み :math:`w_{n, m, i, j}` は :math:`sign(w_{n, m, i, j})` に2 値化され"
"るため、各重みは :math:`\\{-1,\\,1\\}` になります。この重みの 2 値化により、内積"
"の計算は、加算／減算になるため、乗算を必要としません。"

#: nnabla.functions.binary_connect_convolution:16
#: nnabla.functions.binary_weight_affine:14
#: nnabla.functions.binary_weight_convolution:14
#: nnabla.functions.inq_convolution:12 of
msgid "Reference"
msgstr "参照"

#: nnabla.functions.binary_connect_convolution:40
#: nnabla.functions.binary_weight_affine:37
#: nnabla.functions.binary_weight_convolution:38
#: nnabla.functions.inq_convolution:20 of
msgid "Weight. [parameter]"
msgstr "重み。[パラメータ]"

#: nnabla.functions.binary_connect_convolution:43
#: nnabla.functions.binary_weight_affine:40
#: nnabla.functions.binary_weight_convolution:41 of
msgid "Binarized weight. [parameter]"
msgstr "2値化された重み。[パラメータ]"

#: nnabla.functions.binary_weight_affine:1 of
msgid ""
"This function provides a Binary Weight Network affine layer. It computes in the "
"forward pass"
msgstr ""
"この関数は Binary Weight Network affine 層を提供します。forward パスでは以下の計"
"算します。"

#: nnabla.functions.binary_weight_affine:4 of
msgid "y_j = \\frac{1}{\\|\\mathbf{w}_j\\|_{\\ell_1}} \\sum_{i} sign(w_{j,i}) x_i"
msgstr "y_j = \\frac{1}{\\|\\mathbf{w}_j\\|_{\\ell_1}} \\sum_{i} sign(w_{j,i}) x_i"

#: nnabla.functions.binary_weight_affine:8 of
msgid ""
"i.e., the weights :math:`w_{j,i}` are binarized to :math:`sign(w_{j,i})` and, "
"hence, each weight is in :math:`\\{-1,\\,1\\}`. By this weight binarization, the "
"inner product computations turn into additions/subtractions which are followed "
"by multiplication with the scaling factor :math:`\\alpha_j = \\frac{1}{\\|"
"\\mathbf{w}_j\\|_{\\ell_1}}`."
msgstr ""
"つまり、重み :math:`w_{j,i}` は :math:`sign(w_{j,i})` に 2 値化されるため、各重み"
"は :math:`\\{-1,\\,1\\}` になります。この重みの 2 値化により、内積の計算は加算／"
"減算になり、スケーリング係数 :math:`\\alpha_j = \\frac{1}{\\|\\mathbf{w}_j\\|"
"_{\\ell_1}}` との乗算が続きます。"

#: nnabla.functions.binary_weight_affine:16
#: nnabla.functions.binary_weight_convolution:16 of
msgid ""
"`Rastegari, Mohammad, et al. XNOR-Net: ImageNet Classification Using Binary "
"Convolutional Neural Networks. <https://arxiv.org/abs/1603.05279>`_"
msgstr ""
"`Rastegari, Mohammad, et al. XNOR-Net: ImageNet Classification Using Binary "
"Convolutional Neural Networks. <https://arxiv.org/abs/1603.05279>`_"

#: nnabla.functions.binary_weight_affine:22 of
msgid ""
"1) If you would like to share the binary weights with other layers, please use "
"the standard, floating value weights (`weight`) and not the binary weights "
"(`binary_weight`)."
msgstr ""
"1) 他の標準層の間でバイナリ重みを共有する場合は、バイナリ重み "
"( `binary_weight` ) ではなく、標準の浮動小数点値重み ( `weight` ) を使用してくだ"
"さい。"

#: nnabla.functions.binary_weight_affine:43
#: nnabla.functions.binary_weight_convolution:44 of
msgid "Alpha. [parameter]"
msgstr "アルファ。[パラメータ]"

#: nnabla.functions.binary_weight_convolution:1 of
msgid ""
"This function provides a Binary Weight Network convolution layer. It computes in "
"the forward pass"
msgstr ""
"この関数は Binary Weight Network convolution 層を提供します。foward パスでは以下"
"の計算をします。"

#: nnabla.functions.binary_weight_convolution:4 of
msgid ""
"y_{n, a, b} = \\frac{1}{\\|\\mathbf{w}_n\\|_{\\ell_1}} \\sum_{m} \\sum_{i} "
"\\sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b + j}."
msgstr ""
"y_{n, a, b} = \\frac{1}{\\|\\mathbf{w}_n\\|_{\\ell_1}} \\sum_{m} \\sum_{i} "
"\\sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b + j}."

#: nnabla.functions.binary_weight_convolution:8 of
msgid ""
"i.e., the weights :math:`w_{n, m, i, j}` are binarized to :math:`sign(w_{n, m, "
"i, j})` and, hence, each weight is in :math:`\\{-1,\\,1\\}`. By this weight "
"binarization, the inner product computations turn into additions/subtractions "
"which are followed by multiplication with the scaling factor :math:`\\alpha_n = "
"\\frac{1}{\\|\\mathbf{w}_n\\|_{\\ell_1}}`."
msgstr ""
"つまり、重み :math:`w_{n, m, i, j}` は :math:`sign(w_{n, m, i, j})` に 2 値化され"
"るため、各重みは :math:`\\{-1,\\,1\\}` になります。この重みの 2 値化により、内積"
"の計算は加算／減算になり、スケーリング係数 :math:`\\alpha_n = \\frac{1}{\\|"
"\\mathbf{w}_n\\|_{\\ell_1}}` との乗算が続きます。"

#: nnabla.functions.binary_weight_convolution:22 of
msgid ""
"1) If you would like to share the binary weights between other standard layers, "
"please use the standard, floating value weights (`weight`) and not the binary "
"weights (`binary_weight`)."
msgstr ""
"1) 他の標準層の間でバイナリ重みを共有する場合は、バイナリ重み "
"( `binary_weight` ) ではなく、標準の浮動小数点値重み (`weight`) を使用してくださ"
"い。"

#: nnabla.functions.fixed_point_quantize:1 of
msgid "Fixed Point Quantize"
msgstr "固定小数点量子化"

#: nnabla.functions.fixed_point_quantize:5 nnabla.functions.pow2_quantize:5 of
msgid "Indicate the signed number or the unsigned number. Default is true."
msgstr "符号あり、または、符号なしを示します。デフォルトは true です。"

#: nnabla.functions.fixed_point_quantize:7 of
msgid ""
"Bit width used. Note that `sign` consumes one bit. :math:`n-1` is used for "
"number representation in `signed` case."
msgstr ""
"使用されるビット幅。 `sign` は 1 ビットを消費することに注意してください。 :math:"
"`n-1` は `signed` の場合の数値表現に使用されます。"

#: nnabla.functions.fixed_point_quantize:9 of
msgid "Step size."
msgstr "ステップサイズ。"

#: nnabla.functions.fixed_point_quantize:11 nnabla.functions.pow2_quantize:13 of
msgid "If true, quantize input, otherwise not."
msgstr "true　の場合、入力を量子化、そうでなければしない。"

#: nnabla.functions.fixed_point_quantize:13 nnabla.functions.pow2_quantize:15 of
msgid "If true, STE is not 1."
msgstr "true の場合、 STE は1ではありません。"

#: nnabla.functions.fixed_point_quantize:19 of
msgid "``nnabla.function_bases.fixed_point_quantize``."
msgstr "``nnabla.function_bases.fixed_point_quantize``."

#: nnabla.functions.fixed_point_quantize:21 of
msgid "In the forward pass,"
msgstr "forward パスでは、"

#: nnabla.functions.fixed_point_quantize:23 of
msgid ""
"\\begin{equation}     q_i= \\left\\{        \\begin{array}{ll}             max & "
"if \\ \\ \\ x_i > max \\\\             sign(x_i) \\times floor(|x_i| "
"\\delta^{-1} + 2^{-1}) \\times \\delta & if \\ \\ min \\le x_i \\le max \\"
"\\             min & if \\ \\ x_i < min \\\\        \\end{array} \\right., "
"\\end{equation}"
msgstr ""
"\\begin{equation}     q_i= \\left\\{        \\begin{array}{ll}             max & "
"if \\ \\ \\ x_i > max \\\\             sign(x_i) \\times floor(|x_i| "
"\\delta^{-1} + 2^{-1}) \\times \\delta & if \\ \\ min \\le x_i \\le max \\"
"\\             min & if \\ \\ x_i < min \\\\        \\end{array} \\right., "
"\\end{equation}"

#: nnabla.functions.fixed_point_quantize:34 of
msgid ""
"where :math:`\\delta` is the step size, :math:`(min, max) :=(- (2^{n-1} - "
"1)\\delta, (2^{n-1} - 1)\\delta)` if :math:`sign` is true, :math:`(min, max) := "
"(0, (2^n - 1) \\delta)` otherwise, and :math:`n` is the total bit-width used."
msgstr ""
"ここで、:math:`\\delta` はステップサイズで、 :math:`(min, max) :=(- (2^{n-1} - "
"1)\\delta, (2^{n-1} - 1)\\delta)` :math:`sign` が true である場合、 :math:`(min, "
"max) := (0, (2^n - 1) \\delta)` 、そうでなければ、 :math:`n` は合計ビット幅が使用"
"されます。"

#: nnabla.functions.fixed_point_quantize:39 nnabla.functions.min_max_quantize:26 of
msgid "In the backward pass when using `ste_fine_grained` as false,"
msgstr "`ste_fine_grained` を false として backward パスで使用する場合、"

#: nnabla.functions.fixed_point_quantize:41 of
msgid ""
"\\begin{equation}     \\frac{\\partial q_i}{\\partial x_i} = 1. \\end{equation}"
msgstr ""

#: nnabla.functions.fixed_point_quantize:47 nnabla.functions.min_max_quantize:33 of
msgid "In the backward pass when using `ste_fine_grained` as true,"
msgstr "`ste_fine_grained` を true として backward パスで使用する場合、"

#: nnabla.functions.fixed_point_quantize:49 of
msgid ""
"\\begin{equation}     \\frac{\\partial q_i}{\\partial x_i}= \\left"
"\\{             \\begin{array}{ll}                         0 & if \\ \\ \\ x_i > "
"max \\\\                     1 & if \\ \\ min \\le x_i \\le max \\"
"\\                     0 & if \\ \\ x_i < min \\\\             \\end{array} "
"\\right.. \\end{equation}"
msgstr ""

#: nnabla.functions.fixed_point_quantize:62 of
msgid ""
"Quantized values are stored as floating point number, since this function is for "
"simulation purposes."
msgstr ""
"この関数はシミュレーション用であるため、量子化された値は浮動小数点数として保存さ"
"れます。"

#: nnabla.functions.min_max_quantize:1 of
msgid "Min-max quantization."
msgstr "最小最大量子化。"

#: nnabla.functions.min_max_quantize:3 of
msgid ""
"This function uniformly quantizes values in the range of min and max "
"quantization levels."
msgstr "この関数は、最小および最大量子化レベルの範囲の値を均一に量子化します。"

#: nnabla.functions.min_max_quantize:5 of
msgid "Min-max quantization is defined as the following equation"
msgstr "最小最大量子化は、次の式として定義されます。"

#: nnabla.functions.min_max_quantize:7 of
msgid ""
"y = round \\left(\\frac{\\min(\\max(x, m), M) - m}{scale} \\right) \\times scale "
"+ m,"
msgstr ""
"y = round \\left(\\frac{\\min(\\max(x, m), M) - m}{scale} \\right) \\times scale "
"+ m,"

#: nnabla.functions.min_max_quantize:11 of
msgid "where the :math:`scale` is defined as"
msgstr "ここで、 :math:`scale` が"

#: nnabla.functions.min_max_quantize:13 of
msgid "scale = \\frac{M - m}{M_q - m_q},"
msgstr "scale = \\frac{M - m}{M_q - m_q},"

#: nnabla.functions.min_max_quantize:17 of
msgid "and"
msgstr "および"

#: nnabla.functions.min_max_quantize:19 of
msgid "m_q = ql_{min}, \\\\ M_q = ql_{max}, \\\\ m = qr_{min}, \\\\ M = qr_{max}."
msgstr ""
"m_q = ql_{min}, \\\\ M_q = ql_{max}, \\\\ m = qr_{min}, \\\\ M = qr_{max} として"
"定義されます。"

#: nnabla.functions.min_max_quantize:28 nnabla.functions.pow2_quantize:78 of
msgid "\\frac{\\partial q_i}{\\partial x_i} = 1."
msgstr "\\frac{\\partial q_i}{\\partial x_i} = 1."

#: nnabla.functions.min_max_quantize:35 of
msgid ""
"\\frac{\\partial q_i}{\\partial x_i}= \\left\\{ \\begin{array}{ll}   0 & if \\ "
"\\ \\ x_i > M \\\\   1 & if \\ \\ m \\le x_i \\le M \\\\   0 & if \\ \\ x_i < m "
"\\\\ \\end{array} \\right.."
msgstr ""
"\\frac{\\partial q_i}{\\partial x_i}= \\left\\{ \\begin{array}{ll}   0 & if \\ "
"\\ \\ x_i > M \\\\   1 & if \\ \\ m \\le x_i \\le M \\\\   0 & if \\ \\ x_i < m "
"\\\\ \\end{array} \\right.."

#: nnabla.functions.min_max_quantize:44 of
msgid ":math:`qr_{min}` and :math:`qr_{max}` are treaded as follows."
msgstr ":math:`qr_{min}` と :math:`qr_{max}` は次のように処理されます。"

#: nnabla.functions.min_max_quantize:46 of
msgid ""
"`x_min_max` is `True` and `ema` is `True`: Exponential moving average are "
"computed for each :math:`min(x)` and :math:`max(x)` then stored in :math:"
"`qr_{min}` and :math:`qr_{max}`."
msgstr ""
"`x_min_max` が `True` で `ema` が `True` : :math:`min(x)` と :math:`max(x)` ごと"
"に指数移動平均が計算され、 :math:`qr_{min}` と :math:`qr_{max}` に保存されます。"

#: nnabla.functions.min_max_quantize:49 of
msgid ""
"`x_min_max` is `True` and `ema` is `False`: :math:`min(x)` and :math:`max(x)` "
"are computed then stored in :math:`qr_{min}` and :math:`qr_{max}`."
msgstr ""
"`x_min_max` が `True` で `ema` が `False` : :math:`min(x)` と :math:`max(x)` が計"
"算され、 :math:`qr_{min}` と :math:`qr_{max}` に保存されます。"

#: nnabla.functions.min_max_quantize:51 of
msgid ""
"`x_min_max` is `False` and `ema` is `True`: Exponential moving average stored "
"in :math:`qr_{min}` and :math:`qr_{max}` are used."
msgstr ""
"`x_min_max` が `False` で `ema` が `True` : :math:`qr_{min}` と :math:`qr_{max}` "
"に保存されている指数移動平均が使用されます。"

#: nnabla.functions.min_max_quantize:53 of
msgid ""
"`x_min_max` is `False` and `ema` is `False` Gradients of :math:`qr_{min}` and :"
"math:`qr_{max}` are computed in the backward pass."
msgstr ""
"`x_min_max` が `False` で `ema` が `False` : :math:`qr_{min}` と :math:`qr_{max}"
"` の勾配は、backward パスで計算されます。"

#: nnabla.functions.min_max_quantize:56 of
msgid ""
"More precisely, in inference of the min-max quantization, one has to consider "
"*zero-point (zp)* which corresponds to the real value 0, and its data type is an "
"integer. *zero-point* is defined as"
msgstr ""
"より正確には、最小最大量子化の推論では、実際の値 0 に対応する *ゼロ点 ( zp )* を"
"考慮する必要があり、そのデータ型は整数です。 *zero-point* は以下の様に定義されま"
"す。"

#: nnabla.functions.min_max_quantize:60 of
msgid ""
"&& zp_f = ql_{min} -\\frac{qr_{min}}{scale}, \\\\   && zp = \\left"
"\\{ \\begin{array}{ll}   ql_{max} & if \\ \\ \\ zp_f >= ql_{max} \\\\   "
"round(zp_f) & if \\ \\ otherwise \\\\   ql_{min}  & if \\ \\ zp_f <= ql_{min} \\"
"\\ \\end{array} \\right.."
msgstr ""
"&& zp_f = ql_{min} -\\frac{qr_{min}}{scale}, \\\\   && zp = \\left"
"\\{ \\begin{array}{ll}   ql_{max} & if \\ \\ \\ zp_f >= ql_{max} \\\\   "
"round(zp_f) & if \\ \\ otherwise \\\\   ql_{min}  & if \\ \\ zp_f <= ql_{min} \\"
"\\ \\end{array} \\right.."

#: nnabla.functions.min_max_quantize:70 of
msgid ""
"Accordingly, in order to simulate quantization effect of *zero-point*, during "
"both forward and backward pass, :math:`qr_{min}` and :math:`qr_{max}` are "
"adjusted as follows,"
msgstr ""
"従って、 *ゼロ点* の量子化効果をシミュレートするために、forward パスと backward "
"パスの両方で、 :math:`qr_{min}` と :math:`qr_{max}` は次のように調整されます。"

#: nnabla.functions.min_max_quantize:73 of
msgid ""
"qr_{min}^{adj} = ql_{min} - zp * scale, \\\\ qr_{max}^{adj} = ql_{max} - zp * "
"scale."
msgstr ""
"qr_{min}^{adj} = ql_{min} - zp * scale, \\\\ qr_{max}^{adj} = ql_{max} - zp * "
"scale."

#: nnabla.functions.min_max_quantize:78 of
msgid "These operations are often called *nudge*."
msgstr "これらの操作は、通常 *ナッジ* と呼ばれます。"

#: nnabla.functions.min_max_quantize:80 of
msgid ""
"Finally, in the formulas of the min-max quantization, :math:`m` and :math:`M` "
"are replaced by :math:`qr_{min}^{adj}` and :math:`qr_{max}^{adj}` respectively."
msgstr ""
"最後に、最小最大量子化の式では、 :math:`m` と :math:`M` はそれぞれ :math:"
"`qr_{min}^{adj}` と :math:`qr_{max}^{adj}` に置き換えられます。"

#: nnabla.functions.min_max_quantize:85 of
msgid "Minimum quantization range (modified during forward execution)."
msgstr "最小量子化範囲 ( forward パス実行中に変更)。"

#: nnabla.functions.min_max_quantize:87 of
msgid "Maximum quantization range (modified during forward execution)."
msgstr "最大量子化範囲 (forward パス実行中に変更)。"

#: nnabla.functions.min_max_quantize:89 of
msgid "Minimum quantization level, typically 0."
msgstr "最小量子化レベル、通常は 0 。"

#: nnabla.functions.min_max_quantize:91 of
msgid "Maximum quantization level, typically 255."
msgstr "最大量子化レベル、通常は 255。"

#: nnabla.functions.min_max_quantize:93 of
msgid "The decay rate for the exponential moving average."
msgstr "指数移動平均の減衰率。"

#: nnabla.functions.min_max_quantize:95 of
msgid ""
"Use the min and max of x to compute quantization ranges. Default is `False`."
msgstr ""
"x の最小値と最大値を使用して、量子化範囲を計算します。デフォルトは `False` です。"

#: nnabla.functions.min_max_quantize:97 of
msgid ""
"Use the exponential moving average for the min and max quantization ranges. "
"Default is `False`."
msgstr ""
"最小および最大量子化範囲の指数移動平均を使用します。デフォルトは `False` です。"

#: nnabla.functions.min_max_quantize:100 of
msgid ""
"If `True`, STE is not 1, the {0, 1}-mask computed from the min-max is applied to "
"the gradient in the backward; otherwise, STE is 1."
msgstr ""
"`True` の場合、STE は1ではなく、min-max から計算された { 0, 1 }-maskは、backward "
"の勾配に適用されます。そうでなければ、STE は1です。"

#: nnabla.functions.min_max_quantize:103 of
msgid ""
"Epsilon, or small value to ensure :math:`qr_{max} - qr_{min}` must be greater "
"than the epsilon."
msgstr ""
"イプシロン、すなわち :math:`qr_{max} - qr_{min}` がイプシロンより大きいことを確認"
"するための小さな値。"

#: nnabla.functions.min_max_quantize:106 of
msgid "Apply quantization or not."
msgstr "量子化を適用するかどうか。"

#: nnabla.functions.min_max_quantize:111 of
msgid ""
"Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew "
"Howard, Hartwig Adam, and Dmitry Kalenichenko, \"Quantization and Training of "
"Neural Networks for Efficient Integer-Arithmetic-Only Inference\", https://arxiv."
"org/abs/1712.05877"
msgstr ""
"Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew "
"Howard, Hartwig Adam, and Dmitry Kalenichenko, \"Quantization and Training of "
"Neural Networks for Efficient Integer-Arithmetic-Only Inference\", https://arxiv."
"org/abs/1712.05877"

#: nnabla.functions.pow2_quantize:1 of
msgid "Pow2 Quantize"
msgstr "Pow2 量子化"

#: nnabla.functions.pow2_quantize:7 of
msgid ""
"Indicate using zero as a quantized value. Default is true. Note that `zero` "
"consumes one bit."
msgstr ""
"量子化値としてゼロを使用することを示します。デフォルトは true です。 `zero` は 1 "
"ビットを消費することに注意してください。"

#: nnabla.functions.pow2_quantize:9 of
msgid ""
"Bit width used. Note that `sign` consumes one bit. :math:`n-1` is used for "
"number representation in `signed` case. Default is 8."
msgstr ""
"使用されるビット幅。 `sign` は 1 ビットを消費することに注意してください。 :math:"
"`n-1` は、 `signed` の場合の数値表現に使用されます。 デフォルトは 8 です。"

#: nnabla.functions.pow2_quantize:11 of
msgid ""
":math:`2^m` is the upper bound of the dynamic range and :math:`-2^m` is the "
"lower bound, :math:`m \\in \\mathcal{Z}`. Default is 1."
msgstr ""
":math:`2^m` はダイナミックレンジの上限で、 :math:`-2^m` は下限 :math:`m \\in "
"\\mathcal{Z}` です。デフォルトは 1 です。"

#: nnabla.functions.pow2_quantize:21 of
msgid "``nnabla.function_bases.pow2_quantize``."
msgstr "``nnabla.function_bases.pow2_quantize``."

#: nnabla.functions.pow2_quantize:23 of
msgid "In the forward pass of `signed` case,"
msgstr "`signed` のケースの forward パスでは、"

#: nnabla.functions.pow2_quantize:25 of
msgid ""
"q_i= \\left\\{     \\begin{array}{ll}                  max_{+} & if \\ \\ "
"\\overline{q_i} > max_{+} \\\\                  \\overline{q_i} & if \\ \\ "
"min_{+} \\le \\overline{q_i} \\le max_{+} \\\\            min_{+} & if \\ \\ 0 "
"\\le \\overline{q_i} < min_{+} \\\\            min_{-} & if \\ \\ min_{-} < "
"\\overline{q_i} < 0 \\\\            \\overline{q_i} & if \\ \\ max_{-} \\le "
"\\overline{q_i} \\le min_{-}\\\\          max_{-} & if \\ \\ \\overline{q_i} < "
"max_{-} \\\\     \\end{array} \\right.,"
msgstr ""
"q_i= \\left\\{     \\begin{array}{ll}                  max_{+} & if \\ \\ "
"\\overline{q_i} > max_{+} \\\\                  \\overline{q_i} & if \\ \\ "
"min_{+} \\le \\overline{q_i} \\le max_{+} \\\\            min_{+} & if \\ \\ 0 "
"\\le \\overline{q_i} < min_{+} \\\\            min_{-} & if \\ \\ min_{-} < "
"\\overline{q_i} < 0 \\\\            \\overline{q_i} & if \\ \\ max_{-} \\le "
"\\overline{q_i} \\le min_{-}\\\\          max_{-} & if \\ \\ \\overline{q_i} < "
"max_{-} \\\\     \\end{array} \\right.,"

#: nnabla.functions.pow2_quantize:39 of
msgid ""
"&& max_{+} = 2^{m}, min_{+} = 2^{m - (2^{n-1} - 1)},\\\\ && max_{-} = -2^{m}, "
"min_{-} = -2^{m - (2^{n-1} - 1)},\\\\ && \\overline{q_i} = sign(x_i) \\times "
"2^{round(\\log_2 |x_i|)}."
msgstr ""
"&& max_{+} = 2^{m}, min_{+} = 2^{m - (2^{n-1} - 1)},\\\\ && max_{-} = -2^{m}, "
"min_{-} = -2^{m - (2^{n-1} - 1)},\\\\ && \\overline{q_i} = sign(x_i) \\times "
"2^{round(\\log_2 |x_i|)}."

#: nnabla.functions.pow2_quantize:45 of
msgid ""
"This quantization uses the geometric mean between two power-of-two numbers as "
"quantization threshold."
msgstr ""
"この量子化では、2 つの 2 のべき乗数の間の幾何平均を量子化し閾値として使用します。"

#: nnabla.functions.pow2_quantize:48 of
msgid "In the forward pass of `unsigned` case,"
msgstr "`unsigned` のケースの forward パスでは、"

#: nnabla.functions.pow2_quantize:50 of
msgid ""
"q_i= \\left\\{     \\begin{array}{ll}                  max & if \\ \\ "
"\\overline{q_i} > max \\\\                  \\overline{q_i} & if \\ \\ min \\le "
"\\overline{q_i} \\le max \\\\            min & if \\ \\ 0 < \\overline{q_i} < "
"min \\\\     \\end{array} \\right.,"
msgstr ""
"q_i= \\left\\{     \\begin{array}{ll}                  max & if \\ \\ "
"\\overline{q_i} > max \\\\                  \\overline{q_i} & if \\ \\ min \\le "
"\\overline{q_i} \\le max \\\\            min & if \\ \\ 0 < \\overline{q_i} < "
"min \\\\     \\end{array} \\right.,"

#: nnabla.functions.pow2_quantize:61 of
msgid ""
"&& max = 2^{m}, min = 2^{m - (2^{n} - 1)},\\\\ && \\overline{q_i} = "
"2^{int(\\log_2 |x_i|)}."
msgstr ""
"&& max = 2^{m}, min = 2^{m - (2^{n} - 1)},\\\\ && \\overline{q_i} = "
"2^{int(\\log_2 |x_i|)}."

#: nnabla.functions.pow2_quantize:67 of
msgid ""
"When using `with_zero` as true, a pruning threshold is used to round an input to "
"0 or :math:`min`. The pruning threshold is defined in this function as the "
"following,"
msgstr ""
"`with_zero` を true として使用する場合、プルーニング閾値を使用して、入力を0また"
"は :math:`min`　に丸めます。プルーニング閾値は、この関数で次のように定義されてい"
"ます。"

#: nnabla.functions.pow2_quantize:70 of
msgid "pruning\\ threshold = min \\times 2^{-\\frac{1}{2}}."
msgstr "pruning\\ threshold = min \\times 2^{-\\frac{1}{2}}."

#: nnabla.functions.pow2_quantize:74 of
msgid ""
"If an absolute value of the input is lesser than this value, the input is "
"rounded to 0, otherwise :math:`min`."
msgstr ""
"入力の絶対値がこの値よりも小さい場合、入力は 0 に丸められ、それ以外の場合は :"
"math:`min` になります。"

#: nnabla.functions.pow2_quantize:76 of
msgid "In the backward pass when using ste_fine_grained as false,"
msgstr "ste_fine_grained を false として backward パスで使用する場合、"

#: nnabla.functions.pow2_quantize:82 of
msgid "In the backward pass when using ste_fine_grained as true,"
msgstr "ste_fine_grained を true　として backward パスで使用する場合、"

#: nnabla.functions.pow2_quantize:84 of
msgid ""
"\\frac{\\partial q_i}{\\partial x_i}= \\left\\{    \\begin{array}"
"{ll}             0 & if \\ \\ \\overline{q_i} > max_{+} \\\\                 1 & "
"if \\ \\ otherwise \\\\         0 & if \\ \\ \\overline{q_i} < max_{-} \\\\    "
"\\end{array} \\right.."
msgstr ""
"\\frac{\\partial q_i}{\\partial x_i}= \\left\\{    \\begin{array}"
"{ll}             0 & if \\ \\ \\overline{q_i} > max_{+} \\\\                 1 & "
"if \\ \\ otherwise \\\\         0 & if \\ \\ \\overline{q_i} < max_{-} \\\\    "
"\\end{array} \\right.."

#: nnabla.functions.prune:1 of
msgid "Prune the input as the following equation,"
msgstr "次の式のように、入力をプルーニングします。"

#: nnabla.functions.prune:3 of
msgid ""
"q_i = \\left \\{   \\begin{array}{ll}   0   & abs(x_i) < threshold \\\\   x_i & "
"otherwise   \\end{array}   \\right."
msgstr ""
"q_i = \\left \\{   \\begin{array}{ll}   0   & abs(x_i) < threshold \\\\   x_i & "
"otherwise   \\end{array}   \\right."

#: nnabla.functions.prune:12 of
msgid ""
"where :math:`threshold` is determined by `threshold = np.sort(np.abs(x))[int((x."
"size - 1) * rate)]`."
msgstr ""
"ここで、:math:`threshold` は閾値 `threshold = np.sort(np.abs(x))[int((x.size - "
"1) * rate)]` によって定義されます。"

#: nnabla.functions.prune:16 of
msgid "Sparse rate, or pruning rate. [default=``0.9``]"
msgstr "スパースレート、またはプルーニングレート。 [ default = ``0.9`` ]"

#: nnabla.functions.inq_affine:1 of
msgid "This function provides a INQ affine layer. It computes in the forward pass"
msgstr ""
"この関数は INQ affine 層を提供します。forward パスにおいて以下のように計算されま"
"す。"

#: nnabla.functions.inq_affine:4 of
msgid "y_j = \\sum_{i} w_{j,i} x_i,"
msgstr "y_j = \\sum_{i} w_{j,i} x_i,"

#: nnabla.functions.inq_affine:8 nnabla.functions.inq_convolution:8 of
msgid ""
"where the weights :math:`w_{j,i}` are quantized sequentially during training to "
"power-of-two numbers. In the backward pass, only the non-fixed (i.e., learnable) "
"weights are updated."
msgstr ""
"ここでは、重み :math:`w_{j,i}` は学習中に順に 2 のべき乗の数に量子化されます。"
"backward パスでは、固定値でない (つまり、学習可能な) 重みのみが更新されます。"

#: nnabla.functions.inq_affine:14 nnabla.functions.inq_convolution:14 of
msgid ""
"`Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network quantization: Towards "
"lossless CNNs with low-precision weights. <https://arxiv.org/abs/1702.03044>`_"
msgstr ""
"`Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network quantization: Towards "
"lossless CNNs with low-precision weights. <https://arxiv.org/abs/1702.03044>`_"

#: nnabla.functions.inq_affine:23 nnabla.functions.inq_convolution:23 of
msgid ""
"Indicates which weights are already fixed (0 = not fixed, 1 = fixed) . "
"[parameter]"
msgstr ""
"すでに重みが固定されているインデックス (0 = 固定値でない, 1 = 固定値). [パラメー"
"タ]"

#: nnabla.functions.inq_affine:32 nnabla.functions.inq_convolution:44 of
msgid ""
"Number of bits per weight. Needs to be >= 2 as two bits are used to code `zero` "
"and sign of weight. [default=``4``]"
msgstr ""
"重みごとのビット数。 `zero` と重みの符号のコーディングに 2 ビットを使用するため、"
"2 以上である必要があります。 [ default = ``4`` ]"

#: nnabla.functions.inq_affine:35 nnabla.functions.inq_convolution:47 of
#, python-format
msgid ""
"List which specifies after how many forward passes we fix 50% of the learnable "
"weights. If we have done as many iterations as specified in the last element of "
"`inq_iterations`, then all weights are fixed. [default=``()``]"
msgstr ""
"forward パスを何回か行った後に学習可能な重みの 50% を修正するかを指定するリス"
"ト。 `inq_iterations` の最後の要素で指定されるイテレーション回数を行うと、すべて"
"の重みが固定されます。 [ default = ``()`` ]"

#: nnabla.functions.inq_affine:38 nnabla.functions.inq_convolution:50 of
msgid ""
"Chooses algorithm that we use for selecting the weights to fix (\"largest_abs"
"\" ... fix weights with largest absolute value, \"random\" ... fix weights "
"randomly) [default=``'largest_abs'``]"
msgstr ""
"固定する重みを選択するためのアルゴリズムを選びます。 (“largest_abs” … 最大絶対値"
"で重みを固定、 “random” … ランダムに重みを固定) [ default = ``’largest_abs’`` ]"

#: nnabla.functions.inq_convolution:1 of
msgid ""
"This function provides a INQ convolution layer. It computes in the forward pass"
msgstr ""
"この関数は、INQ convolution 層を提供します。 forward パスにおいて以下のように計算"
"されます。"

#: nnabla.functions.inq_convolution:4 of
msgid ""
"y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} w_{n, m, i, j} x_{m, a + i, b + j},"
msgstr ""
"y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} w_{n, m, i, j} x_{m, a + i, b + j},"

#: ../../python/api/function.rst:273
msgid "Unsupported, Special Use"
msgstr "サポートされていない、特別な使用"

#: nnabla.functions.vat_noise:1 of
msgid "Noise for virtual adversarial training."
msgstr "仮想敵対訓練のためのノイズ。"

#: nnabla.functions.vat_noise:3 of
msgid ""
"This layer is a special layer for GUI network designing, specialized for getting "
"the noise of virtual adversarial training."
msgstr ""
"この層は、仮想敵対訓練のノイズを取得するために特化された、GUI ネットワーク設計の"
"ための特別な層です。"

#: nnabla.functions.vat_noise:6 of
msgid ""
"In the backward process, the weight parameter will be replaced with the gradient."
msgstr "backward プロセスでは、重みパラメータが勾配に置き換えられます。"

#: nnabla.functions.unlink:7 nnabla.functions.vat_noise:8 of
msgid "Forward"
msgstr "forward"

#: nnabla.functions.vat_noise:10 of
msgid "y_i = \\frac{\\epsilon x_i}{\\sqrt{\\sum_k x_k^2 + c}}"
msgstr "y_i = \\frac{\\epsilon x_i}{\\sqrt{\\sum_k x_k^2 + c}}"

#: nnabla.functions.unlink:12 nnabla.functions.vat_noise:13 of
msgid "Backward"
msgstr "backward"

#: nnabla.functions.unlink:14 nnabla.functions.vat_noise:15 of
msgid "\\delta x_i = 0"
msgstr "\\delta x_i = 0"

#: nnabla.functions.vat_noise:18 of
msgid "w_i = \\epsilon \\delta y_i"
msgstr "w_i = \\epsilon \\delta y_i"

#: nnabla.functions.unlink:17 nnabla.functions.vat_noise:21 of
msgid "This layer is a special layer for GUI network designing."
msgstr "この層は、GUI ネットワーク設計のための特別な層です。"

#: nnabla.functions.vat_noise:25 of
msgid ""
"`Miyato et.al, Distributional Smoothing with Virtual Adversarial Training. "
"<https://arxiv.org/abs/1507.00677>`_"
msgstr ""
"`Miyato et.al, Distributional Smoothing with Virtual Adversarial Training. "
"<https://arxiv.org/abs/1507.00677>`_"

#: nnabla.functions.vat_noise:28 of
msgid ""
"N-D array of noise input. Noise is standard Gaussian noise initially, but the "
"next step, fed back gradient variable."
msgstr ""
"ノイズ入力の N-D 配列。ノイズは、最初は標準のガウスノイズですが、次のステップで"
"は、勾配変数がフィードバックされます。"

#: nnabla.functions.vat_noise:30 of
msgid "N-D array for keep gradient values."
msgstr "勾配値を保持するための N-D 勾配。"

#: nnabla.functions.vat_noise:35 of
msgid "Noise norm (l2) factor. [default=``1.0``]"
msgstr "ノイズノルム (l2) 係数。 [ default = ``1.0`` ]"

#: nnabla.functions.unlink:1 of
msgid ""
"This function behaves as an identity function on the forward pass, and deletes "
"the gradient for the background pass."
msgstr ""
"この関数は、forward パスで恒等関数として動作し、backward パスの勾配を削除します。"

#: nnabla.functions.unlink:4 of
msgid ""
"This layer is a special layer for GUI network designing, used for getting zero "
"backward operation by adding this layer."
msgstr ""
"この層は、GUI ネットワーク設計のための特別な層であり、この層を追加することによ"
"り、後方向操作をゼロにするために使用されます。"

#: nnabla.functions.unlink:9 of
msgid "y_i = x_i"
msgstr "y_i = x_i"

#: nnabla.functions.sink:1 of
msgid ""
"Creates a dummy variable used to call forward or backward function of multiple "
"variables at one place."
msgstr ""
"複数の変数の forward または backward 関数を1か所で呼び出すために使用されるダミー"
"変数を作成します。"

#: nnabla.functions.sink:4 of
msgid ""
"This takes any numbers of input variables with any shape, and creates a single 0-"
"shape outputs. The forward pass does nothing. The backward pass set ones to the "
"input grads if one_input_grad is set as true."
msgstr ""
"これは、任意の形状の任意の数の入力変数を取り、単一の 0 形状の出力を作成します。"
"forward パスは何もしません。 one_input_grad が true に設定されている場合、"
"backward パスは入力 grads に1を設定します。"

#: nnabla.functions.sink:11 of
msgid ""
"``sink`` can only be called at the very end of the graph, and ``grad`` of input "
"variables are cleared"
msgstr ""
"``sink`` はグラフの最後でのみ呼び出すことができ、入力変数の ``grad`` がクリアされ"
"ます"

#: nnabla.functions.sink:13 of
msgid "when ``y.backward(clear_buffer=True)`` is called."
msgstr "``y.backward(clear_buffer=True)`` が呼ばれます。"

#: nnabla.functions.sink:15 of
msgid "Any number of inputs with any shape. [variadic]"
msgstr "任意の形状の任意の数の入力。 [variadic]"

#: nnabla.functions.sink:18 of
msgid ""
"Set grads of inputs as one during backward. It is useful to set false if you "
"want to set external gradients to the input variables. [default=``True``]"
msgstr ""
"後方向の入力の段階を 1 に設定します。\n"
"入力変数に外部勾配を設定する場合は、 false を設定すると便利です。 [ default = "
"``True`` ]"

#: nnabla.functions.sink:22 of
msgid "Dummy variable."
msgstr "ダミー変数。"

#: nnabla.functions.warp_by_flow:1 of
msgid ""
"Transform the image(s) *data* by *flow* field(s) of offset vectors such that "
"each output pixel corresponds to the input image pixel at the offset location "
"given by horizontal and vertical flow values. Both *data* and *flow* are 4-D "
"variables (in \"NCHW\" layout) with identical shape except the *flow* channel "
"dimension (which is always 2)."
msgstr ""
"各出力ピクセルが水平および垂直のフロー値で指定されたオフセット位置の入力画像ピク"
"セルに対応するように、オフセットベクトルの *flow* フィールドによって画像*データ* "
"を変換します。 *data* および *flow* は、 *フロー* チャネル次元 (常に 2 ) を除き、"
"同じ形状の 4 次元変数 (“NCHW” レイアウト) となります。"

#: nnabla.functions.warp_by_flow:7 of
msgid ""
"output_{n,c,y,x} = data_{n,c,y',x'} \\text{ with } y' = y - flow_{n,1,y,x} "
"\\text{ and } x' = x - flow_{n,0,y,x}"
msgstr ""
"output_{n,c,y,x} = data_{n,c,y',x'} \\text{ with } y' = y - flow_{n,1,y,x} "
"\\text{ and } x' = x - flow_{n,0,y,x}"

#: nnabla.functions.warp_by_flow:11 of
msgid ""
"The output pixel values at :math:`y'` and :math:`x'` locations are obtained by "
"bilinear interpolating between the 4 closest pixels of the input image. Pixel "
"values outside of the input image are implicitly padded with the value of the "
"closest boundary pixel."
msgstr ""
"入力画像の最も近い 4 つのピクセル間をバイリニア補完することによって、 :math:`y'` "
"および :math:`x'` における出力ピクセル値を取得します。入力画像外のピクセル値に"
"は、暗黙的に最も近い境界ピクセルが埋め込まれます。"

#: nnabla.functions.warp_by_flow:16 of
msgid "Input image data with shape `(N, Channels, Height, Width)`."
msgstr "`(N, Channels, Height, Width)` の形式の入力画像データ。"

#: nnabla.functions.warp_by_flow:18 of
msgid "Flow field vectors with shape `(N, 2, Height, Width)`."
msgstr "`(N, 2, Height, Width)` の形式の flow フィールドベクトル。"

#: nnabla.functions.warp_by_flow:21 of
msgid "Transformed image data with shape `(N, Channels, Height, Width)`."
msgstr "`(N, Channels, Height, Width)` の形式の変換画像データ。"

#: nnabla.functions.confusion_matrix:1 of
msgid "Confusion matrix. The return value is already summed over samples."
msgstr "Confusion matrix。戻り値は、要素に対応するサンプル数で合計されています。"

#: nnabla.functions.confusion_matrix:4 of
msgid ""
"Probabilities N-D array. (\\f$D_1 \\times ... \\times D_i \\times ... \\times D_N"
"\\f$)"
msgstr ""
"確率 N-D 配列。 (\\f$D_1 \\times ... \\times D_i \\times ... \\times D_N\\f$)"

#: nnabla.functions.confusion_matrix:6 of
msgid ""
"Labels N-D array. (\\f$D_1 \\times ... \\times 1 \\times ... \\times D_N\\f$)"
msgstr ""
"ラベル N-D 配列。 (\\f$D_1 \\times ... \\times 1 \\times ... \\times D_N\\f$)"

#: nnabla.functions.confusion_matrix:8 of
msgid ""
"Axis on which the confusion matrix is calculated. [default=``len(x.shape) - 1``]"
msgstr "confusion matrix が計算される軸。 [ default = ``len(x.shape) - 1`` ]"

#: nnabla.functions.confusion_matrix:12 of
msgid ""
"Confusion matrix 2-D array. Col index is estimated class. Row index is label "
"class."
msgstr ""
"Confusion matrix 2 次元配列。 Col インデックスはestimated クラス。 Row インデック"
"スは label クラス。"

#: ../../python/api/function.rst:283
msgid "Image Object Detection"
msgstr "画像オブジェクト検出"

#: nnabla.functions.nms_detection2d:1 of
msgid ""
"Non-Maximum Suppression (NMS) to 2D Object detector output. The input is a 3-"
"dimensional tensor with shape of ``(B, N, 5 + C)`` where ``B`` denotes batch "
"size, ``N`` denotes the number of detection box candidates, and ``C`` denotes "
"the number of classes of object detection. ``5 + C`` consists of the box "
"coordinates ``x, y, w, h`` in normalized coordinates (size of each x and y are "
"1.0), objectness (learned to predict IoU value to ground truth box), and the "
"class"
msgstr ""
"2D オブジェクト検出器の出力に対する非最大抑制 ( NMS ) 。入力は、形状が ``(B, N, "
"5 + C)`` の3次元テンソルです。ここで、 ``B`` はバッチサイズ、 ``N`` は検出ボック"
"ス候補の数、 ``C`` はオブジェクト検出のクラス数を示します。 ``5 + C`` は正規化し"
"た（各 x と y のサイズは1.0）ボックス座標 ``x, y, w, h`` 、（グラウンドトゥルース"
"ボックスに対する IoU 値を予測するために学習された）オブジェクト性のボックス座標 "
"``x, y, w, h`` で構成され、クラスは"

#: nnabla.functions.nms_detection2d:8 of
msgid "probabilities of ``C`` classes."
msgstr "``C`` クラスの確率。"

#: nnabla.functions.nms_detection2d:9 of
msgid ""
"It outputs a tensor with the same dimensions as the input, where all values are "
"copied from the input to the output, except the class probabilities are "
"multiplied by objectness, and possibly suppressed to 0 by NMS. During NMS, all "
"of combination of pairs of bounding boxes is compared. For each pair, the "
"bounding box with a lower detection score (described below) is suppressed if the "
"overlap ratio (the IoU) is greater than the value of ``nms``."
msgstr ""
"これは、入力と同じ次元のテンソルを出力し、クラス確率がオブジェクト性によって乗算"
"され、NMS によって 0 に抑制される場合を除き、すべての値が入力から出力にコピーされ"
"ます。NMS では、境界ボックスのペアのすべての組み合わせが比較されます。各ペアにつ"
"いて、オーバーラップ率 ( IoU ) が ``nms`` の値より大きい場合、検出スコアの低いバ"
"ウンディングボックス（以下で説明）は抑制されます。"

#: nnabla.functions.nms_detection2d:18 of
msgid "There are two suppression modes for NMS."
msgstr "NMS には2つの抑制モードがあります。"

#: nnabla.functions.nms_detection2d:20 of
msgid ""
"1. Suppress by class probability (``nms_per_class`` is ``True``): For each "
"bounding box, the detection score is calculated by ``objectness * "
"probability[class_id]`` for each class. The suppression is done for each class "
"independently."
msgstr ""
"1.\\ クラス確率による抑制 ( ``nms_per_class`` が ``True`` ) : 各境界ボックスの検"
"出スコアは、各クラスの ``objectness \\* probability[class_id]`` によって計算され"
"ます。抑制はクラスごとに独立して行われます。"

#: nnabla.functions.nms_detection2d:25 of
msgid ""
"2. Suppress by objectness (``nms_per_class`` is ``False``): The suppression is "
"done for each bounding box using ``objectness`` as a detection score. All class "
"probabilities becomes 0 for every suppressed boxes."
msgstr ""
"2.\\ オブジェクトネスによる抑制 ( ``nms_per_class`` は ``False`` ) : 抑制は、 "
"``objectness`` を検出スコアとして使用して、各境界ボックスに対して行われます。すべ"
"てのクラス確率は、抑制されたボックスごとに 0 になります。"

#: nnabla.functions.nms_detection2d:32 of
msgid ""
"`Joseph Redmon, Ali Farhadi, YOLO9000: Better, Faster, Stronger. <https://arxiv."
"org/abs/1612.08242>`_"
msgstr ""
"`Joseph Redmon, Ali Farhadi, YOLO9000: Better, Faster, Stronger. <https://arxiv."
"org/abs/1612.08242>`_"

#: nnabla.functions.nms_detection2d:35 of
msgid "A 3-dimensional array."
msgstr "A 3- 次元配列。"

#: nnabla.functions.nms_detection2d:37 of
msgid "Detection score threshold. [default=``0.5``]"
msgstr "検出スコアの閾値 [ default = ``0.5`` ]"

#: nnabla.functions.nms_detection2d:40 of
msgid "IoU threshold for Non-maximum suppression (NMS). [default=``0.45``]"
msgstr "非最大抑制 ( NMS )の IoU 閾値。[ default = ``0.45`` ]"

#: nnabla.functions.nms_detection2d:43 of
msgid "If true, NMS is applied for each class. [default=``True``]"
msgstr "true の場合、 NMS は各クラスに適用します。 [ default = ``True`` ]"

#: nnabla.functions.nms_detection2d:47 of
msgid "A 3-dim array with the same dimensions with the input."
msgstr "入力と同じ次元の3次元配列。"

#: ../../python/api/function.rst:289
msgid "Validation"
msgstr "検証"

#: nnabla.functions.top_n_error:1 of
msgid ""
"Top N error along the dimension specified by the axis, the element of outputs is"
msgstr "軸で指定された次元に沿った上位 N エラー、出力の要素は以下となります。"

#: nnabla.functions.top_n_error:3 of
msgid ""
"y_i = \\left \\{ \\begin{array}{l} 1 \\ (x_i \\ is \\ not \\ within \\ N-th \\ "
"place) \\\\ 0 \\ (x_i \\ is \\ within \\ N-th \\ place) \\end{array} \\right."
msgstr ""
"y_i = \\left \\{ \\begin{array}{l} 1 \\ (x_i \\ is \\ not \\ within \\ N-th \\ "
"place) \\\\ 0 \\ (x_i \\ is \\ within \\ N-th \\ place) \\end{array} \\right."

#: nnabla.functions.top_n_error:12 of
msgid ""
"Probabilities N-D array. :math:`D_1 \\times ... \\times D_i \\times ... \\times "
"D_N`"
msgstr "N-D 配列確率。 :math:`D_1 \\times ... \\times D_i \\times ... \\times D_N`"

#: nnabla.functions.top_n_error:14 of
msgid ""
"N-D array of labels. :math:`D_1 \\times ... \\times 1 \\times ... \\times D_N`"
msgstr ""
"ラベルの N-D 配列。 :math:`D_1 \\times ... \\times 1 \\times ... \\times D_N`"

#: nnabla.functions.top_n_error:16 of
msgid "Axis on which the top N error is calculated. [default=``len(x.shape) - 1``]"
msgstr "上位Nエラーが計算される軸。[ default = ``len(x.shape) - 1`` ]"

#: nnabla.functions.top_n_error:19 of
msgid "top N [default=``1``]"
msgstr "上位 N [ default = ``1`` ]"

#: nnabla.functions.top_n_error:23 of
msgid ""
"Element-wise error N-D array. (:math:`D_1 \\times ... \\times 1 \\times ... "
"\\times D_N`)"
msgstr ""
"要素単位でのエラーの N-D 配列。 (:math:`D_1 \\times ... \\times 1 \\times ... "
"\\times D_N`)"

#: nnabla.functions.binary_error:1 of
msgid "Elementwise binary error."
msgstr "要素ごとのバイナリエラー。"

#: nnabla.functions.binary_error:3 of
msgid ""
"y_i = \\left \\{ \\begin{array}{l} 0 ((x^{(0)} \\geq 0.5) = (x^{(1)} \\geq 0.5)) "
"\\\\ 1 ((x^{(0)} \\geq 0.5) \\neq (x^{(1)} \\geq 0.5)) \\end{array} \\right."
msgstr ""
"y_i = \\left \\{ \\begin{array}{l} 0 ((x^{(0)} \\geq 0.5) = (x^{(1)} \\geq 0.5)) "
"\\\\ 1 ((x^{(0)} \\geq 0.5) \\neq (x^{(1)} \\geq 0.5)) \\end{array} \\right."

#: nnabla.functions.binary_error:12 of
msgid "Probabilities N-D array. \\f$-\\infty\\f$ to \\f$\\infty\\f$."
msgstr "N-D 配列確率。f$-inftyf$ から f$inftyf$。"

#: nnabla.functions.binary_error:14 of
msgid ""
"Labels N-D array. Usually set as 0 or 1, but, it allows probability (0 to 1) as "
"inputs."
msgstr ""
"N-D ラベル配列。通常は0または1として設定されますが、入力として確率（0〜1）を許可"
"します。"

#: nnabla.functions.binary_error:17 of
msgid "Element-wise errors N-D array."
msgstr "要素ごとのバイナリエラー N-D 配列。"
