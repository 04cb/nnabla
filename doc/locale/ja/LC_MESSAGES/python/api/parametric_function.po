# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, Sony Corporation
# This file is distributed under the same license as the Neural Network
# Libraries package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
msgid ""
msgstr ""
"Project-Id-Version: Neural Network Libraries 1.7.0.dev1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-05-27 10:13+0900\n"
"PO-Revision-Date: 2020-06-03 10:51+0900\n"
"Last-Translator: \n"
"Language: ja_JP\n"
"Language-Team: \n"
"Plural-Forms: nplurals=1; plural=0\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../python/api/parametric_function.rst:2
msgid "Parametric Functions"
msgstr "パラメトリック関数"

#: ../../python/api/parametric_function.rst:4
msgid ""
"In NNabla, trainable models are created by composing functions that have "
"optimizable parameters. These functions are called parametric functions. "
"Parametric functions are provided by :mod:`nnabla.parametric_functions`."
msgstr ""
"NNabla "
"では、最適化可能なパラメータを持つ複数の関数を組み合わせることでで学習可能なモデルを作成します。このような関数をパラメトリック関数といいます。パラメトリック関数は、"
" :mod:`nnabla.parametric_functions` にて提供されています。"

#: ../../python/api/parametric_function.rst:13
msgid "See also:"
msgstr "また、"

#: ../../python/api/parametric_function.rst:10
msgid ""
"`Python API Tutorial "
"<http://nnabla.readthedocs.io/en/latest/python/tutorial/python_api.html>`_."
msgstr ""
"`Python API Tutorial "
"<http://nnabla.readthedocs.io/jp/latest/python/tutorial/python_api.html>`_"
" も併せてご参照ください。"

#: ../../python/api/parametric_function.rst:18
msgid "Parameter Management API"
msgstr "パラメータを管理するためのAPI"

#: ../../python/api/parametric_function.rst:22
msgid ""
"The parameters registered by :ref:`parametric-functions` can be managed "
"using APIs listed in this section."
msgstr ""
"全ての :ref:`parametric-functions` によって登録されるパラメータは、このセクションにリストアップされているAPI "
"を使って管理することができます。"

#: nnabla.parameter.parameter_scope:1 of
msgid ""
"Grouping parameters registered by parametric functions listed in "
":mod:`nnabla.parametric_functions`."
msgstr ""
":mod:`nnabla.parametric_functions` "
"にリストされたパラメトリック関数によって登録されるパラメータをグループ化します。"

#: nnabla.initializer.BaseInitializer.__call__
#: nnabla.initializer.ConstantInitializer nnabla.initializer.NormalInitializer
#: nnabla.initializer.OrthogonalInitializer nnabla.initializer.RangeInitializer
#: nnabla.initializer.UniformInitializer
#: nnabla.initializer.UniformIntInitializer
#: nnabla.initializer.calc_normal_std_glorot
#: nnabla.initializer.calc_normal_std_he_backward
#: nnabla.initializer.calc_normal_std_he_forward
#: nnabla.initializer.calc_uniform_lim_glorot
#: nnabla.parameter.get_parameter_or_create nnabla.parameter.get_parameters
#: nnabla.parameter.load_parameters nnabla.parameter.parameter_scope
#: nnabla.parameter.save_parameters
#: nnabla.parametric_functions.LSTMCell.__call__
#: nnabla.parametric_functions.affine
#: nnabla.parametric_functions.batch_normalization
#: nnabla.parametric_functions.binary_connect_affine
#: nnabla.parametric_functions.binary_connect_convolution
#: nnabla.parametric_functions.binary_weight_affine
#: nnabla.parametric_functions.binary_weight_convolution
#: nnabla.parametric_functions.convolution
#: nnabla.parametric_functions.cpd3_convolution
#: nnabla.parametric_functions.deconvolution
#: nnabla.parametric_functions.depthwise_convolution
#: nnabla.parametric_functions.depthwise_deconvolution
#: nnabla.parametric_functions.embed
#: nnabla.parametric_functions.fixed_point_quantized_affine
#: nnabla.parametric_functions.fixed_point_quantized_convolution
#: nnabla.parametric_functions.fused_batch_normalization
#: nnabla.parametric_functions.group_normalization
#: nnabla.parametric_functions.gru nnabla.parametric_functions.inq_affine
#: nnabla.parametric_functions.inq_convolution
#: nnabla.parametric_functions.instance_normalization
#: nnabla.parametric_functions.layer_normalization
#: nnabla.parametric_functions.lstm nnabla.parametric_functions.lstm_cell
#: nnabla.parametric_functions.mean_subtraction
#: nnabla.parametric_functions.min_max_quantize
#: nnabla.parametric_functions.min_max_quantized_affine
#: nnabla.parametric_functions.min_max_quantized_convolution
#: nnabla.parametric_functions.multi_head_attention
#: nnabla.parametric_functions.parametric_function_api
#: nnabla.parametric_functions.pow2_quantized_affine
#: nnabla.parametric_functions.pow2_quantized_convolution
#: nnabla.parametric_functions.prelu nnabla.parametric_functions.pruned_affine
#: nnabla.parametric_functions.pruned_convolution
#: nnabla.parametric_functions.rnn nnabla.parametric_functions.spectral_norm
#: nnabla.parametric_functions.svd_affine
#: nnabla.parametric_functions.svd_convolution
#: nnabla.parametric_functions.sync_batch_normalization
#: nnabla.parametric_functions.transformer
#: nnabla.parametric_functions.transformer_decode
#: nnabla.parametric_functions.transformer_encode
#: nnabla.parametric_functions.weight_normalization of
msgid "パラメータ"
msgstr ""

#: nnabla.parameter.parameter_scope:4 of
msgid "Parameter scope name."
msgstr "パラメータスコープ名。"

#: nnabla.parameter.parameter_scope:6 of
msgid ""
"Specify current parameter scope as a local dictionary. The default value "
"is ``None``. In this case, the current parameter scope maintained in "
"global is used."
msgstr ""
"現在のパラメータスコープをローカルディクショナリとして指定する。デフォルト値は ``None`` "
"です。この場合、グローバルに保持されている現在のパラメータスコープが使用されます。"

#: nnabla.initializer.ConstantInitializer:6
#: nnabla.initializer.NormalInitializer:11
#: nnabla.initializer.OrthogonalInitializer:8
#: nnabla.initializer.RangeInitializer:11
#: nnabla.initializer.UniformInitializer:11
#: nnabla.initializer.UniformIntInitializer:11
#: nnabla.initializer.calc_normal_std_glorot:20
#: nnabla.initializer.calc_normal_std_he_backward:15
#: nnabla.initializer.calc_normal_std_he_forward:15
#: nnabla.initializer.calc_uniform_lim_glorot:21
#: nnabla.parameter.parameter_scope:11 nnabla.parameter.parameter_scope:31
#: nnabla.parametric_functions.multi_head_attention:13 of
msgid "Example:"
msgstr "例："

#: nnabla.parameter.parameter_scope:13 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.functions as F\n"
"\n"
"with nn.parameter_scope('conv1'):\n"
"    conv_out1 = PF.convolution(x, 32, (5, 5))\n"
"    bn_out1 = PF.batch_normalization(conv_out1)\n"
"    act_out1 = F.relu(bn_out1)\n"
"with nn.parameter_scope('conv2'):\n"
"    conv_out2 = PF.convolution(act_out1, 64, (3, 3))\n"
"    bn_out2 = PF.batch_normalization(conv_out2)\n"
"    act_out2 = F.relu(bn_out2)"
msgstr ""

#: nnabla.parameter.parameter_scope:28 of
msgid ""
"Nesting `with` blocks allows you to nest parameter scopes. This can also "
"be done by using \"/\" inside the parameter names."
msgstr ""
"`with` 文のブロックを入れ子に(ネスト)することで、パラメータスコープを入れ子に(ネスト)することができます。また、これはパラメータ名に "
"“/” を使うことでも可能となります。"

#: nnabla.parameter.parameter_scope:33 of
msgid ""
"with nn.parameter_scope('network1'):\n"
"    with nn.parameter_scope('conv1'):\n"
"        conv_out1 = PF.convolution(x, 32, (5, 5))\n"
"        bn_out1 = PF.batch_normalization(conv_out1)\n"
"        act_out1 = F.relu(bn_out1)\n"
"    with nn.parameter_scope('conv2'):\n"
"        conv_out2 = PF.convolution(act_out1, 64, (3, 3))\n"
"        bn_out2 = PF.batch_normalization(conv_out2)\n"
"        act_out2 = F.relu(bn_out2)"
msgstr ""

#: nnabla.parameter.parameter_scope:45 of
msgid "is equivalent to"
msgstr "以下と同等です。"

#: nnabla.parameter.parameter_scope:47 of
msgid ""
"with nn.parameter_scope('network1/conv1'):\n"
"    conv_out1 = PF.convolution(x, 32, (5, 5))\n"
"    bn_out1 = PF.batch_normalization(conv_out1)\n"
"    act_out1 = F.relu(bn_out1)\n"
"with nn.parameter_scope('network1/conv2'):\n"
"    conv_out2 = PF.convolution(act_out1, 64, (3, 3))\n"
"    bn_out2 = PF.batch_normalization(conv_out2)\n"
"    act_out2 = F.relu(bn_out2)"
msgstr ""

#: nnabla.parameter.get_current_parameter_scope:1 of
msgid "Returns current parameter scope."
msgstr "現在のパラメータスコープを返します。"

#: nnabla.parameter.get_parameters:1 of
msgid "Get parameter Variables under the current parameter scope."
msgstr "現在のパラメータスコープにおけるパラメータ変数を取得します。"

#: nnabla.parameter.get_parameters:3 of
msgid "Internal use. User doesn't set it manually."
msgstr "内部使用。ユーザーが手動で設定することはありません。"

#: nnabla.parameter.get_parameters:5 of
msgid "Internal use.  User doesn't set it manually."
msgstr "内部使用。ユーザーが手動で設定することはありません。"

#: nnabla.parameter.get_parameters:7 of
msgid ""
"Retrieve all parameters under the current scope if False, while only "
"parameters with need_grad=True are retrieved if True."
msgstr ""
"False の場合は現在のスコープ内にあるすべてのパラメータを取得し、True の場合は need_grad = True "
"のパラメータのみを取得します。"

#: nnabla.initializer.BaseInitializer.__call__ nnabla.parameter.get_parameters
#: nnabla.parametric_functions.affine
#: nnabla.parametric_functions.batch_normalization
#: nnabla.parametric_functions.binary_connect_affine
#: nnabla.parametric_functions.binary_connect_convolution
#: nnabla.parametric_functions.binary_weight_affine
#: nnabla.parametric_functions.binary_weight_convolution
#: nnabla.parametric_functions.convolution
#: nnabla.parametric_functions.cpd3_convolution
#: nnabla.parametric_functions.deconvolution
#: nnabla.parametric_functions.depthwise_convolution
#: nnabla.parametric_functions.depthwise_deconvolution
#: nnabla.parametric_functions.embed
#: nnabla.parametric_functions.fixed_point_quantized_affine
#: nnabla.parametric_functions.fixed_point_quantized_convolution
#: nnabla.parametric_functions.fused_batch_normalization
#: nnabla.parametric_functions.group_normalization
#: nnabla.parametric_functions.gru nnabla.parametric_functions.inq_affine
#: nnabla.parametric_functions.inq_convolution
#: nnabla.parametric_functions.layer_normalization
#: nnabla.parametric_functions.lstm nnabla.parametric_functions.lstm_cell
#: nnabla.parametric_functions.mean_subtraction
#: nnabla.parametric_functions.min_max_quantized_affine
#: nnabla.parametric_functions.min_max_quantized_convolution
#: nnabla.parametric_functions.multi_head_attention
#: nnabla.parametric_functions.parametric_function_api
#: nnabla.parametric_functions.pow2_quantized_affine
#: nnabla.parametric_functions.pow2_quantized_convolution
#: nnabla.parametric_functions.prelu nnabla.parametric_functions.pruned_affine
#: nnabla.parametric_functions.pruned_convolution
#: nnabla.parametric_functions.rnn nnabla.parametric_functions.spectral_norm
#: nnabla.parametric_functions.svd_affine
#: nnabla.parametric_functions.svd_convolution
#: nnabla.parametric_functions.sync_batch_normalization
#: nnabla.parametric_functions.transformer
#: nnabla.parametric_functions.transformer_decode
#: nnabla.parametric_functions.transformer_encode
#: nnabla.parametric_functions.weight_normalization of
msgid "戻り値"
msgstr ""

#: nnabla.parameter.get_parameters:12 of
msgid "{:obj:`str` : :obj:`~nnabla.Variable`}"
msgstr ""

#: nnabla.initializer.BaseInitializer.__call__ nnabla.parameter.get_parameters
#: nnabla.parametric_functions.affine
#: nnabla.parametric_functions.batch_normalization
#: nnabla.parametric_functions.convolution
#: nnabla.parametric_functions.cpd3_convolution
#: nnabla.parametric_functions.deconvolution
#: nnabla.parametric_functions.depthwise_convolution
#: nnabla.parametric_functions.depthwise_deconvolution
#: nnabla.parametric_functions.embed
#: nnabla.parametric_functions.fixed_point_quantized_affine
#: nnabla.parametric_functions.fixed_point_quantized_convolution
#: nnabla.parametric_functions.fused_batch_normalization
#: nnabla.parametric_functions.group_normalization
#: nnabla.parametric_functions.gru
#: nnabla.parametric_functions.layer_normalization
#: nnabla.parametric_functions.lstm
#: nnabla.parametric_functions.mean_subtraction
#: nnabla.parametric_functions.min_max_quantized_affine
#: nnabla.parametric_functions.min_max_quantized_convolution
#: nnabla.parametric_functions.multi_head_attention
#: nnabla.parametric_functions.parametric_function_api
#: nnabla.parametric_functions.pow2_quantized_affine
#: nnabla.parametric_functions.pow2_quantized_convolution
#: nnabla.parametric_functions.prelu nnabla.parametric_functions.pruned_affine
#: nnabla.parametric_functions.pruned_convolution
#: nnabla.parametric_functions.rnn nnabla.parametric_functions.spectral_norm
#: nnabla.parametric_functions.svd_affine
#: nnabla.parametric_functions.svd_convolution
#: nnabla.parametric_functions.sync_batch_normalization
#: nnabla.parametric_functions.transformer
#: nnabla.parametric_functions.transformer_decode
#: nnabla.parametric_functions.transformer_encode
#: nnabla.parametric_functions.weight_normalization of
msgid "戻り値の型"
msgstr ""

#: nnabla.parameter.clear_parameters:1 of
msgid "Clear all parameters in the current scope."
msgstr "現在のスコープにおけるすべてのパラメータを消去します。"

#: nnabla.parameter.save_parameters:1 of
msgid "Save all parameters into a file with the specified format."
msgstr "すべてのパラメータを特定のフォーマットでファイルに保存します。"

#: nnabla.parameter.save_parameters:3 of
msgid "Currently hdf5 and protobuf formats are supported."
msgstr "現在、hdf5 と protobuf のフォーマットがサポートされています。"

#: nnabla.parameter.load_parameters:3 nnabla.parameter.save_parameters:5 of
msgid "path or file object"
msgstr "パスまたはファイルオブジェクト"

#: nnabla.parameter.save_parameters:6 of
msgid ""
"Parameters to be saved. Dictionary is of a parameter name (:obj:`str`) to"
" :obj:`~nnabla.Variable`."
msgstr "保存されるパラメータ。辞書は :obj:`~nnabla.Variable` へのパラメータ名 (:obj:`str`) です。"

#: nnabla.parameter.load_parameters:1 of
msgid "Load parameters from a file with the specified format."
msgstr "特定のフォーマットのファイルからパラメータを読み込みます。"

#: nnabla.parameter.get_parameter_or_create:1 of
msgid ""
"Returns an existing parameter variable in current parameter scope with "
"the provided name."
msgstr "現在のパラメータスコープに存在する、指定された名前のパラメータ変数を返します。"

#: nnabla.parameter.get_parameter_or_create:4 of
msgid ""
"If a variable with the provided name does not exist, a new variable is "
"created and registered to the current parameter scope with the name, then"
" returned."
msgstr "指定された名前の変数が存在しない場合には、新しい変数を作成し、現在のパラメータスコープにその名前で登録してから、パラメータ変数を返します。"

#: nnabla.parameter.get_parameter_or_create:8 of
msgid ""
"The name under the current scope. If it already exists, the name is "
"queried from the parameter manager."
msgstr "現在のスコープにおける名前。すでに存在する場合、名前はパラメータマネージャーから照会されます。"

#: nnabla.parameter.get_parameter_or_create:11 of
msgid ""
"Shape of created parameter. The shape of the specified parameter must "
"match with this shape. The default is None which is only valid if "
"initializer is given as an :obj:`numpy.ndarray`."
msgstr ""
"作成されるパラメータの形状。指定されたパラメータの形状は、この形状と一致する必要があります。デフォルトは None で、イニシャライザーが "
":obj:`numpy.ndarray` として指定されている場合にのみ有効です。 "

#: nnabla.parameter.get_parameter_or_create:15 of
msgid ""
"An initialization function to be applied to the parameter. "
":obj:`numpy.ndarray` can also be given to initialize parameters from "
"numpy array data."
msgstr ""
"パラメータに適用される初期化関数。 :obj:`numpy.ndarray` を指定して、numpy "
"配列データからパラメータを初期化することもできます。"

#: nnabla.parameter.get_parameter_or_create:19 of
msgid ""
"Register the parameter with the specified ``need_grad`` flag. The default"
" is True. If the flag is different from the previously specified one, the"
" flag will be overwritten, but the values will be kept."
msgstr ""
"指定された ``need_grad`` フラグでパラメータを登録します。デフォルトは True "
"です。フラグが以前に指定されたものと異なる場合、フラグは上書きされますが、パラメータの値は保持されます。"

#: nnabla.parameter.get_parameter_or_create:24 of
msgid ""
"Get a parameter variable with the specified ``need_grad`` flag. Note that"
" this doesn't overwrite the flag of the registered parameter variable "
"with the provided name. Instead, if the given flag mismatches with the "
"previously registered ``need_grad`` flag, it returns a new variable "
"referring to the same array contents but with ``need_grad=as_need_grad``."
msgstr ""
"指定された ``need_grad`` "
"フラグでパラメータ変数を取得します。これは、指定された名前を持つ、登録済みのパラメータ変数のフラグを上書きしないことに注意してください。代わりに、指定されたフラグが以前に登録された"
" ``need_grad`` フラグと一致しない場合、同じ配列の内容を参照する新しい変数を返しますが、その際 "
"``need_grad=as_need_grad`` を使用します。"

#: nnabla.parameter.get_parameter_or_create:34 of
msgid ""
"It returns a `Variable` which is unlinked from the registered one in the "
"current parmeter scope (using "
":py:meth:`nnabla.Variable.get_unlinked_variable`). That means changing a "
"`need_grad` attribute doesn't affect the variable existing in the current"
" parameter scope."
msgstr ""
"このメソッドは、現在のパラメータスコープにおいて登録されているものとは繋がりのない `Variable` を返します（ "
":py:meth:`nnabla.Variable.get_unlinked_variable` を使用）。つまり、 `need_grad` "
"属性の変更は、現在のパラメータスコープに存在する変数に影響しません。"

#: ../../python/api/parametric_function.rst:37
msgid "List of Parametric Functions"
msgstr "パラメトリック関数リスト"

#: ../../python/api/parametric_function.rst:41
msgid ""
"Parametric functions are provided by "
":py:mod:`nnabla.parametric_functions` , as listed below. Like functions "
"listed in :ref:`functions`, they take :obj:`~nnabla.Variable` (s) as "
"first argument(s) followed by options specific to a parametric function. "
"In addition, they register parameter :obj:`~nnabla.Variable` (s) into the"
" parameter scope."
msgstr ""
"以下にリストアップされているパラメトリック関数は、 :py:mod:`nnabla.parametric_functions` "
"にて提供されています。 :ref:`functions` にリストされている関数と同様に、最初の引数には "
":obj:`~nnabla.Variable` 、次にそれぞれのパラメトリック関数固有のオプションを取ります。さらに、パラメータ変数 ( "
":obj:`~nnabla.Variable` ) をパラメータスコープに登録します。"

#: ../../python/api/parametric_function.rst:46
msgid ""
"The parameter variables are registered with ``need_grad`` properties "
"specific to a parametric function. The variables with ``need_grad=False``"
" flag will not be updated by gradient descent. Hence, backward "
"computation is not executed for those variables. ``False`` is usually "
"specified when the parameters are updated during foward pass and/or "
"backward pass, e.g., batch normalization."
msgstr ""
"パラメータ変数は、それぞれのパラメトリック関数ごとに指定された ``need_grad`` プロパティを使ってパラメトリック関数に登録されます。 "
"``need_grad=False`` フラグが設定された変数は、勾配降下による更新は行われません。したがって、これらの変数に対して "
"backward 計算が行われることはありません。forward パスや backward パスの間、パラメータを更新する場合(例えば、batch"
" normalizationなど)、通常 ``False`` が指定されます。"

#: ../../python/api/parametric_function.rst:52
msgid ""
"All parametric functions take an optional argument "
"``fix_parameters=False``. By giving ``True``, the associated parameter "
"variables are connected to a computation graph with a property "
"``need_grad=False`` regardless properties of the registered variables, "
"then backward gradient computation is not executed for those variables. "
"This is useful when you create a computation graph for evaluation "
"purpose, fixing parameters partially in a graph, and so on."
msgstr ""
"すべてのパラメトリック関数は、オプション引数 ``fix_parameters=False`` を取ります。 ``True`` "
"を渡すと、関連したパラメータ変数は登録されている変数のプロパティに関係なく、プロパティ ``need_grad=False`` で計算グラフ "
"(computation graph) に繋がり、それらの変数に対して backward "
"勾配計算は行われません。これは、評価目的で計算グラフを構築したり、グラフ中の一部のパラメータを固定したりする際に便利です。"

#: ../../python/api/parametric_function.rst:60
msgid ""
"All parametric functions listed below are decorated with the following "
"decorator."
msgstr "以下にリストアップされているパラメトリック関数はすべて、下記のデコレータを使ってデコレートされています。"

#: nnabla.parametric_functions.parametric_function_api:1 of
msgid "Decorator for parametric functions."
msgstr "パラメトリック関数のデコレータ"

#: nnabla.parametric_functions.parametric_function_api:3 of
msgid ""
"The decorated function is always called under a parameter scope "
"``scope_name``. Also, the decorator adds an additional argument ``name`` "
"(:obj:`str`, default is ``None``) at the end. If ``name`` is specified, "
"the scope ``scope_name`` comes under a scope ``name``. This feature could"
" reduce vertical space usage of the source code. Any parametric function "
"should be decorated by this."
msgstr ""
"デコレートされた関数は、常にパラメータスコープ ``scope_name`` のもとで呼ばれます。また、最後の引数として ``name`` "
"(:obj:`str`, デフォルトは ``None``) が追加されます。``name`` が指定されると、スコープ "
"``scope_name`` はスコープ ``name`` "
"の下にネストされます。この機能に利用することで、ソースコードの行数を削減することができます。どのパラメトリック関数でもこのデコレータでデコレートする必要があります。"

#: nnabla.parametric_functions.parametric_function_api:11 of
msgid ""
"The original function will be called under a parameter scope named by "
"``scope_name``."
msgstr "元の関数は、 ``scope_name`` で指定されたパラメータスコープ内で呼び出されます。"

#: nnabla.parametric_functions.parametric_function_api:14 of
msgid ""
"Descriptions of parameters will be automatically included into docstring."
" This must be a list of tuples with 4 elements composed of (name (str), "
"description (str), shape info (str), need_grad (bool))."
msgstr ""
"パラメータの説明は自動的に docstring に含まれます。これは、( name ( str )、description ( str "
")、shape info ( str )、need_grad ( bool ) )で構成される 4 "
"つの要素を持つタプルのリストである必要があります。"

#: nnabla.parametric_functions.parametric_function_api:19 of
msgid "A decorated parametric function."
msgstr "デコレートされたパラメトリック関数"

#: ../../python/api/parametric_function.rst:64
msgid ""
"See :ref:`parameter` to know how to query and manipulate registered "
"variables."
msgstr "登録されている変数を照会および操作する方法については、 :ref:`parameter` を参照してください。"

#: ../../python/api/parametric_function.rst:66
msgid "Here is the list of parametric functions."
msgstr "以下は、パラメトリック関数のリストです。"

#: nnabla.parametric_functions.affine:1 of
msgid "The affine layer, also known as the fully connected layer. Computes"
msgstr "全結合層ともいわれる、affine 層。以下の計算を行います。"

#: nnabla.parametric_functions.affine:3 of
msgid "{\\mathbf y} = {\\mathbf A} {\\mathbf x} + {\\mathbf b}."
msgstr ""

#: nnabla.parametric_functions.affine:6 of
msgid ""
"where :math:`{\\mathbf x}, {\\mathbf y}` are the inputs and outputs "
"respectively, and :math:`{\\mathbf A}, {\\mathbf b}` are constants."
msgstr ""
"ここでは、 :math:`{\\mathbf x}, {\\mathbf y}` はそれぞれ入力、出力、 :math:`{\\mathbf A},"
" {\\mathbf b}` は定数です。"

#: nnabla.parametric_functions.affine:9
#: nnabla.parametric_functions.binary_connect_affine:36
#: nnabla.parametric_functions.fixed_point_quantized_affine:27
#: nnabla.parametric_functions.min_max_quantized_affine:32
#: nnabla.parametric_functions.pow2_quantized_affine:27
#: nnabla.parametric_functions.pruned_affine:27
#: nnabla.parametric_functions.svd_affine:36 of
msgid ""
"Input N-D array with shape (:math:`M_0 \\times \\ldots \\times M_{B-1} "
"\\times D_B \\times \\ldots \\times D_N`). Dimensions before and after "
"base_axis are flattened as if it is a matrix."
msgstr ""
"(:math:`M_0 \\times \\ldots \\times M_{B-1} \\times D_B \\times \\ldots "
"\\times D_N`) の形状の入力 N-D 配列。base_axis 前後の次元は、行列となるように平坦化されます。"

#: nnabla.parametric_functions.affine:11
#: nnabla.parametric_functions.binary_connect_affine:38
#: nnabla.parametric_functions.binary_weight_affine:36
#: nnabla.parametric_functions.fixed_point_quantized_affine:29
#: nnabla.parametric_functions.inq_affine:19
#: nnabla.parametric_functions.inq_convolution:19
#: nnabla.parametric_functions.min_max_quantized_affine:34
#: nnabla.parametric_functions.pow2_quantized_affine:29
#: nnabla.parametric_functions.pruned_affine:29
#: nnabla.parametric_functions.svd_affine:41 of
msgid "Number of output neurons per data."
msgstr "データごとの出力ニューロンの数。"

#: nnabla.parametric_functions.affine:13
#: nnabla.parametric_functions.binary_connect_affine:40
#: nnabla.parametric_functions.binary_connect_convolution:58
#: nnabla.parametric_functions.binary_weight_affine:38
#: nnabla.parametric_functions.binary_weight_convolution:58
#: nnabla.parametric_functions.convolution:45
#: nnabla.parametric_functions.cpd3_convolution:49
#: nnabla.parametric_functions.deconvolution:21
#: nnabla.parametric_functions.depthwise_convolution:23
#: nnabla.parametric_functions.depthwise_deconvolution:20
#: nnabla.parametric_functions.fixed_point_quantized_affine:31
#: nnabla.parametric_functions.fixed_point_quantized_convolution:45
#: nnabla.parametric_functions.inq_affine:21
#: nnabla.parametric_functions.inq_convolution:21
#: nnabla.parametric_functions.min_max_quantized_affine:36
#: nnabla.parametric_functions.min_max_quantized_convolution:52
#: nnabla.parametric_functions.pow2_quantized_affine:31
#: nnabla.parametric_functions.pow2_quantized_convolution:45
#: nnabla.parametric_functions.pruned_affine:31
#: nnabla.parametric_functions.pruned_convolution:45
#: nnabla.parametric_functions.svd_affine:45
#: nnabla.parametric_functions.svd_convolution:58 of
msgid "Dimensions up to `base_axis` are treated as the sample dimensions."
msgstr "`base_axis` までの次元は、サンプル次元として扱われます。"

#: nnabla.parametric_functions.LSTMCell.__call__:5
#: nnabla.parametric_functions.affine:15
#: nnabla.parametric_functions.binary_connect_affine:44
#: nnabla.parametric_functions.binary_connect_convolution:52
#: nnabla.parametric_functions.binary_weight_convolution:52
#: nnabla.parametric_functions.convolution:41
#: nnabla.parametric_functions.deconvolution:17
#: nnabla.parametric_functions.depthwise_deconvolution:16
#: nnabla.parametric_functions.fixed_point_quantized_affine:33
#: nnabla.parametric_functions.fixed_point_quantized_convolution:41
#: nnabla.parametric_functions.inq_affine:33
#: nnabla.parametric_functions.lstm_cell:26
#: nnabla.parametric_functions.min_max_quantized_affine:38
#: nnabla.parametric_functions.min_max_quantized_convolution:48
#: nnabla.parametric_functions.pow2_quantized_affine:33
#: nnabla.parametric_functions.pow2_quantized_convolution:41
#: nnabla.parametric_functions.svd_affine:48
#: nnabla.parametric_functions.svd_convolution:54 of
msgid ""
"Initializer for weight. By default, it is initialized with "
":obj:`nnabla.initializer.UniformInitializer` within the range determined "
"by :obj:`nnabla.initializer.calc_uniform_lim_glorot`."
msgstr ""
"重みのイニシャライザー。デフォルトでは、 :obj:`nnabla.initializer.calc_uniform_lim_glorot` "
"によって決定される範囲内で :obj:`nnabla.initializer.UniformInitializer` で初期化されます。"

#: nnabla.parametric_functions.LSTMCell.__call__:7
#: nnabla.parametric_functions.affine:17
#: nnabla.parametric_functions.binary_connect_affine:48
#: nnabla.parametric_functions.binary_connect_convolution:56
#: nnabla.parametric_functions.binary_weight_convolution:56
#: nnabla.parametric_functions.convolution:43
#: nnabla.parametric_functions.deconvolution:19
#: nnabla.parametric_functions.depthwise_convolution:21
#: nnabla.parametric_functions.depthwise_deconvolution:18
#: nnabla.parametric_functions.fixed_point_quantized_affine:35
#: nnabla.parametric_functions.fixed_point_quantized_convolution:43
#: nnabla.parametric_functions.inq_affine:37
#: nnabla.parametric_functions.lstm_cell:28
#: nnabla.parametric_functions.min_max_quantized_affine:40
#: nnabla.parametric_functions.min_max_quantized_convolution:50
#: nnabla.parametric_functions.pow2_quantized_affine:35
#: nnabla.parametric_functions.pow2_quantized_convolution:43
#: nnabla.parametric_functions.svd_affine:50
#: nnabla.parametric_functions.svd_convolution:56 of
msgid ""
"Initializer for bias. By default, it is initialized with zeros if "
"`with_bias` is `True`."
msgstr "バイアスのイニシャライザー。 `with_bias` が `True` の場合、デフォルトではゼロで初期化されます。"

#: nnabla.parametric_functions.LSTMCell.__call__:9
#: nnabla.parametric_functions.affine:19
#: nnabla.parametric_functions.binary_connect_affine:50
#: nnabla.parametric_functions.binary_connect_convolution:60
#: nnabla.parametric_functions.binary_weight_convolution:60
#: nnabla.parametric_functions.convolution:47
#: nnabla.parametric_functions.cpd3_convolution:51
#: nnabla.parametric_functions.deconvolution:23
#: nnabla.parametric_functions.depthwise_convolution:25
#: nnabla.parametric_functions.depthwise_deconvolution:22
#: nnabla.parametric_functions.fixed_point_quantized_affine:37
#: nnabla.parametric_functions.fixed_point_quantized_convolution:47
#: nnabla.parametric_functions.lstm:43 nnabla.parametric_functions.lstm_cell:30
#: nnabla.parametric_functions.min_max_quantize:105
#: nnabla.parametric_functions.min_max_quantized_affine:42
#: nnabla.parametric_functions.min_max_quantized_convolution:54
#: nnabla.parametric_functions.pow2_quantized_affine:37
#: nnabla.parametric_functions.pow2_quantized_convolution:47
#: nnabla.parametric_functions.pruned_affine:37
#: nnabla.parametric_functions.pruned_convolution:47
#: nnabla.parametric_functions.svd_affine:52
#: nnabla.parametric_functions.svd_convolution:61 of
msgid "When set to `True`, the weights and biases will not be updated."
msgstr "`True` の場合, 重みとバイアスは更新されません。"

#: nnabla.parametric_functions.affine:21
#: nnabla.parametric_functions.binary_connect_affine:52
#: nnabla.parametric_functions.binary_connect_convolution:62
#: nnabla.parametric_functions.binary_weight_affine:50
#: nnabla.parametric_functions.binary_weight_convolution:62
#: nnabla.parametric_functions.convolution:49
#: nnabla.parametric_functions.cpd3_convolution:53
#: nnabla.parametric_functions.deconvolution:25
#: nnabla.parametric_functions.depthwise_convolution:27
#: nnabla.parametric_functions.depthwise_deconvolution:24
#: nnabla.parametric_functions.fixed_point_quantized_affine:39
#: nnabla.parametric_functions.fixed_point_quantized_convolution:49
#: nnabla.parametric_functions.inq_affine:41
#: nnabla.parametric_functions.inq_convolution:39
#: nnabla.parametric_functions.min_max_quantized_affine:44
#: nnabla.parametric_functions.min_max_quantized_convolution:56
#: nnabla.parametric_functions.pow2_quantized_affine:39
#: nnabla.parametric_functions.pow2_quantized_convolution:49
#: nnabla.parametric_functions.pruned_affine:39
#: nnabla.parametric_functions.pruned_convolution:49
#: nnabla.parametric_functions.svd_affine:55
#: nnabla.parametric_functions.svd_convolution:64 of
msgid "Random generator for Initializer."
msgstr "イニシャライザーのためのランダムジェネレーター。"

#: nnabla.parametric_functions.affine:23
#: nnabla.parametric_functions.binary_connect_convolution:64
#: nnabla.parametric_functions.binary_weight_affine:52
#: nnabla.parametric_functions.binary_weight_convolution:64
#: nnabla.parametric_functions.convolution:51
#: nnabla.parametric_functions.cpd3_convolution:55
#: nnabla.parametric_functions.deconvolution:27
#: nnabla.parametric_functions.depthwise_convolution:29
#: nnabla.parametric_functions.depthwise_deconvolution:26
#: nnabla.parametric_functions.fixed_point_quantized_affine:41
#: nnabla.parametric_functions.fixed_point_quantized_convolution:51
#: nnabla.parametric_functions.gru:37 nnabla.parametric_functions.inq_affine:43
#: nnabla.parametric_functions.inq_convolution:41
#: nnabla.parametric_functions.lstm:41
#: nnabla.parametric_functions.min_max_quantized_affine:46
#: nnabla.parametric_functions.min_max_quantized_convolution:58
#: nnabla.parametric_functions.pow2_quantized_affine:41
#: nnabla.parametric_functions.pow2_quantized_convolution:51
#: nnabla.parametric_functions.pruned_affine:41
#: nnabla.parametric_functions.pruned_convolution:51
#: nnabla.parametric_functions.rnn:37 nnabla.parametric_functions.svd_affine:57
#: nnabla.parametric_functions.svd_convolution:66 of
msgid "Specify whether to include the bias term."
msgstr "バイアス項を含めるか否かを指定します。"

#: nnabla.parametric_functions.affine:25
#: nnabla.parametric_functions.convolution:53
#: nnabla.parametric_functions.deconvolution:29
#: nnabla.parametric_functions.embed:12 of
msgid "Lambda, function, or callable object applied to the weights."
msgstr "重みに適用されるラムダ、関数、または呼び出し可能なオブジェクト。"

#: nnabla.parametric_functions.affine:27
#: nnabla.parametric_functions.convolution:55
#: nnabla.parametric_functions.deconvolution:31 of
msgid "Lambda, function, or callable object applied to the bias."
msgstr "バイアスに適用されるラムダ、関数、または呼び出し可能なオブジェクト。"

#: nnabla.parametric_functions.affine:30
#: nnabla.parametric_functions.cpd3_convolution:67
#: nnabla.parametric_functions.fixed_point_quantized_affine:62
#: nnabla.parametric_functions.min_max_quantized_affine:80
#: nnabla.parametric_functions.pow2_quantized_affine:66
#: nnabla.parametric_functions.pruned_affine:52
#: nnabla.parametric_functions.svd_affine:60
#: nnabla.parametric_functions.svd_convolution:69 of
msgid ""
":math:`(B + 1)`-D array. (:math:`M_0 \\times \\ldots \\times M_{B-1} "
"\\times L`)"
msgstr ""
":math:`(B + 1)`-D 配列。 (:math:`M_0 \\times \\ldots \\times M_{B-1} \\times"
" L`)"

#: nnabla.parametric_functions.affine:31
#: nnabla.parametric_functions.batch_normalization:45
#: nnabla.parametric_functions.binary_connect_affine:55
#: nnabla.parametric_functions.binary_connect_convolution:67
#: nnabla.parametric_functions.binary_weight_affine:55
#: nnabla.parametric_functions.binary_weight_convolution:67
#: nnabla.parametric_functions.convolution:59
#: nnabla.parametric_functions.cpd3_convolution:68
#: nnabla.parametric_functions.deconvolution:35
#: nnabla.parametric_functions.depthwise_convolution:33
#: nnabla.parametric_functions.depthwise_deconvolution:30
#: nnabla.parametric_functions.fixed_point_quantized_affine:63
#: nnabla.parametric_functions.fixed_point_quantized_convolution:75
#: nnabla.parametric_functions.fused_batch_normalization:33
#: nnabla.parametric_functions.inq_affine:46
#: nnabla.parametric_functions.inq_convolution:44
#: nnabla.parametric_functions.lstm_cell:33
#: nnabla.parametric_functions.min_max_quantized_affine:81
#: nnabla.parametric_functions.min_max_quantized_convolution:93
#: nnabla.parametric_functions.pow2_quantized_affine:67
#: nnabla.parametric_functions.pow2_quantized_convolution:75
#: nnabla.parametric_functions.pruned_affine:53
#: nnabla.parametric_functions.pruned_convolution:63
#: nnabla.parametric_functions.svd_convolution:71
#: nnabla.parametric_functions.sync_batch_normalization:51 of
msgid ":class:`~nnabla.Variable`"
msgstr ""

#: nnabla.parametric_functions.affine:38
#: nnabla.parametric_functions.batch_normalization:65
#: nnabla.parametric_functions.binary_connect_affine:63
#: nnabla.parametric_functions.binary_connect_convolution:75
#: nnabla.parametric_functions.binary_weight_affine:64
#: nnabla.parametric_functions.binary_weight_convolution:76
#: nnabla.parametric_functions.convolution:66
#: nnabla.parametric_functions.cpd3_convolution:77
#: nnabla.parametric_functions.deconvolution:42
#: nnabla.parametric_functions.depthwise_convolution:40
#: nnabla.parametric_functions.depthwise_deconvolution:37
#: nnabla.parametric_functions.embed:22
#: nnabla.parametric_functions.fixed_point_quantized_affine:72
#: nnabla.parametric_functions.fixed_point_quantized_convolution:84
#: nnabla.parametric_functions.fused_batch_normalization:42
#: nnabla.parametric_functions.group_normalization:61
#: nnabla.parametric_functions.gru:58 nnabla.parametric_functions.inq_affine:54
#: nnabla.parametric_functions.inq_convolution:52
#: nnabla.parametric_functions.instance_normalization:53
#: nnabla.parametric_functions.layer_normalization:55
#: nnabla.parametric_functions.lstm:66 nnabla.parametric_functions.lstm_cell:40
#: nnabla.parametric_functions.mean_subtraction:37
#: nnabla.parametric_functions.min_max_quantize:117
#: nnabla.parametric_functions.min_max_quantized_affine:92
#: nnabla.parametric_functions.min_max_quantized_convolution:104
#: nnabla.parametric_functions.multi_head_attention:69
#: nnabla.parametric_functions.pow2_quantized_affine:76
#: nnabla.parametric_functions.pow2_quantized_convolution:84
#: nnabla.parametric_functions.prelu:28
#: nnabla.parametric_functions.pruned_affine:62
#: nnabla.parametric_functions.pruned_convolution:72
#: nnabla.parametric_functions.rnn:58
#: nnabla.parametric_functions.spectral_norm:58
#: nnabla.parametric_functions.svd_affine:70
#: nnabla.parametric_functions.svd_convolution:79
#: nnabla.parametric_functions.sync_batch_normalization:73
#: nnabla.parametric_functions.transformer:66
#: nnabla.parametric_functions.transformer_decode:45
#: nnabla.parametric_functions.transformer_encode:37
#: nnabla.parametric_functions.weight_normalization:50 of
msgid "Parameters to be registered"
msgstr "登録されるパラメータ"

#: nnabla.parametric_functions.affine:34 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"affine\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"affine\"`` に登録されます。"

#: nnabla.parametric_functions.affine:36 of
msgid "W (``need_grad=True``) : Weight matrix. (shape: ``(inmaps, outmaps)``)"
msgstr "W (``need_grad=True``) : 重み行列 (形状: ``(inmaps, outmaps)``)"

#: nnabla.parametric_functions.affine:37 of
msgid "b (``need_grad=True``) : bias vector. (shape: ``(outputs,)``)"
msgstr "b (``need_grad=True``) : バイアスベクター (形状: ``(outputs,)``)"

#: nnabla.parametric_functions.affine:42
#: nnabla.parametric_functions.batch_normalization:69
#: nnabla.parametric_functions.binary_connect_affine:67
#: nnabla.parametric_functions.binary_connect_convolution:79
#: nnabla.parametric_functions.binary_weight_affine:68
#: nnabla.parametric_functions.binary_weight_convolution:80
#: nnabla.parametric_functions.convolution:70
#: nnabla.parametric_functions.cpd3_convolution:81
#: nnabla.parametric_functions.deconvolution:46
#: nnabla.parametric_functions.depthwise_convolution:44
#: nnabla.parametric_functions.depthwise_deconvolution:41
#: nnabla.parametric_functions.embed:26
#: nnabla.parametric_functions.fixed_point_quantized_affine:76
#: nnabla.parametric_functions.fixed_point_quantized_convolution:88
#: nnabla.parametric_functions.fused_batch_normalization:46
#: nnabla.parametric_functions.group_normalization:65
#: nnabla.parametric_functions.gru:62 nnabla.parametric_functions.inq_affine:58
#: nnabla.parametric_functions.inq_convolution:56
#: nnabla.parametric_functions.instance_normalization:57
#: nnabla.parametric_functions.layer_normalization:59
#: nnabla.parametric_functions.lstm:70 nnabla.parametric_functions.lstm_cell:44
#: nnabla.parametric_functions.mean_subtraction:41
#: nnabla.parametric_functions.min_max_quantize:121
#: nnabla.parametric_functions.min_max_quantized_affine:96
#: nnabla.parametric_functions.min_max_quantized_convolution:108
#: nnabla.parametric_functions.multi_head_attention:73
#: nnabla.parametric_functions.pow2_quantized_affine:80
#: nnabla.parametric_functions.pow2_quantized_convolution:88
#: nnabla.parametric_functions.prelu:32
#: nnabla.parametric_functions.pruned_affine:66
#: nnabla.parametric_functions.pruned_convolution:76
#: nnabla.parametric_functions.rnn:62
#: nnabla.parametric_functions.spectral_norm:62
#: nnabla.parametric_functions.svd_affine:74
#: nnabla.parametric_functions.svd_convolution:83
#: nnabla.parametric_functions.sync_batch_normalization:77
#: nnabla.parametric_functions.transformer:70
#: nnabla.parametric_functions.transformer_decode:49
#: nnabla.parametric_functions.transformer_encode:41
#: nnabla.parametric_functions.weight_normalization:54 of
msgid ""
"If the ``name`` option is passed, the parameters become wrapped inside "
"the parameter scope with the specified name, yielding the same results as"
" the following code. This can be used to simplify the code."
msgstr ""
"``name`` "
"オプションが渡された場合、パラメータは特定の名前でパラメータスコープ内にラップされ、以下のコードと同じ結果となります。これは、コードの簡素化に利用できます。"

#: nnabla.parametric_functions.affine:46 of
msgid ""
"with parametric_scope(name):\n"
"    output = affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.convolution:1 of
msgid "N-D Convolution with a bias term."
msgstr "バイアス項を含んだ N-D Convolution"

#: nnabla.parametric_functions.convolution:3 of
msgid "For Dilated Convolution (a.k.a. Atrous Convolution), refer to:"
msgstr "Dilated Convolution (別名 Atrous Convolution) については、以下をご参照ください。"

#: nnabla.parametric_functions.convolution:5 of
msgid ""
"Chen et al., DeepLab: Semantic Image Segmentation with Deep Convolutional"
" Nets, Atrous Convolution, and Fully Connected CRFs. "
"https://arxiv.org/abs/1606.00915"
msgstr ""

#: nnabla.parametric_functions.convolution:7 of
msgid ""
"Yu et al., Multi-Scale Context Aggregation by Dilated Convolutions. "
"https://arxiv.org/abs/1511.07122"
msgstr ""

#: nnabla.parametric_functions.convolution:11 of
msgid ""
"Convolution is a computationally intensive operation that should "
"preferably be run with the `cudnn` backend. NNabla then uses CuDNN "
"library functions to determine and cache the fastest algorithm for the "
"given set of convolution parameters, which results in additional memory "
"consumption which may pose a problem for GPUs with insufficient memory "
"size. In that case, the `NNABLA_CUDNN_WORKSPACE_LIMIT` environment "
"variable can be used to restrict the choice of algorithms to those that "
"fit the given workspace memory limit, expressed in bytes. In some cases "
"it may also be desired to restrict the automatic search to algorithms "
"that produce deterministic (reproducible) results. This can be requested "
"by setting the the environment variable `NNABLA_CUDNN_DETERMINISTIC` to a"
" non-zero value."
msgstr ""
"Convolution は、計算負荷の大きい演算となるため、 `cudnn` バックエンドで実行することを推奨します。その際、NNabla は "
"CuDNN library の関数を使って、 与えられたconvolution "
"パラメータセットに対して最速のアルゴリズムを決定し、キャッシュします。それにより、メモリをさらに消費し、GPU "
"のメモリサイズが足りなくなる問題を引き起こす可能性があります。そのような場合は、環境変数 "
"`NNABLA_CUDNN_WORKSPACE_LIMIT` "
"にバイト数を指定することで、所定のワークスペースのメモリ制限に収まるように、アルゴリズムの選択を制限することができます。場合によっては、自動検索を決定的な（再現性のある）結果を生成するアルゴリズムに制限した方がよいケースがあります。その場合には、環境変数"
" `NNABLA_CUDNN_DETERMINISTIC` をゼロ以外の値に設定してください。"

#: nnabla.parametric_functions.batch_normalization:44
#: nnabla.parametric_functions.binary_connect_convolution:36
#: nnabla.parametric_functions.binary_weight_convolution:36
#: nnabla.parametric_functions.convolution:25
#: nnabla.parametric_functions.cpd3_convolution:31
#: nnabla.parametric_functions.deconvolution:3
#: nnabla.parametric_functions.depthwise_convolution:7
#: nnabla.parametric_functions.depthwise_deconvolution:4
#: nnabla.parametric_functions.fixed_point_quantized_convolution:27
#: nnabla.parametric_functions.fixed_point_quantized_convolution:74
#: nnabla.parametric_functions.fused_batch_normalization:32
#: nnabla.parametric_functions.mean_subtraction:29
#: nnabla.parametric_functions.min_max_quantized_convolution:32
#: nnabla.parametric_functions.min_max_quantized_convolution:92
#: nnabla.parametric_functions.pow2_quantized_convolution:27
#: nnabla.parametric_functions.pow2_quantized_convolution:74
#: nnabla.parametric_functions.prelu:21
#: nnabla.parametric_functions.pruned_convolution:27
#: nnabla.parametric_functions.pruned_convolution:62
#: nnabla.parametric_functions.svd_convolution:35
#: nnabla.parametric_functions.sync_batch_normalization:50 of
msgid "N-D array."
msgstr "N-D 配列"

#: nnabla.parametric_functions.binary_connect_convolution:38
#: nnabla.parametric_functions.binary_weight_convolution:38
#: nnabla.parametric_functions.convolution:27
#: nnabla.parametric_functions.cpd3_convolution:33
#: nnabla.parametric_functions.fixed_point_quantized_convolution:29
#: nnabla.parametric_functions.min_max_quantized_convolution:34
#: nnabla.parametric_functions.pow2_quantized_convolution:29
#: nnabla.parametric_functions.pruned_convolution:29
#: nnabla.parametric_functions.svd_convolution:37 of
msgid ""
"Number of convolution kernels (which is equal to the number of output "
"channels). For example, to apply convolution on an input with 16 types of"
" filters, specify 16."
msgstr ""
"convolution カーネルの数（出力チャネルの数）。例えば、入力に対して、16 種類のフィルターによるconvolution "
"を適用するには、16を指定します。"

#: nnabla.parametric_functions.binary_connect_convolution:40
#: nnabla.parametric_functions.binary_weight_convolution:40
#: nnabla.parametric_functions.convolution:29
#: nnabla.parametric_functions.cpd3_convolution:35
#: nnabla.parametric_functions.depthwise_convolution:9
#: nnabla.parametric_functions.depthwise_deconvolution:6
#: nnabla.parametric_functions.fixed_point_quantized_convolution:31
#: nnabla.parametric_functions.min_max_quantized_convolution:36
#: nnabla.parametric_functions.pow2_quantized_convolution:31
#: nnabla.parametric_functions.pruned_convolution:31 of
msgid ""
"Convolution kernel size. For example, to apply convolution on an image "
"with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5)."
msgstr ""
"convolution カーネルのサイズ。例えば、画像に対して、3（高さ）x 5（幅）の 2 次元カーネルによる convolution "
"を適用するには、( 3, 5 ) を指定します。"

#: nnabla.parametric_functions.binary_connect_convolution:42
#: nnabla.parametric_functions.binary_weight_convolution:42
#: nnabla.parametric_functions.convolution:31
#: nnabla.parametric_functions.cpd3_convolution:39
#: nnabla.parametric_functions.deconvolution:9
#: nnabla.parametric_functions.depthwise_convolution:11
#: nnabla.parametric_functions.depthwise_deconvolution:8
#: nnabla.parametric_functions.fixed_point_quantized_convolution:33
#: nnabla.parametric_functions.min_max_quantized_convolution:38
#: nnabla.parametric_functions.pow2_quantized_convolution:33
#: nnabla.parametric_functions.pruned_convolution:33 of
msgid "Padding sizes for dimensions."
msgstr "各次元に対するパディングサイズ。"

#: nnabla.parametric_functions.binary_connect_convolution:44
#: nnabla.parametric_functions.binary_weight_convolution:44
#: nnabla.parametric_functions.convolution:33
#: nnabla.parametric_functions.cpd3_convolution:41
#: nnabla.parametric_functions.deconvolution:11
#: nnabla.parametric_functions.depthwise_convolution:13
#: nnabla.parametric_functions.depthwise_deconvolution:10
#: nnabla.parametric_functions.fixed_point_quantized_convolution:35
#: nnabla.parametric_functions.min_max_quantized_convolution:40
#: nnabla.parametric_functions.pow2_quantized_convolution:35
#: nnabla.parametric_functions.pruned_convolution:35 of
msgid "Stride sizes for dimensions."
msgstr "各次元に対するストライドサイズ。"

#: nnabla.parametric_functions.binary_connect_convolution:46
#: nnabla.parametric_functions.binary_weight_convolution:46
#: nnabla.parametric_functions.convolution:35
#: nnabla.parametric_functions.cpd3_convolution:43
#: nnabla.parametric_functions.deconvolution:13
#: nnabla.parametric_functions.depthwise_convolution:15
#: nnabla.parametric_functions.depthwise_deconvolution:12
#: nnabla.parametric_functions.fixed_point_quantized_convolution:37
#: nnabla.parametric_functions.min_max_quantized_convolution:42
#: nnabla.parametric_functions.pow2_quantized_convolution:37
#: nnabla.parametric_functions.pruned_convolution:37 of
msgid "Dilation sizes for dimensions."
msgstr "各次元に対する膨張サイズ。"

#: nnabla.parametric_functions.convolution:37
#: nnabla.parametric_functions.fixed_point_quantized_convolution:39
#: nnabla.parametric_functions.min_max_quantized_convolution:44
#: nnabla.parametric_functions.pow2_quantized_convolution:39
#: nnabla.parametric_functions.pruned_convolution:39 of
msgid ""
"Number of groups of channels. This makes connections across channels more"
" sparse by grouping connections along map direction."
msgstr "チャネルのグループ数。これにより、マップ方向に沿って接続をグループ化することにより、チャネル間の接続がよりスパースになります。"

#: nnabla.parametric_functions.convolution:39
#: nnabla.parametric_functions.min_max_quantized_convolution:46 of
msgid ""
"If True, the last dimension is considered as channel dimension, a.k.a. "
"NHWC order."
msgstr "True の場合、最後の次元はチャネル次元になり、いわゆるNHWC 順になります。"

#: nnabla.parametric_functions.convolution:58 of
msgid "N-D array. See :obj:`~nnabla.functions.convolution` for the output shape."
msgstr "N-D 配列。出力形状については、 :obj:`~nnabla.functions.convolution` を参照してください。"

#: nnabla.parametric_functions.convolution:62 of
msgid "The following variables are registered in a parameter scope ``\"conv\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"conv\"`` に登録されます。"

#: nnabla.parametric_functions.convolution:64 of
msgid ""
"W (``need_grad=True``) : Filter weights. (shape: ``(outmaps, inmaps // "
"group, *kernel)``)"
msgstr ""
"W (``need_grad=True``) : フィルターの重み (形状: ``(outmaps, inmaps // group, "
"*kernel)``)"

#: nnabla.parametric_functions.binary_connect_affine:62
#: nnabla.parametric_functions.binary_connect_convolution:74
#: nnabla.parametric_functions.binary_weight_affine:63
#: nnabla.parametric_functions.binary_weight_convolution:75
#: nnabla.parametric_functions.convolution:65
#: nnabla.parametric_functions.cpd3_convolution:76
#: nnabla.parametric_functions.deconvolution:41
#: nnabla.parametric_functions.inq_affine:53
#: nnabla.parametric_functions.inq_convolution:51
#: nnabla.parametric_functions.svd_affine:69
#: nnabla.parametric_functions.svd_convolution:78 of
msgid "b (``need_grad=True``) : Bias vector. (shape: ``(outmaps,)``)"
msgstr "b (``need_grad=True``) : バイアスベクター (形状: ``(outmaps,)``)"

#: nnabla.parametric_functions.convolution:74 of
msgid ""
"with parametric_scope(name):\n"
"    output = convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.depthwise_convolution:1 of
msgid "N-D Depthwise Convolution with a bias term."
msgstr "バイアス項を使った N-D Depthwise Convolution"

#: nnabla.parametric_functions.depthwise_convolution:3 of
msgid "Reference:"
msgstr "参照 :"

#: nnabla.parametric_functions.depthwise_convolution:5 of
msgid ""
"Chollet: Chollet, Francois. \"Xception: Deep Learning with Depthwise "
"Separable Convolutions. https://arxiv.org/abs/1610.02357"
msgstr ""

#: nnabla.parametric_functions.depthwise_convolution:17 of
msgid "Number of output feature maps per input feature map."
msgstr "入力特徴マップごとの出力特徴マップの数。"

#: nnabla.parametric_functions.depthwise_convolution:19 of
msgid ""
"Initializer for weight.  By default, it is initialized with "
":obj:`nnabla.initializer.UniformInitializer` within the range determined "
"by :obj:`nnabla.initializer.calc_uniform_lim_glorot`."
msgstr ""
"重みのイニシャライザー。デフォルトでは、 :obj:`nnabla.initializer.calc_uniform_lim_glorot` "
"によって決定される範囲内で :obj:`nnabla.initializer.UniformInitializer` で初期化されます。"

#: nnabla.parametric_functions.depthwise_convolution:32 of
msgid ""
"N-D array. See :obj:`~nnabla.functions.depthwise_convolution` for the "
"output shape."
msgstr ""
"N-D 配列。出力形状については、 :obj:`~nnabla.functions.depthwise_convolution` "
"を参照してください。"

#: nnabla.parametric_functions.depthwise_convolution:36 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"depthwise_conv\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"depthwise_conv\"`` に登録されます。"

#: nnabla.parametric_functions.depthwise_convolution:38 of
msgid ""
"W (``need_grad=True``) : Filter weights. (shape: ``(inmaps * multiplier, "
"*kernel)``)"
msgstr "W (``need_grad=True``) : フィルターの重み (形状: ``(inmaps * multiplier, *kernel)``)"

#: nnabla.parametric_functions.depthwise_convolution:39 of
msgid "b (``need_grad=True``) : Bias vector. (shape: ``(inmaps * multiplier,)``)"
msgstr "b (``need_grad=True``) : バイアスベクター (形状: ``(inmaps * multiplier,)``)"

#: nnabla.parametric_functions.depthwise_convolution:48 of
msgid ""
"with parametric_scope(name):\n"
"    output = depthwise_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.deconvolution:1 of
msgid "Deconvolution layer."
msgstr "Deconvolution 層"

#: nnabla.parametric_functions.deconvolution:5 of
msgid ""
"Number of deconvolution kernels (which is equal to the number of output "
"channels). For example, to apply deconvolution on an input with 16 types "
"of filters, specify 16."
msgstr ""
"deconvolution カーネルの数（出力チャネル数と同じ）。例えば、入力に対して、16 種類のフィルターによるdeconvolution "
"を適用するには、16 を指定します。"

#: nnabla.parametric_functions.deconvolution:7 of
msgid ""
"Convolution kernel size. For example, to apply deconvolution on an image "
"with a 3 (height) by 5 (width) two-dimensional kernel, specify (3,5)."
msgstr ""
"convolution カーネルのサイズ。例えば、画像に対して、3（高さ）x 5（幅）の2次元カーネルによる deconvolution "
"を適用するには、( 3, 5 )を指定します。"

#: nnabla.parametric_functions.binary_connect_convolution:48
#: nnabla.parametric_functions.binary_weight_convolution:48
#: nnabla.parametric_functions.deconvolution:15 of
msgid ""
"Number of groups of channels. This makes connections across channels "
"sparser by grouping connections along map direction."
msgstr "チャネルのグループ数。これにより、マップ方向に沿って接続をグループ化することにより、チャネル間の接続がよりスパースになります。"

#: nnabla.parametric_functions.deconvolution:34 of
msgid ""
"N-D array. See :obj:`~nnabla.functions.deconvolution` for the output "
"shape."
msgstr "N-D 配列。出力形状については、 :obj:`~nnabla.functions.deconvolution` を参照してください。"

#: nnabla.parametric_functions.deconvolution:38 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"deconv\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"deconv\"`` に登録されます。"

#: nnabla.parametric_functions.deconvolution:40 of
msgid ""
"W (``need_grad=True``) : Filter weights. (shape: ``(inmaps, outmaps // "
"group, *kernel)``)"
msgstr ""
"W (``need_grad=True``) : フィルターの重み (形状: ``(inmaps, outmaps // group, "
"*kernel)``)"

#: nnabla.parametric_functions.deconvolution:50 of
msgid ""
"with parametric_scope(name):\n"
"    output = deconvolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.depthwise_deconvolution:1 of
msgid ""
"Depthwise deconvolution computes the transposed depthwise convolution for"
" one-dimensional and two-dimensional input data."
msgstr ""
"Depthwise deconvolution は、1 次元および 2 次元の入力データに対して depthwise convolusion "
"の転置を計算します。"

#: nnabla.parametric_functions.depthwise_deconvolution:14 of
msgid "Number of input feature maps per output feature map."
msgstr "出力フィーチャマップごとの入力フィーチャマップの数。"

#: nnabla.parametric_functions.depthwise_deconvolution:29 of
msgid ""
"N-D array. See :obj:`~nnabla.functions.depthwise_deconvolution` for the "
"output shape."
msgstr ""
"N-D 配列。出力形状については、 :obj:`~nnabla.functions.depthwise_deconvolution` "
"を参照してください。"

#: nnabla.parametric_functions.depthwise_deconvolution:33 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"depthwise_deconv\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"depthwise_deconv\"`` に登録されます。"

#: nnabla.parametric_functions.depthwise_deconvolution:35 of
msgid "W (``need_grad=True``) : Filter weights. (shape: ``(inmaps,) + kernel``)"
msgstr "W (``need_grad=True``) : フィルターの重み (形状: ``(inmaps,) + kernel``)"

#: nnabla.parametric_functions.depthwise_deconvolution:36 of
msgid "b (``need_grad=True``) : Bias vector. (shape: ``(inmaps / divisor,)``)"
msgstr "b (``need_grad=True``) : バイアスベクター (形状: ``(inmaps / divisor,)``)"

#: nnabla.parametric_functions.depthwise_deconvolution:45 of
msgid ""
"with parametric_scope(name):\n"
"    output = depthwise_deconvolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.batch_normalization:1 of
msgid "Batch normalization layer."
msgstr "Batch normalization 層"

#: nnabla.parametric_functions.batch_normalization:3 of
msgid ""
"\\begin{array}{lcl} \\mu &=& \\frac{1}{M} \\sum x_i\\\\ \\sigma^2 &=& "
"\\frac{1}{M} \\sum \\left(x_i - \\mu\\right)^2\\\\ \\hat{x}_i &=& "
"\\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon }}\\\\ y_i &= & "
"\\hat{x}_i \\gamma + \\beta. \\end{array}"
msgstr ""

#: nnabla.parametric_functions.batch_normalization:12 of
msgid ""
"where :math:`x_i, y_i` are the inputs. In testing, the mean and variance "
"computed by moving average calculated during training are used."
msgstr ""
"ここでは、 :math:`x_i, y_i` は入力とします。テスト時には、学習中に計算された移動平均を使って算出された平均 (mean) と分散"
" (variance) が使われます。"

#: nnabla.parametric_functions.batch_normalization:15
#: nnabla.parametric_functions.fused_batch_normalization:4
#: nnabla.parametric_functions.mean_subtraction:20
#: nnabla.parametric_functions.sync_batch_normalization:17 of
msgid "N-D array of input."
msgstr "入力の N-D 配列。"

#: nnabla.parametric_functions.batch_normalization:17
#: nnabla.parametric_functions.fused_batch_normalization:9
#: nnabla.parametric_functions.sync_batch_normalization:23 of
msgid ""
"Mean and variance for each element in ``axes`` are calculated using "
"elements on the rest axes. For example, if an input is 4 dimensions, and "
"``axes`` is ``[1]``,  batch mean is calculated as ``np.mean(inp.d, "
"axis=(0, 2, 3), keepdims=True)`` (using numpy expression as an example)."
msgstr ""
"``axes`` の各要素の平均と分散は、残りの axes の要素を使用して計算されます。例えば、入力が 4 次元で、 ``axes`` が "
"``[1]`` の場合、バッチ平均は ``np.mean(inp.d, axis=(0, 2, 3), keepdims=True)`` "
"として計算されます ( numpy 式を例として使用 )。"

#: nnabla.parametric_functions.batch_normalization:23
#: nnabla.parametric_functions.fused_batch_normalization:15
#: nnabla.parametric_functions.sync_batch_normalization:29 of
msgid "Decay rate of running mean and variance."
msgstr "移動平均と分散の減衰率。"

#: nnabla.parametric_functions.batch_normalization:25
#: nnabla.parametric_functions.fused_batch_normalization:17
#: nnabla.parametric_functions.group_normalization:34
#: nnabla.parametric_functions.instance_normalization:27
#: nnabla.parametric_functions.layer_normalization:28
#: nnabla.parametric_functions.sync_batch_normalization:31 of
msgid "Tiny value to avoid zero division by std."
msgstr "std によるゼロ除算を回避する小さな値。"

#: nnabla.parametric_functions.batch_normalization:27
#: nnabla.parametric_functions.fused_batch_normalization:19
#: nnabla.parametric_functions.sync_batch_normalization:33 of
msgid "Use mini-batch statistics rather than running ones."
msgstr "移動統計量ではなく、ミニバッチ統計量を使用します。"

#: nnabla.parametric_functions.batch_normalization:29
#: nnabla.parametric_functions.fused_batch_normalization:23
#: nnabla.parametric_functions.sync_batch_normalization:35 of
msgid "Output batch mean and variance."
msgstr "バッチ平均と分散を出力します。"

#: nnabla.parametric_functions.batch_normalization:31
#: nnabla.parametric_functions.fused_batch_normalization:25
#: nnabla.parametric_functions.group_normalization:38
#: nnabla.parametric_functions.layer_normalization:32
#: nnabla.parametric_functions.sync_batch_normalization:37 of
msgid "When set to `True`, the beta and gamma will not be updated."
msgstr "`True` に設定すると、beta と gamma は更新されません。"

#: nnabla.parametric_functions.batch_normalization:33
#: nnabla.parametric_functions.sync_batch_normalization:39 of
msgid ""
"Parameter initializers can be set with a dict. A key of the dict must be "
"``'beta'``, ``'gamma'``, ``'mean'`` or ``'var'``. A value of the dict "
"must be an :obj:`~nnabla.initializer.Initializer` or a "
":obj:`numpy.ndarray`. E.g. ``{'beta': ConstantInitializer(0), 'gamma': "
"np.ones(gamma_shape) * 2}``."
msgstr ""
"パラメータイニシャライザーは dict で設定できます。dict のキーは ``'beta'`` 、 ``'gamma'`` 、 "
"``'mean'`` または ``'var'`` である必要があります。dict の値は、 "
":obj:`~nnabla.initializer.Initializer` または numpy.ndarray "
":obj:`numpy.ndarray` である必要があります。例 ``{'beta': ConstantInitializer(0), "
"'gamma': np.ones(gamma_shape) * 2}`` 。"

#: nnabla.parametric_functions.batch_normalization:39
#: nnabla.parametric_functions.fused_batch_normalization:27
#: nnabla.parametric_functions.group_normalization:46
#: nnabla.parametric_functions.instance_normalization:39
#: nnabla.parametric_functions.layer_normalization:40
#: nnabla.parametric_functions.sync_batch_normalization:45 of
msgid "If `True`, the scale term is omitted."
msgstr "`True` の場合、スケール項は省略されます。"

#: nnabla.parametric_functions.batch_normalization:41
#: nnabla.parametric_functions.fused_batch_normalization:29
#: nnabla.parametric_functions.group_normalization:48
#: nnabla.parametric_functions.instance_normalization:41
#: nnabla.parametric_functions.layer_normalization:42
#: nnabla.parametric_functions.sync_batch_normalization:47 of
msgid "If `True`, the bias term is omitted."
msgstr "`True` の場合、バイアス項は省略されます。"

#: nnabla.initializer.OrthogonalInitializer:23
#: nnabla.initializer.calc_normal_std_glorot:35
#: nnabla.initializer.calc_normal_std_he_backward:30
#: nnabla.initializer.calc_normal_std_he_forward:30
#: nnabla.initializer.calc_uniform_lim_glorot:36
#: nnabla.parametric_functions.batch_normalization:48
#: nnabla.parametric_functions.binary_connect_affine:17
#: nnabla.parametric_functions.binary_connect_convolution:17
#: nnabla.parametric_functions.binary_weight_affine:15
#: nnabla.parametric_functions.binary_weight_convolution:17
#: nnabla.parametric_functions.cpd3_convolution:26
#: nnabla.parametric_functions.group_normalization:22
#: nnabla.parametric_functions.gru:15
#: nnabla.parametric_functions.instance_normalization:17
#: nnabla.parametric_functions.layer_normalization:20
#: nnabla.parametric_functions.lstm:17 nnabla.parametric_functions.lstm_cell:14
#: nnabla.parametric_functions.min_max_quantize:109
#: nnabla.parametric_functions.multi_head_attention:8
#: nnabla.parametric_functions.rnn:13
#: nnabla.parametric_functions.spectral_norm:10
#: nnabla.parametric_functions.sync_batch_normalization:54
#: nnabla.parametric_functions.transformer:7
#: nnabla.parametric_functions.weight_normalization:14 of
msgid "参照"
msgstr ""

#: nnabla.parametric_functions.batch_normalization:49 of
msgid ""
"Ioffe and Szegedy, Batch Normalization: Accelerating Deep Network "
"Training by Reducing Internal Covariate Shift. "
"https://arxiv.org/abs/1502.03167"
msgstr ""

#: nnabla.parametric_functions.batch_normalization:51
#: nnabla.parametric_functions.sync_batch_normalization:59 of
msgid ""
"The shape of parameters has the same number of dimensions with the input "
"data, and the shapes in ``axes`` has the same dimensions with the input, "
"while the rest has ``1``. If an input is 4-dim and ``axes=[1]``, the "
"parameter shape will be ``param_shape  = np.mean(inp.d, axis=(0, 2, 3), "
"keepdims=True).shape`` (using numpy expression as an example)."
msgstr ""
"パラメータの形状は入力データと同じ次元数で、各軸のサイズは、 ``axes`` に指定された軸については入力と同じ大きさであり、残りは ``1``"
" となります。例えば、入力が 4 次元で、 ``axes=[1]`` である場合、パラメータ形状は、 ``param_shape = "
"np.mean(inp.d, axis=(0, 2, 3), keepdims=True).shape`` (例として、numpy 表記を使用) "
"となります。"

#: nnabla.parametric_functions.batch_normalization:59
#: nnabla.parametric_functions.fused_batch_normalization:36
#: nnabla.parametric_functions.sync_batch_normalization:67 of
msgid "The following variables are registered in a parameter scope ``\"bn\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"bn\"`` に登録されます。"

#: nnabla.parametric_functions.batch_normalization:61
#: nnabla.parametric_functions.fused_batch_normalization:38
#: nnabla.parametric_functions.group_normalization:59
#: nnabla.parametric_functions.instance_normalization:51
#: nnabla.parametric_functions.layer_normalization:53
#: nnabla.parametric_functions.sync_batch_normalization:69 of
msgid ""
"beta (``need_grad=True``) : Trainable bias :math:`\\beta`. (shape: ``<see"
" above>``)"
msgstr "beta (``need_grad=True``) : 学習可能な :math:`\\beta`. (形状: ``<上記参照>``)"

#: nnabla.parametric_functions.batch_normalization:62
#: nnabla.parametric_functions.fused_batch_normalization:39
#: nnabla.parametric_functions.group_normalization:60
#: nnabla.parametric_functions.instance_normalization:52
#: nnabla.parametric_functions.layer_normalization:54
#: nnabla.parametric_functions.sync_batch_normalization:70 of
msgid ""
"gamma (``need_grad=True``) : Trainable scaling factor :math:`\\gamma`. "
"(shape: ``<see above>``)"
msgstr ""
"gamma (``need_grad=True``) : 学習可能なスケーリングファクター :math:`\\gamma`. (形状: "
"``<上記参照>``)"

#: nnabla.parametric_functions.batch_normalization:63
#: nnabla.parametric_functions.fused_batch_normalization:40
#: nnabla.parametric_functions.sync_batch_normalization:71 of
msgid ""
"mean (``need_grad=False``) : Moving average of batch mean. (shape: ``<see"
" above>``)"
msgstr "mean (``need_grad=False``) : バッチ平均の移動平均 (形状: ``<上記参照>``)"

#: nnabla.parametric_functions.batch_normalization:64
#: nnabla.parametric_functions.fused_batch_normalization:41
#: nnabla.parametric_functions.sync_batch_normalization:72 of
msgid ""
"var (``need_grad=False``) : Moving average of batch variance. (shape: "
"``<see above>``)"
msgstr "var (``need_grad=False``) : バッチ分散の移動平均 (形状: ``<上記参照>``)"

#: nnabla.parametric_functions.batch_normalization:73 of
msgid ""
"with parametric_scope(name):\n"
"    output = batch_normalization(<args>)"
msgstr ""

#: nnabla.parametric_functions.fused_batch_normalization:1 of
msgid ""
"Batch normalization layer fused with the following add2 operation of a "
"residual input and an nonlinear activation."
msgstr ""
"Batch Normalizationの直後に続く残差入力とのadd2演算と非線形活性化演算の実行を含んだ Batch normalization"
" 層。"

#: nnabla.parametric_functions.fused_batch_normalization:6 of
msgid ""
"A residual input. By specifying None, the activation function will follow"
" immediately after BN operation."
msgstr "残差の入力。 None を指定すると、BN 操作の直後に activation 関数が実行されます。"

#: nnabla.parametric_functions.fused_batch_normalization:21 of
msgid "Activation function. The default is 'relu'."
msgstr "activation 関数。デフォルトは 'relu' です。"

#: nnabla.parametric_functions.fused_batch_normalization:50 of
msgid ""
"with parametric_scope(name):\n"
"    output = fused_batch_normalization(<args>)"
msgstr ""

#: nnabla.parametric_functions.sync_batch_normalization:1 of
msgid "Synchronized batch normalization layer."
msgstr "Synchronized batch normalization 層"

#: nnabla.parametric_functions.sync_batch_normalization:3 of
msgid ""
"For some tasks (e.g., semantic segmentation), batch size will be too "
"small and BatchNormalization layer might not work well. "
"SyncBatchNorlization layer solves these problems by synchronizing batch "
"stats (mean and var) between multiple processes."
msgstr ""
"タスク (例: semantic segmentation ) によっては、バッチサイズが小さすぎて、BatchNormalization "
"層がうまく動かない場合があります。SyncBatchNorlization "
"層は、バッチ統計情報（平均と分散）を複数のプロセス間で同期することでこのような問題を解決します。"

#: nnabla.parametric_functions.sync_batch_normalization:6 of
msgid ""
"\\begin{array}{lcl} \\mu &=& \\frac{1}{M} \\sum x_i\\\\ \\sigma^2 &=& "
"\\frac{1}{M} \\left(\\sum x_i - \\mu\\right)^2\\\\ \\hat{x}_i &=& "
"\\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon }}\\\\ y_i &= & "
"\\hat{x}_i \\gamma + \\beta. \\end{array}"
msgstr ""

#: nnabla.parametric_functions.sync_batch_normalization:15 of
msgid "where :math:`x_i, y_i` are the inputs."
msgstr "ここでは、 :math:`x_i, y_i` は入力とします。"

#: nnabla.parametric_functions.sync_batch_normalization:19 of
msgid "The communicator"
msgstr "communicator"

#: nnabla.parametric_functions.sync_batch_normalization:21 of
msgid "The name of the communicator group"
msgstr "communicator グループの名前"

#: nnabla.parametric_functions.sync_batch_normalization:55 of
msgid ""
"Ioffe and Szegedy, Batch Normalization: Accelerating Deep Network "
"Training by Reducing Internal Covariate Shift, "
"https://arxiv.org/abs/1502.03167"
msgstr ""

#: nnabla.parametric_functions.sync_batch_normalization:56 of
msgid ""
"Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang, Xiaogang Wang, "
"Ambrish Tyagi, Amit Agrawal, Context Encoding for Semantic Segmentation, "
"https://arxiv.org/abs/1803.08904"
msgstr ""

#: nnabla.parametric_functions.sync_batch_normalization:57 of
msgid ""
"Implementing Synchronized Multi-GPU Batch Normalization "
"https://hangzhang.org/PyTorch-Encoding/notes/syncbn.html"
msgstr ""

#: nnabla.parametric_functions.sync_batch_normalization:81 of
msgid ""
"with parametric_scope(name):\n"
"    output = sync_batch_normalization(<args>)"
msgstr ""

#: nnabla.parametric_functions.mean_subtraction:1 of
msgid "Mean subtraction layer."
msgstr "Mean subtraction 層"

#: nnabla.parametric_functions.mean_subtraction:3 of
msgid ""
"It subtracts the mean of the elements of the input array, and normalizes "
"it to :math:`0`. Preprocessing arrays with this function has the effect "
"of improving accuracy in various tasks such as image classification."
msgstr ""
"入力配列の要素の平均値を減算し、平均を :math:`0` "
"に正規化します。この関数を使った配列の前処理は、画像分類などの様々なタスクにおいて精度を向上させる効果があります。"

#: nnabla.parametric_functions.mean_subtraction:7 of
msgid "At training time, this function is defined as"
msgstr "学習時は、この関数は以下のように定義されます。"

#: nnabla.parametric_functions.mean_subtraction:9 of
msgid ""
"\\begin{array}{lcl} \\mu &=& \\frac{1}{M} \\sum x_i \\\\ y_i &=& x_i - "
"\\mu \\end{array}"
msgstr ""

#: nnabla.parametric_functions.mean_subtraction:16 of
msgid ""
"At testing time, the mean values used are those that were computed during"
" training by moving average."
msgstr "テスト時には、学習中に計算した移動平均の値を上式の平均として利用します。"

#: nnabla.parametric_functions.mean_subtraction:18 of
msgid ""
"The backward performs an approximated differentiation that takes into "
"account only the latest mini-batch."
msgstr "backward は、最新のミニバッチのみを考慮した近似微分を行います。"

#: nnabla.parametric_functions.mean_subtraction:22 of
msgid ""
"Base axis of Mean Subtraction operation. Dimensions up to base_axis is "
"treated as sample dimension."
msgstr "Mean Subtraction 演算のベース軸。base_axis までの次元はサンプル次元として扱われます。"

#: nnabla.parametric_functions.mean_subtraction:24 of
msgid "When set to `True`, the running mean will not be updated."
msgstr "`True` に設定すると、移動平均は更新されません。"

#: nnabla.parametric_functions.mean_subtraction:26 of
msgid "dummy parameter. This argument dose not affect anything."
msgstr "ダミーパラメータ。この引数は何にも影響しません。"

#: nnabla.parametric_functions.mean_subtraction:33 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"mean_subtraction\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"mean_subtraction\"`` に登録されます。"

#: nnabla.parametric_functions.mean_subtraction:35 of
msgid ""
"mean (``need_grad=False``) : Moving average. (shape: "
"``inp.shape[base_axis:]``)"
msgstr "mean (``need_grad=False``) : 移動平均 (形状: ``inp.shape[base_axis:]``)"

#: nnabla.parametric_functions.mean_subtraction:36 of
msgid ""
"t (``need_grad=False``) : Minibatch counter used in forward pass. (shape:"
" ``(1,)``)"
msgstr "t (``need_grad=False``) : forward パスを使ったミニバッチカウンター (形状: ``(1,)``)"

#: nnabla.parametric_functions.mean_subtraction:45 of
msgid ""
"with parametric_scope(name):\n"
"    output = mean_subtraction(<args>)"
msgstr ""

#: nnabla.parametric_functions.layer_normalization:1 of
msgid "Applies Layer Normalization over an input variable, which is defined as:"
msgstr "入力変数に Layer Normalization を適用します。Layer Normalizationは以下のように定義されます。"

#: nnabla.parametric_functions.layer_normalization:3 of
msgid ""
"\\begin{eqnarray}   \\mu^l &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^l \\\\   "
"\\sigma^l &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^l - "
"\\mu^l\\right)^2} \\\\   y &=& \\frac{x - \\mu^l}{\\sigma^l + \\epsilon} "
"\\gamma + \\beta \\end{eqnarray}"
msgstr ""

#: nnabla.parametric_functions.layer_normalization:10 of
msgid ""
"where :math:`x` and :math:`y` are input and output variable, "
":math:`\\mu^l` and :math:`\\sigma^l` are the mean and std of each layer "
"along batch axis, and :math:`\\alpha` and :math:`\\beta` are trainable "
"parameter."
msgstr ""
"ここでは、 :math:`x` と :math:`y` は入力と出力変数、 :math:`\\mu^l` と :math:`\\sigma^l` "
"はバッチ軸に沿った層ごとの平均値と標準値、 :math:`\\alpha` と :math:`\\beta` は学習可能なパラメータです。"

#: nnabla.parametric_functions.layer_normalization:15 of
msgid ""
"Unlike other normalizations, which applies scalar scale and bias for each"
" entire channel/plane, Layer Normalization applies per-element scale and "
"bias."
msgstr ""
"全てのチャンネルにスカラースケールやバイアスを適用する他の normalization とは異なり、Layer Normalization "
"は要素ごとにスケールやバイアスを適用します。"

#: nnabla.parametric_functions.layer_normalization:21 of
msgid ""
"`Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton, Layer Normalization."
" <https://arxiv.org/abs/1607.06450>`_"
msgstr ""

#: nnabla.parametric_functions.group_normalization:26
#: nnabla.parametric_functions.instance_normalization:21
#: nnabla.parametric_functions.layer_normalization:24 of
msgid "An input variable."
msgstr "入力変数。"

#: nnabla.parametric_functions.group_normalization:32
#: nnabla.parametric_functions.layer_normalization:26 of
msgid "Axes mean and variance are taken."
msgstr "平均と分散を計算する軸。"

#: nnabla.parametric_functions.layer_normalization:30 of
msgid "It `True`, calculated mean and variance are also returned."
msgstr "`True` の場合、計算された平均と分散も返します。"

#: nnabla.parametric_functions.group_normalization:40
#: nnabla.parametric_functions.instance_normalization:33
#: nnabla.parametric_functions.layer_normalization:34 of
msgid ""
"Parameter initializers can be set with a dict. A key of the dict must be "
"``'gamma'``, ``'beta'``. A value of the dict must be an "
":obj:`~nnabla.initializer.Initializer` or a :obj:`numpy.ndarray`. E.g. "
"``{'gamma': np.ones(...) * 2, 'beta': ConstantInitializer(0)}``."
msgstr ""
"パラメータイニシャライザーは dict で設定できます。 dictのキーは ``'gamma'``、``'beta'`` "
"である必要があります。dict の値は、 :obj:`~nnabla.initializer.Initializer` または "
":obj:`numpy.ndarray` である必要があります。例 ``{'gamma': np.ones(...) * 2, 'beta': "
"ConstantInitializer(0)}`` 。"

#: nnabla.parametric_functions.layer_normalization:45 of
msgid ""
"Normalized output variable. * :obj:`~nnabla.Variable`: Mean (if "
"``output_stat=True`). * :obj:`~nnabla.Variable`: Std (if "
"``output_stat=True`)"
msgstr ""
"正規化された出力変数。 * :obj:`~nnabla.Variable`: 平均値 ( ``output_stat=True`` の場合). *"
" :obj:`~nnabla.Variable`: Std ( ``output_stat=True`` の場合)"

#: nnabla.parametric_functions.group_normalization:54
#: nnabla.parametric_functions.layer_normalization:48 of
msgid "* :obj:`~nnabla.Variable`"
msgstr ""

#: nnabla.parametric_functions.group_normalization:54
#: nnabla.parametric_functions.layer_normalization:48 of
msgid ":obj:`~nnabla.Variable`"
msgstr ""

#: nnabla.parametric_functions.layer_normalization:51 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"layer_normalization\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"layer_normalization\"`` に登録されます。"

#: nnabla.parametric_functions.layer_normalization:63 of
msgid ""
"with parametric_scope(name):\n"
"    output = layer_normalization(<args>)"
msgstr ""

#: nnabla.parametric_functions.instance_normalization:1 of
msgid ""
"Applies Instance Normalization over an input variable, which is defined "
"as:"
msgstr "入力変数に Instance Normalization を適用します。Instance Normalizaionは以下のように定義されます。"

#: nnabla.parametric_functions.instance_normalization:3 of
msgid ""
"\\begin{eqnarray}   \\mu^i &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^i \\\\   "
"\\sigma^i &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^i - "
"\\mu^i\\right)^2} \\\\   y &=& \\frac{x - \\mu^i}{\\sigma^ + \\epsilon} "
"\\gamma + \\beta \\end{eqnarray}"
msgstr ""

#: nnabla.parametric_functions.instance_normalization:10 of
msgid ""
"where :math:`x` and :math:`y` are input and output variable, "
":math:`\\mu^i` and :math:`\\sigma^i` are the mean and std of each "
"instance which is separately calculated for each batch and channel, and "
":math:`\\gamma` and :math:`\\beta` are adaptive gains and biases."
msgstr ""
"ここでは、 :math:`x` と :math:`y` は入力と出力変数、 :math:`\\mu^i` と :math:`\\sigma^i` "
"はバッチとチャネルごとに個別に計算される平均値と標準偏差、 :math:`\\gamma` と :math:`\\beta` "
"は適用ゲインとバイアスとします。"

#: nnabla.parametric_functions.instance_normalization:14 of
msgid ""
"If the input shape is [B, C, H, W] (= channel_axis=1, batch_axis=0), the "
"shape of calculated mean and std are [B, C, 1, 1]"
msgstr ""
"例えば、入力の形状が [ B, C, H, W ] ( = channel_axis=1, batch_axis=0 ) の場合、 "
"計算される平均値と標準値の形状は [ B, C, 1, 1 ] です。"

#: nnabla.parametric_functions.instance_normalization:18 of
msgid ""
"`Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky, Instance "
"Normalization: The Missing Ingredient for Fast Stylization. "
"<https://arxiv.org/abs/1607.08022>`_"
msgstr ""

#: nnabla.parametric_functions.instance_normalization:23 of
msgid "Channel axes."
msgstr "チャンネル軸。"

#: nnabla.parametric_functions.instance_normalization:25 of
msgid "Batch axes."
msgstr "バッチ軸。"

#: nnabla.parametric_functions.instance_normalization:29 of
msgid "It `True`, the batch statistics of mean and variance."
msgstr "`True` の場合、バッチの平均と分散を出力します。"

#: nnabla.parametric_functions.instance_normalization:31 of
msgid "If `True`, the beta and gamma will not be updated."
msgstr "`True` の場合、beta と gamma は更新されません。"

#: nnabla.parametric_functions.instance_normalization:43 of
msgid ""
"* :obj:`~nnabla.Variable`: Normalized output variable. * "
":obj:`~nnabla.Variable`: Mean (if ``output_stat=True`) * "
":obj:`~nnabla.Variable`: Std (if ``output_stat=True`)"
msgstr ""

#: nnabla.parametric_functions.instance_normalization:44 of
msgid ":obj:`~nnabla.Variable`: Normalized output variable."
msgstr ":obj:`~nnabla.Variable`: 正規化された出力変数。"

#: nnabla.parametric_functions.instance_normalization:45 of
msgid ":obj:`~nnabla.Variable`: Mean (if ``output_stat=True`)"
msgstr ":obj:`~nnabla.Variable`: 平均値(``output_stat=True`` の場合)"

#: nnabla.parametric_functions.instance_normalization:46 of
msgid ":obj:`~nnabla.Variable`: Std (if ``output_stat=True`)"
msgstr ":obj:`~nnabla.Variable`: Std 標準偏差(``output_stat=True`` の場合)"

#: nnabla.parametric_functions.instance_normalization:49 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"instance_normalization\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"instance_normalization\"`` に登録されます。"

#: nnabla.parametric_functions.instance_normalization:61 of
msgid ""
"with parametric_scope(name):\n"
"    output = instance_normalization(<args>)"
msgstr ""

#: nnabla.parametric_functions.group_normalization:1 of
msgid "Applies Group Normalization over an input tensor, which is defined as:"
msgstr "入力変数に Group Normalization を適用します。Group Normalizationは以下のように定義されます。"

#: nnabla.parametric_functions.group_normalization:3 of
msgid ""
"\\begin{eqnarray}   \\mu^g &=& \\frac{1}{H} \\sum_{i=1}^{H} x_i^g \\\\   "
"\\sigma^g &=& \\sqrt{\\frac{1}{H} \\sum_{i=1}^{H} \\left(x_i^g - "
"\\mu^g\\right)^2} \\\\   y &=& \\frac{x - \\mu^g}{\\sigma^g + \\epsilon} "
"\\gamma + \\beta \\end{eqnarray}"
msgstr ""

#: nnabla.parametric_functions.group_normalization:10 of
msgid ""
"where :math:`x` and :math:`y` are input and output variable, "
":math:`\\mu^g` and :math:`\\sigma^g` are the mean and std of each group "
"which contains `num_channels / num_groups` channels, and :math:`\\gamma` "
"and :math:`\\beta` are adaptive gains and biases."
msgstr ""
"ここでは、 :math:`x` と :math:`y` は入力と出力変数、 :math:`\\mu^g` と :math:`\\sigma^g` "
"は グループごとの平均と標準偏差で、各グループのチェンネル数は `num_channels / num_groups` です。 "
":math:`\\gamma` と :math:`\\beta` は適応ゲインとバイアスです。"

#: nnabla.parametric_functions.group_normalization:14 of
msgid ""
"The input channels, specified by :attr:`channel_axis`, are separeted into"
" :attr:`num_groups` groups, and the mean and std are calculated over the "
"each group. For example, if the input shape is [B, C, H, W] (= "
"channel_axis=1, batch_axis=0), an input variable is once reshaped to [B, "
"num_groups, C / num_groups, H, W] and standardize by its mean and std "
"whose shapes are [B, num_groups, C / num_groups, 1, 1]. Before returning,"
" an output variable is reshaped again to the original input shape (= [B, "
"C, H, W] in the case above)."
msgstr ""
":attr:`channel_axis` によって指定された入力チャネルは、 :attr:`num_groups` "
"グループに分けられ、グループごとに平均と標準偏差が計算されます。例えば、入力の形状が [ B, C, H, W ] (= "
"channel_axis=1, batch_axis=0) の場合、入力変数は、まず [ B, num_groups, C / "
"num_groups, H, W ] に変形され、形状が [ B, num_groups, C / num_groups, 1, 1 ] "
"の平均値と標準値によって標準化されます。出力変数は元々の入力の形状 ( 上述の例の場合は [ B, C, H, W "
"])に再度変形されてから出力されます。"

#: nnabla.parametric_functions.group_normalization:23 of
msgid ""
"`Yuxin Wu, Kaiming He, Group Normalization. "
"<https://arxiv.org/abs/1803.08494>`_"
msgstr ""

#: nnabla.parametric_functions.group_normalization:28 of
msgid ""
"A number of groups. The channel dim of 'x' must be integer multiple of "
"`num_groups`."
msgstr "グループ数。 'x' のチャンネル dim は `num_groups` の整数倍である必要があります。"

#: nnabla.parametric_functions.group_normalization:30 of
msgid "Channel axis."
msgstr "チャンネル軸。"

#: nnabla.parametric_functions.group_normalization:36 of
msgid "It true, the batch statistics of mean and variance."
msgstr "True の場合、平均と分散のバッチの統計。"

#: nnabla.parametric_functions.group_normalization:51 of
msgid ""
"Normalized output variable. * :obj:`~nnabla.Variable`: Mean (if "
"``output_stat=True`) * :obj:`~nnabla.Variable`: Std (if "
"``output_stat=True`)"
msgstr ""
"正規化された出力変数。 * :obj:`~nnabla.Variable`: 平均 (``output_stat=True`` の場合) * "
":obj:`~nnabla.Variable`: Std (``output_stat=True`` の場合)"

#: nnabla.parametric_functions.group_normalization:57 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"group_normalization\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"group_normalization\"`` に登録されます。"

#: nnabla.parametric_functions.group_normalization:69 of
msgid ""
"with parametric_scope(name):\n"
"    output = group_normalization(<args>)"
msgstr ""

#: nnabla.parametric_functions.rnn:1 of
msgid "N-Step RNN (recurrent neural networks)."
msgstr "N-Step RNN (回帰型ニューラルネットワーク)。"

#: nnabla.parametric_functions.rnn:3 of
msgid ""
"N-Step RNN function implements Elman RNN with nonlineraity to input "
"sequence. N-Step RNN function is defined as following:"
msgstr ""
"N-Step RNN 関数は、入力シーケンスに対して非線形層を含んだElman RNN を実装したものです。N-Step RNN "
"関数は以下のように定義されます。"

#: nnabla.parametric_functions.rnn:6 of
msgid "h_t = \\tanh(w_{ih}x_t+b_{ih}+w_{hh}h_{(t-1)})."
msgstr ""

#: nnabla.parametric_functions.gru:11 nnabla.parametric_functions.lstm:13
#: nnabla.parametric_functions.rnn:9 of
msgid ""
"We use the following notations to describe the inputs and outputs below. "
":math:`T`: sequcne length, :math:`B`: batch size, :math:`I`: input size, "
":math:`L`: number of layers, :math:`D`: number of directions, can be "
"either 1 or 2, :math:`H`: hidden size."
msgstr ""
"これ以降の入力や出力の説明には、以下の表記を利用します。 :math:`T`: シーケンスの長さ、 :math:`B`: バッチサイズ、 "
":math:`I`: 入力サイズ、 :math:`L`: 層数、 :math:`D`: 方向数（１もしくは２）、 :math:`H`: "
"隠れサイズ。"

#: nnabla.parametric_functions.rnn:14 of
msgid "Jeffrey L. Elman. \"Finding Structure in Time.\" Cognitive Science. 1990."
msgstr ""

#: nnabla.parametric_functions.gru:19 nnabla.parametric_functions.lstm:21
#: nnabla.parametric_functions.rnn:17 of
msgid "Input N-D array with shape :math:`(T, B, I)`."
msgstr ":math:`(T, B, I)` の形状の入力 N-D 配列。"

#: nnabla.parametric_functions.gru:21 nnabla.parametric_functions.lstm:23
#: nnabla.parametric_functions.rnn:19 of
msgid "Input N-D array with shape :math:`(L, D, B, H)`."
msgstr ":math:`(L, D, B, H)` の形状の入力 N-D 配列。"

#: nnabla.parametric_functions.rnn:21 of
msgid "Initializer for weight at the first layer. Shape is :math:`(D, H, I + H)`."
msgstr "最初の層での重みのイニシャライザー。 形状は :math:`(D, H, I + H)` 。"

#: nnabla.parametric_functions.rnn:23 of
msgid ""
"Initializer for weights at the second layer and up. Shape is :math:`(L-1,"
" D, H, D*H + H)`."
msgstr "二番目、それ以上の層での重みのイニシャライザー。 形状は :math:`(L-1, D, H, D*H + H)` 。"

#: nnabla.parametric_functions.rnn:25 of
msgid "Initializer for bias. Shape is :math:`(L, D, H)`."
msgstr "バイアスのイニシャライザー。形状は :math:`(L, D, H)` 。"

#: nnabla.parametric_functions.gru:29 nnabla.parametric_functions.lstm:33
#: nnabla.parametric_functions.rnn:27 of
msgid ""
"Number of layers in the network. If set to 1, only the weights for the "
"first layer will be invoked. Default is 1."
msgstr "ネットワーク内のレイヤー数。 1 に設定すると、最初のレイヤーの重みのみが呼び出されます。デフォルトは 1 です。"

#: nnabla.parametric_functions.rnn:29 of
msgid ""
"Type of nonlinearity applied to input sequcne. Must be either tanh or "
"relu. Default is tanh."
msgstr "入力シーケンスに適用される非線形演算の種類。 tanh または relu である必要があります。デフォルトは tanh です。"

#: nnabla.parametric_functions.gru:31 nnabla.parametric_functions.lstm:35
#: nnabla.parametric_functions.rnn:31 of
msgid "Dropout ratio applied to parameters. Default is 0.0."
msgstr "パラメータに適用されるドロップアウトの割合。デフォルトは 0.0 です。"

#: nnabla.parametric_functions.gru:33 nnabla.parametric_functions.lstm:37
#: nnabla.parametric_functions.rnn:33 of
msgid ""
"If True, bidirectional computation will be performed in each layer. "
"Default is False."
msgstr "Trueの場合、各層で双方向計算が実行されます。デフォルトは False です。"

#: nnabla.parametric_functions.gru:35 nnabla.parametric_functions.lstm:39
#: nnabla.parametric_functions.rnn:35 of
msgid "Backpropagation will be performed only when it is true. Default is True."
msgstr "True の場合のみ、Backpropagation が実行されます。デフォルトは True です。"

#: nnabla.parametric_functions.gru:40 nnabla.parametric_functions.rnn:40 of
msgid ""
"Output :math:`y` with shape :math:`(T, B, D * H)` ~nnabla.Variable: "
"Output :math:`h_n` with shape :math:`(L, D, B, H)`"
msgstr ""
":math:`(T, B, D * H)` の形状の出力 :math:`y` \n"
" ~nnabla.Variable: :math:`(L, D, B, H)` の形状の出力 :math:`h_n`"

#: nnabla.parametric_functions.gru:45 nnabla.parametric_functions.lstm:52
#: nnabla.parametric_functions.rnn:45
#: nnabla.parametric_functions.spectral_norm:30
#: nnabla.parametric_functions.weight_normalization:30 of
msgid "サンプル"
msgstr ""

#: nnabla.parametric_functions.rnn:46 of
msgid ""
"x = nn.Variable((seq_len, batch_size, input_size))\n"
"h = nn.Variable((num_layers, num_directions, batch_size, hidden_size))\n"
"y, hn = PF.rnn(x, h)"
msgstr ""

#: nnabla.parametric_functions.rnn:53 of
msgid "The following variables are registered in a parameter scope ``\"rnn\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"rnn\"`` に登録されます。"

#: nnabla.parametric_functions.rnn:55 of
msgid ""
"weight_l0 (``need_grad=True``) : Filter weights at 0-th layer. (shape: "
"``(D, H, I + H)``)"
msgstr "weight_l0 (``need_grad=True``) : 第０層でのフィルターの重み (形状: ``(D, H, I + H)``)"

#: nnabla.parametric_functions.rnn:56 of
msgid ""
"weight (``need_grad=True``) : Filter weights at 1-st layer and above. "
"(shape: ``(L-1, D, H, DH + H)``)"
msgstr ""
"weight (``need_grad=True``) : 第１層以上でのフィルターの重み (形状: ``(L-1, D, H, DH + "
"H)``)"

#: nnabla.parametric_functions.rnn:57 of
msgid "bias (``need_grad=True``) : Biases. (shape: ``(L, D, H)``)"
msgstr "bias (``need_grad=True``) : バイアス。 (形状: ``(L, D, H)``)"

#: nnabla.parametric_functions.rnn:66 of
msgid ""
"with parametric_scope(name):\n"
"    output = rnn(<args>)"
msgstr ""

#: nnabla.parametric_functions.lstm:1 of
msgid "LSTM (long short-term memory)."
msgstr ""

#: nnabla.parametric_functions.lstm:3 nnabla.parametric_functions.lstm_cell:3
#: of
msgid ""
"Long Short-Term Memory, or LSTM, is a building block for recurrent neural"
" networks (RNN) layers. LSTM unit consists of a cell and input, output, "
"forget gates whose functions are defined as following:"
msgstr ""
"Long Short-Term Memory (LSTM) は、回帰型ニューラルネットワーク (RNN) "
"層を構成するための要素の一つです。LSTM ユニットは、セルと入力、出力、忘却ゲートで構成され、その関数は以下のように定義されます。"

#: nnabla.parametric_functions.lstm:6 nnabla.parametric_functions.lstm_cell:6
#: of
msgid ""
"f_t&&=\\sigma(W_fx_t+U_fh_{t-1}+b_f) \\\\ "
"i_t&&=\\sigma(W_ix_t+U_ih_{t-1}+b_i) \\\\ "
"o_t&&=\\sigma(W_ox_t+U_oh_{t-1}+b_o) \\\\ c_t&&=f_t\\odot "
"c_{t-1}+i_t\\odot\\tanh(W_cx_t+U_ch_{t-1}+b_c) \\\\ "
"h_t&&=o_t\\odot\\tanh(c_t)."
msgstr ""

#: nnabla.parametric_functions.lstm:18 nnabla.parametric_functions.lstm_cell:15
#: of
msgid ""
"S. Hochreiter, and J. Schmidhuber. \"Long Short-Term Memory.\" Neural "
"Computation. 1997."
msgstr ""

#: nnabla.parametric_functions.lstm:25 of
msgid "Input N-D array with shape :math:`(L, D, B, H)` ."
msgstr ":math:`(L, D, B, H)` の形状の入力 N-D 配列。"

#: nnabla.parametric_functions.lstm:27 of
msgid ""
"Initializer for weight at the first layer. Shape is :math:`(D, 4, H, I + "
"H)`."
msgstr "最初の層での重みのイニシャライザー。 形状は :math:`(D, 4, H, I + H)` です。"

#: nnabla.parametric_functions.lstm:29 of
msgid ""
"Initializer for weights at the second layer and up. Shape is :math:`(L-1,"
" D, 4, H, D * H + H)`."
msgstr ""
"オプション) – 二番目、それ以上の層での重みのイニシャライザー。 形状は :math:`(L-1, D, 4, H, D * H + H)` "
"です。"

#: nnabla.parametric_functions.gru:27 nnabla.parametric_functions.lstm:31 of
msgid "Initializer for bias. Shape is :math:`(L, D, 4, H)`."
msgstr "バイアスのイニシャライザー。形状は :math:`(L, D, 4, H)` です。"

#: nnabla.parametric_functions.lstm:46 of
msgid ""
"Output :math:`y` with shape :math:`(T, B, D * H)` ~nnabla.Variable: "
"Output :math:`h_n` with shape :math:`(L, D, B, H)` ~nnabla.Variable: "
"Output :math:`c_n` with shape :math:`(L, D, B, H)`"
msgstr ""
":math:`(T, B, D * H)` の形状の出力 :math:`y` ~nnabla.Variable: :math:`(L, D, B,"
" H)` の形状の出力 :math:`h_n` ~nnabla.Variable: :math:`(L, D, B, H)` の形状の出力 "
":math:`c_n`"

#: nnabla.parametric_functions.lstm:53 of
msgid ""
"x = nn.Variable((seq_len, batch_size, input_size))\n"
"h = nn.Variable((num_layers, num_directions, batch_size, hidden_size))\n"
"c = nn.Variable((num_layers, num_directions, batch_size, hidden_size))\n"
"y, hn, cn = PF.lstm(x, h, c)"
msgstr ""

#: nnabla.parametric_functions.lstm:61 nnabla.parametric_functions.lstm_cell:36
#: of
msgid "The following variables are registered in a parameter scope ``\"lstm\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"lstm\"`` に登録されます。"

#: nnabla.parametric_functions.lstm:63 of
msgid ""
"weight_l0 (``need_grad=True``) : Filter weights at 0-th layer. (shape: "
"``(D, 4, H, I + H)``)"
msgstr ""
"weight_l0 (``need_grad=True``) : 第 0 層でのフィルターの重み (形状: ``(D, 4, H, I + "
"H)``)"

#: nnabla.parametric_functions.lstm:64 of
msgid ""
"weight (``need_grad=True``) : Filter weights at 1-st layer and above. "
"(shape: ``(L-1, D, 4, H, DH + H)``)"
msgstr ""
"weight (``need_grad=True``) : 第 1 層以上でのフィルターの重み (形状: ``(L-1, D, 4, H, DH "
"+ H)``)"

#: nnabla.parametric_functions.gru:57 nnabla.parametric_functions.lstm:65 of
msgid "bias (``need_grad=True``) : Biases. (shape: ``(L, D, 4, H)``)"
msgstr "bias (``need_grad=True``) : バイアス (形状: ``(L, D, 4, H)``)"

#: nnabla.parametric_functions.lstm:74 of
msgid ""
"with parametric_scope(name):\n"
"    output = lstm(<args>)"
msgstr ""

#: nnabla.parametric_functions.gru:1 of
msgid "GRU (gated recurrent units)."
msgstr "GRU (gated recurrent units)"

#: nnabla.parametric_functions.gru:3 of
msgid "GRU is defined as following:"
msgstr "GRU は、以下の通り定義されます。"

#: nnabla.parametric_functions.gru:5 of
msgid ""
"r_t&&=\\sigma(W_rx_t+U_rh_{t-1}+b_r) \\\\ "
"z_t&&=\\sigma(W_zx_t+U_zh_{t-1}+b_z) \\\\ n_t&&=\\tanh(W_nx_t+b_{in}+r_n "
"\\odot (U_nh_{t-1}+b_{hn})) \\\\ h_t&&=(1-z_t) \\odot n_t+z_t \\odot "
"h_{t-1}."
msgstr ""

#: nnabla.parametric_functions.gru:16 of
msgid ""
"K. Cho et al. \"Learning Phrase Representations using RNN Encoder--"
"Decoder for Statistical Machine Translation.\" Empirical Methods in "
"Natural Language Processing. 2014."
msgstr ""

#: nnabla.parametric_functions.gru:23 of
msgid ""
"Initializer for weight at the first layer. Shape is :math:`(D, 3, H, I + "
"H)`."
msgstr "最初の層での重みのイニシャライザー。 形状は :math:`(D, 3, H, I + H)` です。"

#: nnabla.parametric_functions.gru:25 of
msgid ""
"Initializer for weights at the second layer and up. Shape is :math:`(L-1,"
" D, 3, H, D * H + H)`."
msgstr ""
"オプション) – 二番目、それ以上の層での重みのイニシャライザー。 形状は :math:`(L-1, D, 3, H, D * H + H)` "
"です。"

#: nnabla.parametric_functions.gru:46 of
msgid ""
"x = nn.Variable((seq_len, batch_size, input_size))\n"
"h = nn.Variable((num_layers, num_directions, batch_size, hidden_size))\n"
"y, hn = PF.gru(x, h)"
msgstr ""

#: nnabla.parametric_functions.gru:53 of
msgid "The following variables are registered in a parameter scope ``\"gru\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"gru\"`` に登録されます。"

#: nnabla.parametric_functions.gru:55 of
msgid ""
"weight_l0 (``need_grad=True``) : Filter weights at 0-th layer. (shape: "
"``(D, 3, H, I + H)``)"
msgstr "weight_l0 (``need_grad=True``) : 第０層でのフィルターの重み (形状: ``(D, 3, H, I + H)``)"

#: nnabla.parametric_functions.gru:56 of
msgid ""
"weight (``need_grad=True``) : Filter weights at 1-st layer and above. "
"(shape: ``(L-1, D, 3, H, DH + H)``)"
msgstr ""
"weight (``need_grad=True``) : 第１層以上でのフィルターの重み (形状: ``(L-1, D, 3, H, DH + "
"H)``)"

#: nnabla.parametric_functions.gru:66 of
msgid ""
"with parametric_scope(name):\n"
"    output = gru(<args>)"
msgstr ""

#: nnabla.parametric_functions.embed:1 of
msgid "Embed."
msgstr "Embed (埋め込み)。"

#: nnabla.parametric_functions.embed:3 of
msgid ""
"Embed slices a matrix/tensor with indexing array/tensor. Weights are "
"initialized with :obj:`nnabla.initializer.UniformInitializer` within the "
"range of :math:`-\\sqrt{3}` and :math:`\\sqrt{3}`."
msgstr ""
"Embed は、インデックス配列／テンソルを使って、配列／テンソルをスライスします。重みは、 "
"`nnabla.initializer.UniformInitializer` を使って :math:`-\\sqrt{3}` から "
":math:`\\sqrt{3}` の範囲内に初期化されます。"

#: nnabla.parametric_functions.embed:5 of
msgid "[Integer] Indices with shape :math:`(I_0, ..., I_N)`"
msgstr ":math:`(I_0, ..., I_N)` の形状の [整数] インデックス"

#: nnabla.parametric_functions.embed:7 of
msgid "number of possible inputs, words or vocabraries"
msgstr "データに出現し得る入力、単語、語彙の数"

#: nnabla.parametric_functions.embed:8 of
msgid "number of embedding features"
msgstr "埋め込む機能の数"

#: nnabla.parametric_functions.embed:9 of
msgid "When set to `True`, the embedding weight matrix will not be updated."
msgstr "`True` に設定すると、埋め込み重み行列は更新されません。"

#: nnabla.parametric_functions.embed:15 of
msgid "Output with shape :math:`(I_0, ..., I_N, W_1, ..., W_M)`"
msgstr ":math:`(I_0, ..., I_N, W_1, ..., W_M)` の形状の出力"

#: nnabla.parametric_functions.embed:19 of
msgid "The following variables are registered in a parameter scope ``\"embed\"``;"
msgstr "以下の変数は、パラメータスコープ ``\"embed\"`` に登録されます。"

#: nnabla.parametric_functions.embed:21 of
msgid ""
"W (``need_grad=True``) : Embedding matrix. (shape: ``(n_inputs, "
"n_features)``)"
msgstr "W (``need_grad=True``) : 埋め込み行列 (形状: ``(n_inputs, n_features)``)"

#: nnabla.parametric_functions.embed:30 of
msgid ""
"with parametric_scope(name):\n"
"    output = embed(<args>)"
msgstr ""

#: nnabla.parametric_functions.prelu:1 of
msgid "Parametrized Rectified Linear Unit function defined as"
msgstr "次のように定義されたパラメータ化された正規化線形ユニット関数。"

#: nnabla.parametric_functions.prelu:3 of
msgid "y_i = \\max(0, x_i) + w_i \\min(0, x_i)"
msgstr ""

#: nnabla.parametric_functions.prelu:6 of
msgid ""
"where negative slope :math:`w` is learned and can vary across channels "
"(an axis specified with base_axis). Weights are initialized with "
":math:`-1`."
msgstr ""
"ここでは、負の傾き :math:`w` が学習され、チャネル ( base_axis で指定された軸) 間で変化します。重みは "
":math:`-1` で初期化されます。"

#: nnabla.parametric_functions.prelu:9 of
msgid "N-D array as input"
msgstr "入力 N-D 配列"

#: nnabla.parametric_functions.prelu:11 of
msgid "Dimensions up to base_axis is treated as sample dimension."
msgstr "base_axis までの次元は、サンプル次元として扱われます。"

#: nnabla.parametric_functions.prelu:13 of
msgid "Use shared weight value or not"
msgstr "共有の重み値を使用するか否か"

#: nnabla.parametric_functions.prelu:15 of
msgid "When set to `True`, the negative slope values will not be updated."
msgstr "`True` の場合、負の勾配値は更新されません。"

#: nnabla.parametric_functions.prelu:18 of
msgid ""
"Initializer of negative slopes. By default, they are initialized with "
"`0.25`."
msgstr "負の傾きのイニシャライザー。デフォルトでは、 `0.25` で初期化されます。"

#: nnabla.parametric_functions.prelu:25 of
msgid "The following variables are registered in a parameter scope ``\"prelu\"``;"
msgstr "次の変数は、パラメータスコープ ``\"prelu\"`` に登録されます。"

#: nnabla.parametric_functions.prelu:27 of
msgid ""
"slope (``need_grad=True``) : Negative slope. (shape: ``tuple() if shared "
"else (inp.shape[base_axis],)``)"
msgstr ""
"slope (``need_grad=True``) : 負の傾き(形状: ``共有されている場合は tuple() それ以外は "
"(inp.shape[base_axis],)``)"

#: nnabla.parametric_functions.prelu:36 of
msgid ""
"with parametric_scope(name):\n"
"    output = prelu(<args>)"
msgstr ""

#: nnabla.parametric_functions.svd_affine:1 of
msgid ""
"SVD affine is a low rank approximation of the affine layer. It can be "
"seen as two consecutive affine layers with a bottleneck. It computes:"
msgstr ""
"SVD Affine (特異値分解 Affine) は、Affine 層の低ランク近似です。ボトルネックのある 2 つの連続した Affine "
"層と見なすことができます。次のように計算します。"

#: nnabla.parametric_functions.svd_affine:5 of
msgid "{\\mathbf y} = {\\mathbf U} {\\mathbf V} {\\mathbf x} + {\\mathbf b}."
msgstr ""

#: nnabla.parametric_functions.svd_affine:8 of
msgid ""
"where :math:`{\\mathbf x}, {\\mathbf y}` are the inputs and outputs "
"respectively, and :math:`{\\mathbf U}, {\\mathbf V}, {\\mathbf b}` are "
"constants."
msgstr ""
"ここで、 :math:`{\\mathbf x}, {\\mathbf y}` はそれぞれ入力と出力で、 :math:`{\\mathbf U},"
" {\\mathbf V}, {\\mathbf b}` は定数です。"

#: nnabla.parametric_functions.svd_affine:12 of
msgid ""
"The weights :math:`{\\mathbf U}` and :math:`{\\mathbf V}` are "
"approximated with singular value decomposition (SVD) of the original "
"weight matrix :math:`{\\mathbf W}` and by selecting the :math:`{R}` "
"dominant singular values and the corresponding singular vectors. "
"Therefore the low rank :math:`{R}` is the size of the bottleneck."
msgstr ""
"重み :math:`{\\mathbf U}` と :math:`{\\mathbf V}` は、元の重み行列 :math:`{\\mathbf "
"W}` の特異値分解 ( SVD ) を使って、 :math:`{R}` "
"個の支配的な特異値と対応する特異ベクトルを選択することによって近似します。したがって、低ランク :math:`{R}` "
"はボトルネックのサイズとなります。"

#: nnabla.parametric_functions.svd_affine:19
#: nnabla.parametric_functions.svd_convolution:18 of
msgid ""
"If `uv_init` is a numpy array, :math:`{\\mathbf U}` and :math:`{\\mathbf "
"V}` are computed such that `uv_init` is approximated by "
":math:`{\\mathbf{UV}}`. If `uv_init` is `None` or an initializer, the "
"product of :math:`{\\mathbf U}` and :math:`{\\mathbf V}` approximates the"
" random initialization."
msgstr ""
"`uv_init` が numpy 配列の場合、 :math:`{\\mathbf U}` と :math:`{\\mathbf V}` は、 "
"`uv_init` が :math:`{\\mathbf{UV}}` で近似されるように計算されます。 `uv_init` が `None` "
"またはイニシャライザーの場合、 :math:`{\\mathbf U}` と :math:`{\\mathbf V}` "
"の積はランダムな初期値を近似します。"

#: nnabla.parametric_functions.svd_affine:25
#: nnabla.parametric_functions.svd_convolution:24 of
msgid ""
"If :math:`{\\mathbf U}` and :math:`{\\mathbf V}` exist in the context, "
"they take precedence over `uv_init`."
msgstr ""
":math:`{\\mathbf U}` と :math:`{\\mathbf V}` がコンテキストに存在する場合、それらは `uv_init`"
" よりも優先されます。"

#: nnabla.parametric_functions.svd_affine:28 of
msgid ""
"Suppose the weight of the affine is of :math:`{I \\times O}` and the "
"compression rate you want to specify is :math:`{CR}`, then you set "
":math:`{R}` as"
msgstr ""
"Affine の重みが :math:`{I \\times O}` で、指定する圧縮率が :math:`{CR}` とすると、 "
":math:`{R}` を次のように設定できます。"

#: nnabla.parametric_functions.svd_affine:32 of
msgid "R = \\left\\lfloor \\frac{(1 - CR)OI}{O + I} \\right\\rfloor."
msgstr ""

#: nnabla.parametric_functions.svd_affine:43 of
msgid "rank of the factorized layer (size of the bottleneck)"
msgstr "分解された層のランク (ボトルネックのサイズ)"

#: nnabla.parametric_functions.svd_affine:65 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"svd_affine\"``;"
msgstr "以下の変数がパラメータスコープ ``\"svd_affine\"`` に登録されます。"

#: nnabla.parametric_functions.svd_affine:67 of
msgid "U (``need_grad=True``) : :math:`{\\mathbf U}`. (shape: ``(inmaps, r)``)"
msgstr "U (``need_grad=True``) : :math:`{\\mathbf U}`. (形状: ``(inmaps, r)``)"

#: nnabla.parametric_functions.svd_affine:68 of
msgid "V (``need_grad=True``) : :math:`{\\mathbf V}`. (shape: ``(r, outmaps)``)"
msgstr "V (``need_grad=True``) : :math:`{\\mathbf V}`. (形状: ``(r, outmaps)``)"

#: nnabla.parametric_functions.svd_affine:78 of
msgid ""
"with parametric_scope(name):\n"
"    output = svd_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.svd_convolution:1 of
msgid ""
"SVD convolution is a low rank approximation of the convolution layer. It "
"can be seen as a depth wise convolution followed by a 1x1 convolution."
msgstr ""
"SVD convolution (特異値分解 convolution) は、convolution 層を低ランク近似します。これは、depth "
"wise convolution に続く 1 x 1 convolution と見なすことができます。"

#: nnabla.parametric_functions.svd_convolution:5 of
msgid ""
"The flattened kernels for the i-th input map are expressed by their low "
"rank approximation. The kernels for the i-th input :math:`{\\mathbf W_i}`"
" are approximated with the singular value decomposition (SVD) and by "
"selecting the :math:`{R}` dominant singular values and the corresponding "
"singular vectors."
msgstr ""
"i 番目の入力マップの平坦化されたカーネルは、それらの低ランクの近似で表されます。 i 番目のインプット :math:`{\\mathbf "
"W_i}` のカーネルは、特異値分解 ( SVD )を利用して、 :math:`{R}` "
"個の支配的な特異値と対応する特異ベクトルを選択することで近似されます。"

#: nnabla.parametric_functions.svd_convolution:11 of
msgid "{\\mathbf W_{:,i,:}} ~ {\\mathbf U_i} {\\mathbf V_i}."
msgstr ""

#: nnabla.parametric_functions.svd_convolution:14 of
msgid ""
":math:`{\\mathbf U}` contains the weights of the depthwise convolution "
"with multiplier :math:`{R}` and :math:`{\\mathbf V}` contains the weights"
" of the 1x1 convolution."
msgstr ""
":math:`{\\mathbf U}` は、乗数 :math:`{R}` を使った depthwise convolution の重さを含み、 "
":math:`{\\mathbf V}` は 1 x 1 convolution の重みを含みます。"

#: nnabla.parametric_functions.svd_convolution:27 of
msgid ""
"Suppose the kernel tensor of the convolution is of :math:`{O \\times I "
"\\times K \\times K}` and the compression rate you want to specify is "
":math:`{CR}`, then you set :math:`{R}` as"
msgstr ""
"convolution のカーネルテンソルが :math:`{O \\times I \\times K \\times K}` "
"であり、指定する圧縮率が :math:`{CR}` であるとすると、 :math:`{R}` は次のように設定できます。"

#: nnabla.parametric_functions.svd_convolution:31 of
msgid "R = \\left\\lfloor \\frac{(1 - CR)OIK^2}{I(O + K^2)} \\right\\rfloor."
msgstr ""

#: nnabla.parametric_functions.svd_convolution:42 of
msgid ""
"Convolution kernel size. For example, to apply convolution on an image "
"with a 3 (height) by 5 (width) two-dimensional kernel, specify (3, 5)."
msgstr ""
"カーネルサイズ。例えば、入力に対して3 (高さ) x 5 (幅) の 2 次元カーネルによる convlution を適用するには、( 3, 5 "
") を指定します。"

#: nnabla.parametric_functions.svd_convolution:46 of
msgid "Rank of the factorized layer."
msgstr "分解された層のランク。"

#: nnabla.parametric_functions.svd_convolution:48 of
msgid "Padding sizes (`int`) for dimensions."
msgstr "各次元に対するパディングサイズ (`int`) 。"

#: nnabla.parametric_functions.svd_convolution:50 of
msgid "Stride sizes (`int`) for dimensions."
msgstr "各次元に対するストライドサイズ (`int`) 。"

#: nnabla.parametric_functions.svd_convolution:52 of
msgid "Dilation sizes (`int`) for dimensions."
msgstr "各次元に対する膨張サイズ (`int`) 。"

#: nnabla.parametric_functions.svd_convolution:74 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"svd_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"svd_conv\"`` に登録されます；"

#: nnabla.parametric_functions.svd_convolution:76 of
msgid ""
"U (``need_grad=True``) : Decomposed filter weights :math:`{\\mathbf U}`. "
"(shape: ``(inmaps * r, *kernel)``)"
msgstr ""
"U (``need_grad=True``) : 分解フィルターの重み :math:`{\\mathbf U}`. (形状: ``(inmaps "
"* r, *kernel)``)"

#: nnabla.parametric_functions.svd_convolution:77 of
msgid ""
"V (``need_grad=True``) : Decomposed filter weights :math:`{\\mathbf V}`. "
"(shape: ``(outmaps, inmaps * r, 1, ...)``)"
msgstr ""
"V (``need_grad=True``) : 分解フィルターの重み :math:`{\\mathbf V}`. (形状: "
"``(outmaps, inmaps * r, 1, ...)``)"

#: nnabla.parametric_functions.svd_convolution:87 of
msgid ""
"with parametric_scope(name):\n"
"    output = svd_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.cpd3_convolution:1 of
msgid ""
"CP convolution is a low rank approximation of a convolution layer. A 3D "
"tensor containing the parameter is built by collapsing the N-D kernels "
"into 1D, then the tensor is decomposed into three matrices. The "
"decomposed layer can be seen as linear combinations of the input feature "
"maps to :math:`{R}` feature maps followed by a depthwise convolution and "
"followed by linear combinations of the feature maps to compute the output"
" feature maps."
msgstr ""
"CP convolution は、convolution 層の低ランク近似です。パラメータを含む 3D テンソルは、 N-D カーネルを 1 D "
"に折り畳むことによって構築され、そのテンソルは 3 つの行列に分解されます。分解されたレイヤーは、特徴マップ :math:`{R}` "
"に対する入力特徴マップの線形結合と見なされ、その後、depthwise convolution "
"が続き、その後に出力マップを計算するための特徴マップの線形結合が続きます。"

#: nnabla.parametric_functions.cpd3_convolution:3 of
msgid ""
"The CP decomposition allows to approximate the kernel tensor by "
":math:`{R}` rank-1 tensors of the form:"
msgstr "CP 分解では、次の形式のランク 1 テンソル :math:`{R}` により、カーネルテンソルに近似させることができます。"

#: nnabla.parametric_functions.cpd3_convolution:5 of
msgid ""
"\\sum_{r=1}^{R} \\lambda_r {\\mathbf{o}^{(r)} \\otimes \\mathbf{i}^{(r)} "
"\\otimes \\mathbf{k}^{(r)}},"
msgstr ""

#: nnabla.parametric_functions.cpd3_convolution:9 of
msgid ""
"where :math:`{\\lambda}_r` is the normalization coefficient and "
":math:`{\\otimes}` is the outer product."
msgstr "ここで、 :math:`{\\lambda}_r` は正規化係数、 :math:`{\\otimes}` は外積です。"

#: nnabla.parametric_functions.cpd3_convolution:12 of
msgid ""
"If `oik_init` is a numpy array, U and V are computed so that uv_init can "
"be approximates from UV If `oik_init` is None or an initializer, the "
"product of U and V approximate the randomly initialized array"
msgstr ""
"`oik_init` が numpy 配列の場合、U と V は uv_init が UV から近似できるように計算されます。 "
"`oik_init` が None またはイニシャライザーの場合、 U と V の積はランダムに初期化された配列を近似します。"

#: nnabla.parametric_functions.cpd3_convolution:15 of
msgid ""
"If `O`, `I` and `K` exist in context, they are used to initialize the "
"layer and oik_init is not used."
msgstr "`O` 、 `I` 、および `K` がコンテキスト内に存在する場合、それらは層の初期化に使用され、oik_init は使用されません。"

#: nnabla.parametric_functions.cpd3_convolution:17 of
msgid ""
"Suppose the kernel tensor of the affine is of :math:`{I \\times O}` and "
"the compression rate you want to specify is :math:`{CR}`, then you set "
":math:`{R}` as"
msgstr ""
"Affine のカーネルテンソルが :math:`{I \\times O}` で、指定する圧縮率が :math:`{CR}` であるとすると、 "
":math:`{R}` は次のように設定することができます。"

#: nnabla.parametric_functions.cpd3_convolution:21 of
msgid "R = \\left\\lfloor \\frac{(1 - CR)OIK^2}{O + I + K^2} \\right\\rfloor."
msgstr ""

#: nnabla.parametric_functions.cpd3_convolution:27 of
msgid ""
"Lebedev, Vadim, Yaroslav Ganin, Maksim Rakhuba, Ivan Oseledets, and "
"Victor Lempitsky,  \"Speeding-up convolutional neural networks using "
"fine-tuned cp-decomposition.\", arXiv preprint arXiv:1412.6553 (2014)."
msgstr ""

#: nnabla.parametric_functions.cpd3_convolution:29 of
msgid ""
"Marcella Astrid, Seung-Ik Lee, \"CP-decomposition with Tensor Power "
"Method for Convolutional Neural Networks Compression\", BigComp 2017."
msgstr ""

#: nnabla.parametric_functions.cpd3_convolution:37 of
msgid "rank of the factorized layer"
msgstr "因数分解された層のランク。"

#: nnabla.parametric_functions.cpd3_convolution:45 of
msgid ""
"Initializer for weight. Initializer for weight. By default, it is "
"initialized with :obj:`nnabla.initializer.UniformInitializer` within the "
"range determined by :obj:`nnabla.initializer.calc_uniform_lim_glorot`."
msgstr ""
"重みのイニシャライザー。デフォルトでは、 :obj:`nnabla.initializer.calc_uniform_lim_glorot` "
"によって決定される範囲内で :obj:`nnabla.initializer.UniformInitializer` で初期化されます。"

#: nnabla.parametric_functions.cpd3_convolution:47 of
msgid ""
"Initializer for bias. It is initialized with zeros if `with_bias` is "
"`True`."
msgstr "バイアスのイニシャライザー。 `with_bias` が `True` の場合、デフォルトではゼロで初期化されます。"

#: nnabla.parametric_functions.cpd3_convolution:57 of
msgid "Max iteration of the ALS."
msgstr "ALSの最大イテレーション。"

#: nnabla.parametric_functions.cpd3_convolution:59 of
msgid ""
"Threshold for stopping the ALS. If the value is negative, the convergence"
" check is ignored; in other words, it may reduce the computation time."
msgstr "ALS を停止するための閾値。値が負の場合、収束チェックは無視されます。つまり、計算時間を短縮することができます。"

#: nnabla.parametric_functions.cpd3_convolution:63 of
msgid ""
"regularization parameter for the ALS. Larger lambda_reg means larger "
"regularization."
msgstr "ALS の正則化パラメータ。 lambda_reg が大きいほど、正則化が大きくなります。"

#: nnabla.parametric_functions.cpd3_convolution:71 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"cpd3_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"cpd3_conv\"`` に登録されます。"

#: nnabla.parametric_functions.cpd3_convolution:73 of
msgid ""
"I (``need_grad=True``) : Decomposed filter weights :math:`{\\mathbf I}`. "
"(shape: ``(r, inmaps, 1, ...)``)"
msgstr ""
"I (``need_grad=True``) : 分解フィルターの重み :math:`{\\mathbf I}`. (形状: ``(r, "
"inmaps, 1, ...)``)"

#: nnabla.parametric_functions.cpd3_convolution:74 of
msgid ""
"K (``need_grad=True``) : Decomposed filter weights :math:`{\\mathbf K}`. "
"(shape: ``(r, *kernel)``)"
msgstr ""
"K (``need_grad=True``) : 分割フィルターの重み :math:`{\\mathbf K}`. (形状: ``(r, "
"*kernel)``)"

#: nnabla.parametric_functions.cpd3_convolution:75 of
msgid ""
"O (``need_grad=True``) : Decomposed filter weights :math:`{\\mathbf O}`. "
"(shape: ``(outmaps, r, 1, ...)``)"
msgstr ""
"O (``need_grad=True``) : 分解フィルターの重み :math:`{\\mathbf O}`. (形状: "
"``(outmaps, r, 1, ...)``)"

#: nnabla.parametric_functions.cpd3_convolution:85 of
msgid ""
"with parametric_scope(name):\n"
"    output = cpd3_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.binary_connect_affine:1 of
msgid "Binary Connect Affine, multiplier-less inner-product."
msgstr "Binary Connect Affine は、乗算なしの内積です。"

#: nnabla.parametric_functions.binary_connect_affine:3 of
msgid ""
"Binary Connect Affine is an affine function, except the definition of the"
" inner product is modified. The input-output relation of this function is"
" as follows:"
msgstr "Binary Connect Affine は Affine 関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.binary_connect_affine:7 of
msgid "y_i = \\sum_{i} sign(w_i) x_i."
msgstr ""

#: nnabla.parametric_functions.binary_connect_affine:11
#: nnabla.parametric_functions.binary_connect_convolution:11 of
msgid ""
"Therefore :math:`sign(w_i)` is either :math:`1` or :math:`-1` and the "
"inner product simplifies to addition."
msgstr "したがって、 :math:`sign(w_i)` は :math:`1` または :math:`-1` であり、内積は加算に単純化されます。"

#: nnabla.parametric_functions.binary_connect_affine:14 of
msgid "This function should be used together with Batch Normalization."
msgstr "この関数は、Batch Normalization と併せて使用する必要があります。"

#: nnabla.parametric_functions.binary_connect_affine:18
#: nnabla.parametric_functions.binary_connect_convolution:18 of
msgid ""
"M. Courbariaux, Y. Bengio, and J.-P. David. \"BinaryConnect: Training "
"Deep Neural Networks with binary weights during propagations.\" Advances "
"in Neural Information Processing Systems. 2015."
msgstr ""

#: nnabla.parametric_functions.binary_connect_affine:24
#: nnabla.parametric_functions.binary_connect_convolution:24
#: nnabla.parametric_functions.binary_weight_affine:22
#: nnabla.parametric_functions.binary_weight_convolution:24 of
msgid ""
"1) if you would like to share weights between some layers, please make "
"sure to share the standard, floating value weights (`weight`) and not the"
" binarized weights (`binary_weight`)"
msgstr ""
"1 ) 複数の層で重みを共有したい場合は、バイナリ化された重み (`binary_weight`) ではなく、通常の浮動小数点表現での重み "
"(`weight`) を共有してください。"

#: nnabla.parametric_functions.binary_connect_affine:28
#: nnabla.parametric_functions.binary_connect_convolution:28
#: nnabla.parametric_functions.binary_weight_affine:26
#: nnabla.parametric_functions.binary_weight_convolution:28 of
msgid ""
"2) The weights and the binary weights become synced only after "
":func:`~nnabla._variable.Variable.forward` is called, and not after a "
"call to :func:`~nnabla._variable.Variable.backward`. To access the "
"parameters of the network, remember to call "
":func:`~nnabla._variable.Variable.forward` once before doing so, "
"otherwise the float weights and the binary weights will not be in sync."
msgstr ""
"2 ) 重みとバイナリの重みは、 :func:`~nnabla._variable.Variable.forward` "
"が呼び出された後にのみ同期され、 :func:`~nnabla._variable.Variable.backward` "
"への呼び出し後では同期されません。ネットワークのパラメータにアクセスする前には、必ず "
":func:`~nnabla._variable.Variable.forward` を 1 "
"回呼び出してください。これを行わないと、浮動小数点表現の重みとバイナリの重みが同期されません。"

#: nnabla.parametric_functions.binary_connect_affine:33
#: nnabla.parametric_functions.binary_connect_convolution:33
#: nnabla.parametric_functions.binary_weight_affine:31
#: nnabla.parametric_functions.binary_weight_convolution:33 of
msgid ""
"3) Quantized values are stored as floating point number for "
"`binary_weight`, since this function is only for simulation purposes."
msgstr "3 ) この関数はシミュレーション専用であるため、量子化された値は `binary_weight` の浮動小数点数として格納されます。"

#: nnabla.parametric_functions.binary_connect_affine:42
#: nnabla.parametric_functions.binary_connect_convolution:50
#: nnabla.parametric_functions.binary_weight_affine:40
#: nnabla.parametric_functions.binary_weight_convolution:50
#: nnabla.parametric_functions.inq_affine:23 of
msgid "Input value at zero is quantized to this value."
msgstr "ゼロでの入力値は、この値に量子化されます。"

#: nnabla.parametric_functions.binary_connect_affine:46
#: nnabla.parametric_functions.binary_connect_convolution:54
#: nnabla.parametric_functions.binary_weight_convolution:54 of
msgid ""
"Initializer for binary weight. By default, it is initialized with "
":obj:`nnabla.initializer.UniformInitializer` within the range determined "
"by :obj:`nnabla.initializer.calc_uniform_lim_glorot`."
msgstr ""
"バイナリの重みのイニシャライザー。デフォルトでは、 "
":obj:`nnabla.initializer.calc_uniform_lim_glorot` によって決定される範囲内で "
":obj:`nnabla.initializer.UniformInitializer` で初期化されます。"

#: nnabla.parametric_functions.binary_connect_affine:58 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"bicon_affine\"``;"
msgstr "次の変数は、パラメータスコープ ``\"bicon_affine\"`` に登録されます。"

#: nnabla.parametric_functions.binary_connect_affine:60
#: nnabla.parametric_functions.binary_weight_affine:60
#: nnabla.parametric_functions.inq_affine:51 of
msgid ""
"W (``need_grad=True``) : Weight matrix in floating type. (shape: "
"``(inmaps, outmaps)``)"
msgstr "W (``need_grad=True``) : 浮動小数点表現での重み行列。 (形状: ``(inmaps, outmaps)``)"

#: nnabla.parametric_functions.binary_connect_affine:61
#: nnabla.parametric_functions.binary_weight_affine:61 of
msgid ""
"Wb (``need_grad=False``) : Binarized weights. (shape: ``(inmaps, "
"outmaps)``)"
msgstr "Wb (``need_grad=False``) : バイナリ化された重み。 (形状: ``(inmaps, outmaps)``)"

#: nnabla.parametric_functions.binary_connect_affine:71 of
msgid ""
"with parametric_scope(name):\n"
"    output = binary_connect_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.binary_connect_convolution:1 of
msgid "Binary Connect Convolution, multiplier-less inner-product."
msgstr "Binary Connect Convolution は、乗算なしの内積です。"

#: nnabla.parametric_functions.binary_connect_convolution:3 of
msgid ""
"Binary Connect Convolution is the convolution function, except the "
"definition of the inner product is modified. The input-output relation of"
" this function is as follows:"
msgstr ""
"Binary Connect Convolution は convolution "
"関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.binary_connect_convolution:7 of
msgid ""
"y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} sign(w_{n, m, i, j}) x_{m, a "
"+ i, b + j}."
msgstr ""

#: nnabla.parametric_functions.binary_connect_convolution:14 of
msgid "This function should be used together with BatchNormalization."
msgstr "この関数は、BatchNormalization と共に使用する必要があります。"

#: nnabla.parametric_functions.binary_connect_convolution:70 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"bicon_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"bicon_conv\"`` に登録されます。"

#: nnabla.parametric_functions.binary_connect_convolution:72
#: nnabla.parametric_functions.binary_weight_convolution:72
#: nnabla.parametric_functions.inq_convolution:49 of
msgid ""
"W (``need_grad=True``) : Filter weights in float. (shape: ``(outmaps, "
"inmaps, *kernel)``)"
msgstr ""
"W (``need_grad=True``) : 浮動小数点表現におけるフィルターの重み。(形状: ``(outmaps, inmaps, "
"*kernel)``)"

#: nnabla.parametric_functions.binary_connect_convolution:73
#: nnabla.parametric_functions.binary_weight_convolution:73 of
msgid ""
"Wb (``need_grad=False``) : Binarized filter weights. (shape: ``(outmaps, "
"inmaps, *kernel)``)"
msgstr ""
"Wb (``need_grad=False``) : バイナリ化されたフィルターの重み。(形状: ``(outmaps, inmaps, "
"*kernel)``)"

#: nnabla.parametric_functions.binary_connect_convolution:83 of
msgid ""
"with parametric_scope(name):\n"
"    output = binary_connect_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.binary_weight_affine:1 of
msgid "Binary Weight Affine, multiplier-less inner-product with a scale factor."
msgstr "Binary Weight Affine は、スケールファクターを伴う乗算なしの内積です。"

#: nnabla.parametric_functions.binary_weight_affine:3 of
msgid ""
"Binary Weight Affine is the affine function, but the inner product in "
"this function is the following,"
msgstr "Binary Weight Affine は Affine 関数ですが、この関数の内積は次のとおりです。"

#: nnabla.parametric_functions.binary_weight_affine:6 of
msgid "y_j = \\frac{1}{\\|\\mathbf{w}_j\\|_{\\ell_1}} \\sum_{i} sign(w_{ji}) x_i"
msgstr ""

#: nnabla.parametric_functions.binary_weight_affine:10 of
msgid ""
"Therefore :math:`sign(w_{ji})` is either :math:`1` or :math:`-1` and the "
"inner product simplifies to addition followed by scaling factor "
":math:`\\alpha = \\frac{1}{\\|\\mathbf{w}_j\\|_{\\ell_1}}`. The number of"
" ::math:`\\alpha` is the outmaps of the affine function."
msgstr ""
"したがって、 :math:`sign(w_{ji})` は :math:`1` または :math:`-1` "
"であり、内積計算は加算とスケールファクター :math:`\\alpha = "
"\\frac{1}{\\|\\mathbf{w}_j\\|_{\\ell_1}}` による乗算に単純化されます。 :math:`\\alpha` "
"の数が Affine 関数の outmaps となります。"

#: nnabla.parametric_functions.binary_weight_affine:16
#: nnabla.parametric_functions.binary_weight_convolution:18 of
msgid ""
"Rastegari, Mohammad, et al. \"XNOR-Net: ImageNet Classification Using "
"Binary Convolutional Neural Networks.\" arXiv preprint arXiv:1603.05279 "
"(2016)."
msgstr ""

#: nnabla.parametric_functions.binary_weight_affine:34
#: nnabla.parametric_functions.inq_affine:17
#: nnabla.parametric_functions.inq_convolution:17 of
msgid ""
"Input N-D array with shape (:math:`M_0 \\times \\ldots \\times M_{B-1} "
"\\times D_B \\times \\ldots \\times D_N`). Dimensions before and after "
"base_axis are flattened as if it was a matrix."
msgstr ""
"(:math:`M_0 \\times \\ldots \\times M_{B-1} \\times D_B \\times \\ldots "
"\\times D_N`) の形状の入力 N-D 配列。base_axis 前後の次元は、行列のように平坦化されます。"

#: nnabla.parametric_functions.binary_weight_affine:42
#: nnabla.parametric_functions.inq_convolution:31 of
msgid ""
"Initializer for the weight. By default, it is initialized with "
":obj:`nnabla.initializer.UniformInitializer` within the range determined "
"by :obj:`nnabla.initializer.calc_uniform_lim_glorot`."
msgstr ""
"重みのイニシャライザー。デフォルトでは、 :obj:`nnabla.initializer.calc_uniform_lim_glorot` "
"によって決定される範囲内で :obj:`nnabla.initializer.UniformInitializer` で初期化されます。"

#: nnabla.parametric_functions.binary_weight_affine:44 of
msgid ""
"Initializer for the binary weight. By default, it is initialized with "
":obj:`nnabla.initializer.UniformInitializer` within the range determined "
"by :obj:`nnabla.initializer.calc_uniform_lim_glorot`."
msgstr ""
"バイナリの重みのイニシャライザー。デフォルトでは、 "
":obj:`nnabla.initializer.calc_uniform_lim_glorot` によって決定される範囲内で "
":obj:`nnabla.initializer.UniformInitializer` で初期化されます。"

#: nnabla.parametric_functions.binary_weight_affine:46 of
msgid ""
"Initializer for the bias. By defalut, it is initialized with zeros if "
"`with_bias` is `True`."
msgstr "バイアスのイニシャライザー。 `with_bias` が `True` の場合、デフォルトではゼロで初期化されます。"

#: nnabla.parametric_functions.binary_weight_affine:48
#: nnabla.parametric_functions.inq_affine:39
#: nnabla.parametric_functions.inq_convolution:37 of
msgid "When set to `True`, the weight and bias will not be updated."
msgstr "`True` の場合, 重みとバイアスは更新されません。"

#: nnabla.parametric_functions.binary_weight_affine:58 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"bwn_affine\"``;"
msgstr "次の変数は、パラメータスコープ ``\"bwn_affine\"`` に登録されます。"

#: nnabla.parametric_functions.binary_weight_affine:62
#: nnabla.parametric_functions.binary_weight_convolution:74 of
msgid ""
"alpha (``need_grad=False``) : Scaling factor :math:`\\alpha`. (shape: "
"``(outmaps,)``)"
msgstr ""
"alpha (``need_grad=False``) : スケールファクター :math:`\\alpha` (形状: "
"``(outmaps,)``)"

#: nnabla.parametric_functions.binary_weight_affine:72 of
msgid ""
"with parametric_scope(name):\n"
"    output = binary_weight_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.binary_weight_convolution:1 of
msgid ""
"Binary Weight Convolution, multiplier-less inner-product with a scale "
"factor."
msgstr "Binary Weight Convolution は、スケールファクターを伴う乗算なしの内積です。"

#: nnabla.parametric_functions.binary_weight_convolution:3 of
msgid ""
"Binary Weight Convolution is the convolution function, but the inner "
"product in this function is the following,"
msgstr "Binary Weight Convolution は、convolution 関数ですが、この関数の内積は次のとおりです。"

#: nnabla.parametric_functions.binary_weight_convolution:6 of
msgid ""
"y_{n, a, b} = \\frac{1}{\\|\\mathbf{w}_n\\|_{\\ell_1}} \\sum_{m} "
"\\sum_{i} \\sum_{j} sign(w_{n, m, i, j}) x_{m, a + i, b + j}."
msgstr ""

#: nnabla.parametric_functions.binary_weight_convolution:11 of
msgid ""
"Therefore :math:`sign(w_{n, m, i, j})`  is either :math:`1` or :math:`-1`"
" and the inner product simplifies to addition followed by scaling factor "
":math:`\\alpha = \\frac{1}{\\|\\mathbf{w}_n\\|_{\\ell_1}}`. The number of"
" :math:`n` is the number of outmaps of the convolution function."
msgstr ""
"したがって、 :math:`sign(w_{n, m, i, j})` は :math:`1` または :math:`-1` "
"であり、内積は加算とスケールファクター :math:`\\alpha = "
"\\frac{1}{\\|\\mathbf{w}_n\\|_{\\ell_1}}` による乗算に単純化されます。 :math:`n` "
"の数は、convolution 関数の outmaps の数です。"

#: nnabla.parametric_functions.binary_weight_convolution:70 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"bwn_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"bwn_conv\"`` に登録されます。"

#: nnabla.parametric_functions.binary_weight_convolution:84 of
msgid ""
"with parametric_scope(name):\n"
"    output = binary_weight_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.inq_affine:1 of
msgid "Incremental Network Quantization Affine Layer"
msgstr "Incremental Network Quantization Affine (増分ネットワーク量子化 Affine) 層。"

#: nnabla.parametric_functions.inq_affine:3
#: nnabla.parametric_functions.inq_convolution:3 of
msgid ""
"During training, the weights are sequentially quantized to power-of-two "
"values, which allows the training of a multiplierless network."
msgstr "学習中、重みは順次 2 の累乗の値に量子化されます。これにより、乗算のないネットワークの学習が可能になります。"

#: nnabla.parametric_functions.inq_affine:6
#: nnabla.parametric_functions.inq_convolution:6 of
msgid ""
"Using `inq_iterations`, one can specify after how many forward passes "
"half of the learnable weights are fixed and quantized to powers-of-two. "
"After reaching the last value in `inq_iterations`, all weights are fixed."
msgstr ""
"`inq_iterations` を使用すると、学習可能な重みの半分が固定され、2 の累乗に量子化されるまでに forward "
"パスを行う回数を指定することができます。 `inq_iterations` の最後の値に到達すると、すべての重みが固定されます。"

#: nnabla.parametric_functions.inq_affine:10
#: nnabla.parametric_functions.inq_convolution:10 of
msgid "For more details, please refer to the reference."
msgstr "詳しくは以下をご参照ください。"

#: nnabla.parametric_functions.inq_affine:12
#: nnabla.parametric_functions.inq_convolution:12 of
msgid ""
"Reference: Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network "
"quantization: Towards lossless CNNs with low-precision weights. "
"<https://arxiv.org/abs/1702.03044>"
msgstr ""
"参照: Zhou A, Yao A, Guo Y, Xu L, Chen Y. Incremental network quantization:"
" Towards lossless CNNs with low-precision weights. "
"<https://arxiv.org/abs/1702.03044>"

#: nnabla.parametric_functions.inq_affine:25
#: nnabla.parametric_functions.inq_convolution:23 of
msgid ""
"Number of bits per weight. Value has to be larger than 1 as one bit is "
"already used to code the value \"0\""
msgstr "重みごとのビット数。1 ビットは値 \"0\" のコーディングにすでに使用されているため、値は 1 より大きくする必要があります。"

#: nnabla.parametric_functions.inq_affine:27
#: nnabla.parametric_functions.inq_convolution:25 of
msgid "Tuple of iteration numbers at which we fix half of the weights."
msgstr "重みの半分を固定するイテレーション数のタプル。 "

#: nnabla.parametric_functions.inq_affine:29
#: nnabla.parametric_functions.inq_convolution:27 of
msgid ""
"Chooses algorithm that is used to decide which weights are fixed. "
"(\"largest_abs\" ... fix weights with largest absolute value, \"random\" "
"... fix weights randomly)"
msgstr ""
"固定する重みを決定するために使用されるアルゴリズムを選択します。(“largest_abs” … 最大絶対値で重みを固定します。  "
"“random” …重みをランダムに固定します。）"

#: nnabla.parametric_functions.inq_affine:31
#: nnabla.parametric_functions.inq_convolution:29 of
msgid "Random seed for INQ algorithm"
msgstr " INQ アルゴリズムのランダムシード"

#: nnabla.parametric_functions.inq_affine:35 of
msgid ""
"Initializer for indicators (0 ... learnable, 1 ... fixed). By default, it"
" is initialized with zeros."
msgstr "インジケーターのイニシャライザー (0 … 学習可能, 1 … 固定)。デフォルトでは、ゼロで初期化されます。"

#: nnabla.parametric_functions.inq_affine:49 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"inq_affine\"``;"
msgstr "次の変数は、パラメータスコープ ``\"inq_affine\"`` に登録されます。"

#: nnabla.parametric_functions.inq_affine:52 of
msgid ""
"I (``need_grad=False``) : Binary indicator matrix of fixed weights. "
"(shape: ``(inmaps, outmaps)``)"
msgstr "I (``need_grad=False``) : 固定の重みのバイナリインジケーター行列 (形状: ``(inmaps, outmaps)``)"

#: nnabla.parametric_functions.inq_affine:62 of
msgid ""
"with parametric_scope(name):\n"
"    output = inq_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.inq_convolution:1 of
msgid "Incremental Network Quantization Convolution Layer"
msgstr "Incremental Network Quantization Convolution (増分ネットワーク量子化 Convolution) 層"

#: nnabla.parametric_functions.inq_convolution:33 of
msgid ""
"Initializer for the indicators (0 ... learnable, 1 ... fixed). By "
"default, it is initialized with zeros."
msgstr "インジケーターのイニシャライザー (0 … 学習可能, 1 … 固定)。デフォルトでは、ゼロで初期化されます。"

#: nnabla.parametric_functions.inq_convolution:35 of
msgid ""
"Initializer for the bias. By default, it is initialized with zeros if "
"`with_bias` is `True`."
msgstr "バイアスのイニシャライザー。 `with_bias` が `True` の場合、デフォルトではゼロで初期化されます。"

#: nnabla.parametric_functions.inq_convolution:47 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"inq_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"inq_conv\"`` に登録されます。"

#: nnabla.parametric_functions.inq_convolution:50 of
msgid ""
"I (``need_grad=False``) : Binary indicator matrix of fixed weights. "
"(shape: ``(outmaps, inmaps, *kernel)``)"
msgstr ""
"I (``need_grad=False``) : 固定の重みのバイナリインジケーター行列 (形状: ``(outmaps, inmaps, "
"*kernel)``)"

#: nnabla.parametric_functions.inq_convolution:60 of
msgid ""
"with parametric_scope(name):\n"
"    output = inq_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.fixed_point_quantized_affine:1 of
msgid "Fixed-Point Quantized Affine."
msgstr "Fixed-Point Quantized Affine (固定小数点量子化 Affine)"

#: nnabla.parametric_functions.fixed_point_quantized_affine:3 of
msgid ""
"Fixed-Point Quantized Affine is the affine function, except the "
"definition of the inner product is modified. The input-output relation of"
" this function is as follows:"
msgstr ""
"Fixed-Point Quantized Affine は Affine "
"関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:7
#: nnabla.parametric_functions.min_max_quantized_affine:7
#: nnabla.parametric_functions.pow2_quantized_affine:7
#: nnabla.parametric_functions.pruned_affine:7 of
msgid "y_j = \\sum_{i} Q(w_{ji}) x_i,"
msgstr ""

#: nnabla.parametric_functions.fixed_point_quantized_affine:11 of
msgid "where :math:`Q(w_{ji})` is the fixed-point quantization function."
msgstr "ここで :math:`Q(w_{ji})` は fixed-point quantization 関数です。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:15
#: nnabla.parametric_functions.fixed_point_quantized_convolution:15
#: nnabla.parametric_functions.min_max_quantized_affine:20
#: nnabla.parametric_functions.min_max_quantized_convolution:20
#: nnabla.parametric_functions.pow2_quantized_affine:15
#: nnabla.parametric_functions.pow2_quantized_convolution:15
#: nnabla.parametric_functions.pruned_affine:15
#: nnabla.parametric_functions.pruned_convolution:15 of
msgid ""
"1) if you would like to share weights between some layers, please make "
"sure to share the standard, floating value weights (`weight`) and not the"
" quantized weights (`quantized weight`)"
msgstr ""
"1 ) 複数の層で重みを共有する場合は、量子化された重み (`quantized weight`) ではなく、標準の浮動小数点の重み "
"(`weight`) を共有してください。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:19
#: nnabla.parametric_functions.fixed_point_quantized_convolution:19
#: nnabla.parametric_functions.min_max_quantized_affine:24
#: nnabla.parametric_functions.min_max_quantized_convolution:24
#: nnabla.parametric_functions.pow2_quantized_affine:19
#: nnabla.parametric_functions.pow2_quantized_convolution:19
#: nnabla.parametric_functions.pruned_affine:19
#: nnabla.parametric_functions.pruned_convolution:19 of
msgid ""
"2) The weights and the quantized weights become synced only after "
":func:`~nnabla._variable.Variable.forward` is called, and not after a "
"call to :func:`~nnabla._variable.Variable.backward`. To access the "
"parameters of the network, remember to call "
":func:`~nnabla._variable.Variable.forward` once before doing so, "
"otherwise the float weights and the quantized weights will not be in "
"sync."
msgstr ""
"2 ) 重みと量子化された重みは、 :func:`~nnabla._variable.Variable.forward` "
"が呼び出された後にのみ同期され、 :func:`~nnabla._variable.Variable.backward` "
"への呼び出し後では同期されません。ネットワークのパラメータにアクセスする前には、必ず "
":func:`~nnabla._variable.Variable.forward` を 1 "
"回呼び出してください。これを行わないと、浮動小数点の重みとバイナリの重みが同期しなくなります。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:24
#: nnabla.parametric_functions.fixed_point_quantized_convolution:24
#: nnabla.parametric_functions.min_max_quantized_affine:29
#: nnabla.parametric_functions.min_max_quantized_convolution:29
#: nnabla.parametric_functions.pruned_affine:24
#: nnabla.parametric_functions.pruned_convolution:24 of
msgid ""
"3) CPU and GPU implementations now use float value for `quantized "
"weight`, since this function is only for simulation purposes."
msgstr "3 ) この関数はシミュレーション専用であるため、量子化された値は `quantized weight` の浮動小数点数として格納されます。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:43
#: nnabla.parametric_functions.fixed_point_quantized_convolution:53
#: nnabla.parametric_functions.min_max_quantized_affine:48
#: nnabla.parametric_functions.min_max_quantized_convolution:60
#: nnabla.parametric_functions.pow2_quantized_affine:43
#: nnabla.parametric_functions.pow2_quantized_convolution:53
#: nnabla.parametric_functions.pruned_affine:43
#: nnabla.parametric_functions.pruned_convolution:53 of
msgid "Quantize weights if `True`."
msgstr "`True` の場合、重みを量子化します。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:45
#: nnabla.parametric_functions.fixed_point_quantized_convolution:57
#: nnabla.parametric_functions.pow2_quantized_affine:45
#: nnabla.parametric_functions.pow2_quantized_convolution:55
#: nnabla.parametric_functions.pow2_quantized_convolution:65 of
msgid "Use signed quantization if `True`."
msgstr "`True` の場合、符号付き量子化を使用します。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:47
#: nnabla.parametric_functions.fixed_point_quantized_convolution:59
#: nnabla.parametric_functions.pow2_quantized_affine:49
#: nnabla.parametric_functions.pow2_quantized_convolution:57 of
msgid "Bit width used for weight."
msgstr "重みに使われるビット幅。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:49
#: nnabla.parametric_functions.fixed_point_quantized_convolution:61 of
msgid "Step size for weight."
msgstr "重みの間隔サイズ。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:51
#: nnabla.parametric_functions.fixed_point_quantized_affine:59
#: nnabla.parametric_functions.fixed_point_quantized_convolution:63
#: nnabla.parametric_functions.fixed_point_quantized_convolution:71
#: nnabla.parametric_functions.pow2_quantized_affine:53
#: nnabla.parametric_functions.pow2_quantized_affine:63
#: nnabla.parametric_functions.pow2_quantized_convolution:61
#: nnabla.parametric_functions.pow2_quantized_convolution:71 of
msgid "STE is fine-grained if `True`."
msgstr "`True` の場合、STE はfine-grainedです。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:53
#: nnabla.parametric_functions.fixed_point_quantized_convolution:55
#: nnabla.parametric_functions.fixed_point_quantized_convolution:65
#: nnabla.parametric_functions.min_max_quantized_affine:62
#: nnabla.parametric_functions.min_max_quantized_convolution:74
#: nnabla.parametric_functions.pow2_quantized_affine:55
#: nnabla.parametric_functions.pow2_quantized_convolution:63
#: nnabla.parametric_functions.pruned_affine:47
#: nnabla.parametric_functions.pruned_convolution:57 of
msgid "Quantize bias if `True`."
msgstr "`True` の場合、バイアスを量子化します。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:55
#: nnabla.parametric_functions.fixed_point_quantized_convolution:67
#: nnabla.parametric_functions.pow2_quantized_affine:59
#: nnabla.parametric_functions.pow2_quantized_convolution:67 of
msgid "Bit width used for bias."
msgstr "バイアスに使われるビット幅"

#: nnabla.parametric_functions.fixed_point_quantized_affine:57
#: nnabla.parametric_functions.fixed_point_quantized_convolution:69 of
msgid "Step size for bias."
msgstr "バイアスの間隔サイズ。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:66 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"fp_quantized_affine\"``;"
msgstr "次の変数は、パラメータスコープ ``\"fp_quantized_affine\"`` に登録されます。"

#: nnabla.parametric_functions.fixed_point_quantized_affine:68
#: nnabla.parametric_functions.min_max_quantized_affine:86
#: nnabla.parametric_functions.pow2_quantized_affine:72
#: nnabla.parametric_functions.pruned_affine:58 of
msgid ""
"W (``need_grad=True``) : Weight matrix in float. (shape: ``(inmaps, "
"outmaps)``)"
msgstr "W (``need_grad=True``) : 浮動小数点による重みの行列 (形状: ``(inmaps, outmaps)``)"

#: nnabla.parametric_functions.fixed_point_quantized_affine:69
#: nnabla.parametric_functions.fixed_point_quantized_convolution:81
#: nnabla.parametric_functions.min_max_quantized_affine:87
#: nnabla.parametric_functions.min_max_quantized_convolution:99
#: nnabla.parametric_functions.pow2_quantized_affine:73
#: nnabla.parametric_functions.pow2_quantized_convolution:81
#: nnabla.parametric_functions.pruned_affine:59
#: nnabla.parametric_functions.pruned_convolution:69 of
msgid "b (``need_grad=True``) : Bias vector in float. (shape: ``(outmaps,)``)"
msgstr "b (``need_grad=True``) : 浮動小数点によるバイアスベクトル (形状: ``(outmaps,)``)"

#: nnabla.parametric_functions.fixed_point_quantized_affine:70
#: nnabla.parametric_functions.min_max_quantized_affine:88
#: nnabla.parametric_functions.pow2_quantized_affine:74 of
msgid ""
"W_q (``need_grad=False``) : Quantized weights. (shape: ``(inmaps, "
"outmaps)``)"
msgstr "W_q (``need_grad=False``) : 量子化された重み (形状: ``(inmaps, outmaps)``)"

#: nnabla.parametric_functions.fixed_point_quantized_affine:71
#: nnabla.parametric_functions.fixed_point_quantized_convolution:83
#: nnabla.parametric_functions.min_max_quantized_affine:89
#: nnabla.parametric_functions.min_max_quantized_convolution:101
#: nnabla.parametric_functions.pow2_quantized_affine:75
#: nnabla.parametric_functions.pow2_quantized_convolution:83
#: nnabla.parametric_functions.pruned_affine:61
#: nnabla.parametric_functions.pruned_convolution:71 of
msgid "b_q (``need_grad=False``) : Quantized biases. (shape: ``(outmaps,)``)"
msgstr "b_q (``need_grad=False``) : 量子化されたバイアス (形状: ``(outmaps,)``)"

#: nnabla.parametric_functions.fixed_point_quantized_affine:80 of
msgid ""
"with parametric_scope(name):\n"
"    output = fixed_point_quantized_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.fixed_point_quantized_convolution:1 of
msgid "Fixed-Point Quantized Convolution."
msgstr "Fixed-Point Quantized Convolution (固定小数点量子化 Convolution)"

#: nnabla.parametric_functions.fixed_point_quantized_convolution:3 of
msgid ""
"Fixed-Point Quantized Convolution is the convolution function, except the"
" definition of the inner product is modified. The input-output relation "
"of this function is as follows:"
msgstr ""
"Fixed-Point Quantized Convolution は、convolution "
"関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.fixed_point_quantized_convolution:7
#: nnabla.parametric_functions.min_max_quantized_convolution:7
#: nnabla.parametric_functions.pow2_quantized_convolution:7
#: nnabla.parametric_functions.pruned_convolution:7 of
msgid ""
"y_{n, a, b} = \\sum_{m} \\sum_{i} \\sum_{j} Q(w_{n, m, i, j}) x_{m, a + "
"i, b + j},"
msgstr ""

#: nnabla.parametric_functions.fixed_point_quantized_convolution:11 of
msgid "where :math:`Q(w_{n, m, i, j})` is the fixed-point quantization function."
msgstr "ここで :math:`Q(w_{n, m, i, j})` は fixed-point quantization 関数です。"

#: nnabla.parametric_functions.fixed_point_quantized_convolution:78 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"fp_quantized_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"fp_quantized_conv\"`` に登録されます。"

#: nnabla.parametric_functions.fixed_point_quantized_convolution:80
#: nnabla.parametric_functions.min_max_quantized_convolution:98
#: nnabla.parametric_functions.pow2_quantized_convolution:80
#: nnabla.parametric_functions.pruned_convolution:68 of
msgid ""
"W (``need_grad=True``) : Filter weights in float. (shape: ``(outmaps, "
"inmaps // group, *kernel)``)"
msgstr ""
"W (``need_grad=True``) : 浮動小数点によるフィルターの重み (形状: ``(outmaps, inmaps // "
"group, *kernel)``)"

#: nnabla.parametric_functions.fixed_point_quantized_convolution:82
#: nnabla.parametric_functions.min_max_quantized_convolution:100
#: nnabla.parametric_functions.pow2_quantized_convolution:82 of
msgid ""
"W_q (``need_grad=False``) : Quantized weights. (shape: ``(outmaps, inmaps"
" // group, *kernel)``)"
msgstr ""
"W_q (``need_grad=False``) : 量子化された重み(形状: ``(outmaps, inmaps // group, "
"*kernel)``)"

#: nnabla.parametric_functions.fixed_point_quantized_convolution:92 of
msgid ""
"with parametric_scope(name):\n"
"    output = fixed_point_quantized_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.min_max_quantized_affine:1 of
msgid "Min-max Quantized Affine."
msgstr "Min-max Quantized Affine (最小最大量子化 Affine)"

#: nnabla.parametric_functions.min_max_quantized_affine:3 of
msgid ""
"Min-max Quantized Affine is the affine function, except the definition of"
" the inner product is modified. The input-output relation of this "
"function is as follows:"
msgstr "Min-max Quantized Affine は、Affine 関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.min_max_quantized_affine:11 of
msgid "where :math:`Q(w_{ji})` is the min-max quantization function."
msgstr "ここで :math:`Q(w_{ji})` は min-max quantization 関数です。"

#: nnabla.parametric_functions.min_max_quantized_affine:13 of
msgid ""
"In the min_max_quantized affine, the exponential moving average is not "
"used. the min and max quantization ranges are either the min-max of "
"weights and bias or trained."
msgstr ""
"Min-max Quantized Affine "
"では、指数移動平均は使用されません。量子化範囲の最小値と最大値は、重みとバイアスの最小値と最大値であるか、学習によって決定されます。"

#: nnabla.parametric_functions.min_max_quantized_affine:16
#: nnabla.parametric_functions.min_max_quantized_convolution:16 of
msgid ""
"Notice that the min and max values of inputs are always used instead of "
"the exponential moving average."
msgstr "入力の最小値と最大値は、常に指数移動平均の代わりに使用されることに注意してください。"

#: nnabla.parametric_functions.min_max_quantized_affine:50
#: nnabla.parametric_functions.min_max_quantized_convolution:62 of
msgid "Minimum quantization level for weights. Default is 0."
msgstr "重みの最小量子化レベル。デフォルトは 0 です。"

#: nnabla.parametric_functions.min_max_quantized_affine:52
#: nnabla.parametric_functions.min_max_quantized_convolution:64 of
msgid "Maximum quantization level for weights. Default is 255."
msgstr "重みの最大量子化レベル。デフォルトは 255 です。"

#: nnabla.parametric_functions.min_max_quantized_affine:54
#: nnabla.parametric_functions.min_max_quantized_convolution:66 of
msgid ""
"Use the min and max of weights to compute quantization ranges. Default is"
" `False`."
msgstr "量子化範囲を計算するために重みの最小値と最大値を使用します。デフォルトは `False` です。"

#: nnabla.parametric_functions.min_max_quantized_affine:56
#: nnabla.parametric_functions.min_max_quantized_convolution:68 of
msgid ""
"Initializer for the minimum quantization range, qr_min. Default is "
":obj:`nnabla.initializer.ConstantInitializer` (-2.0)."
msgstr ""
"最小量子化範囲のイニシャライザー、 qr_min 。デフォルトは、 "
":obj:`nnabla.initializer.ConstantInitializer` (-2.0)。"

#: nnabla.parametric_functions.min_max_quantized_affine:58 of
msgid ""
"Initializer for the minimum quantization range, qr_min. Default is "
":obj:`nnabla.initializer.ConstantInitializer` (2.0)."
msgstr ""
"最大量子化範囲のイニシャライザー、 qr_max 。 デフォルトは、 "
":obj:`nnabla.initializer.ConstantInitializer` (2.0)。"

#: nnabla.parametric_functions.min_max_quantize:96
#: nnabla.parametric_functions.min_max_quantized_affine:60
#: nnabla.parametric_functions.min_max_quantized_affine:74
#: nnabla.parametric_functions.min_max_quantized_convolution:72
#: nnabla.parametric_functions.min_max_quantized_convolution:86 of
msgid ""
"If true, STE is not 1, the {0, 1}-mask computed from the min-max is "
"applied to the gradient in the backward; otherwise, STE is 1."
msgstr ""
"`True` の場合、STE は 1 ではなく、min-max から計算された {0、1} -マスクが backward "
"の勾配に適用されます。それ以外の場合、STE は 1 です。"

#: nnabla.parametric_functions.min_max_quantized_affine:64
#: nnabla.parametric_functions.min_max_quantized_convolution:76 of
msgid "Minimum quantization level for bias. Default is 0."
msgstr "バイアスの最小量子化レベル。デフォルトは 0 です。"

#: nnabla.parametric_functions.min_max_quantized_affine:66
#: nnabla.parametric_functions.min_max_quantized_convolution:78 of
msgid "Maximum quantization level for bias. Default is 255."
msgstr "バイアスの最大量子化レベル。デフォルトは 255 です。"

#: nnabla.parametric_functions.min_max_quantized_affine:68
#: nnabla.parametric_functions.min_max_quantized_convolution:80 of
msgid ""
"Use the min and max of bias to compute quantization ranges. Default is "
"`False`."
msgstr "量子化範囲を計算するためにバイアスの最小値と最大値を使用します。デフォルトは `False` です。"

#: nnabla.parametric_functions.min_max_quantize:101
#: nnabla.parametric_functions.min_max_quantized_affine:70
#: nnabla.parametric_functions.min_max_quantized_convolution:82 of
msgid ""
"Initializer for the minimum quantization range, qr_min. Default is "
":obj:`nnabla.initializer.ConstantInitializer` (-6.0)."
msgstr ""
"最小量子化範囲のイニシャライザー、 qr_min 。 デフォルトは、 "
":obj:`nnabla.initializer.ConstantInitializer` (-6.0)。"

#: nnabla.parametric_functions.min_max_quantized_affine:72 of
msgid ""
"Initializer for the minimum quantization range, qr_min. Default is "
":obj:`nnabla.initializer.ConstantInitializer` (6.0)."
msgstr ""
"最大量子化範囲のイニシャライザー、 qr_max 。 デフォルトは、 "
":obj:`nnabla.initializer.ConstantInitializer` (6.0)。"

#: nnabla.parametric_functions.min_max_quantize:98
#: nnabla.parametric_functions.min_max_quantized_affine:76
#: nnabla.parametric_functions.min_max_quantized_convolution:88 of
msgid ""
"Epsilon, or small value to ensure :math:`qr_{max} - qr_{min}` must be "
"greater than the epsilon for both weights and bias."
msgstr "イプシロン、 :math:`qr_{max} - qr_{min}` が確実に重みとバイアスの両方のイプシロンより大きくなるような小さな値。"

#: nnabla.parametric_functions.min_max_quantized_affine:84 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"min_max_quantized_affine\"``;"
msgstr "次の変数は、パラメータスコープ ``\"min_max_quantized_affine\"`` に登録されます。"

#: nnabla.parametric_functions.min_max_quantized_affine:90
#: nnabla.parametric_functions.min_max_quantized_convolution:102 of
msgid ""
"qr_min (``need_grad=False``) : Minimum quantization range. Minimum values"
" of inputs or trainable range.. (shape: ``ql_min.shape``)"
msgstr ""
"qr_min (``need_grad=False``) : 最小量子化範囲。入力または学習可能な範囲の最小値 (形状: "
"``ql_min.shape``)"

#: nnabla.parametric_functions.min_max_quantized_affine:91
#: nnabla.parametric_functions.min_max_quantized_convolution:103 of
msgid ""
"qr_max (``need_grad=False``) : Maximum quantization range. Maximum values"
" of inputs or trainable range.. (shape: ``ql_max.shape``)"
msgstr ""
"qr_max (``need_grad=False``) : 最大量子化範囲。入力または学習可能な範囲の最大値 (形状: "
"``ql_max.shape``)"

#: nnabla.parametric_functions.min_max_quantized_affine:100 of
msgid ""
"with parametric_scope(name):\n"
"    output = min_max_quantized_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.min_max_quantized_convolution:1 of
msgid "Min-max Quantized Convolution."
msgstr "Min-max Quantized Convolution (最小最大量子化 Convolution)"

#: nnabla.parametric_functions.min_max_quantized_convolution:3 of
msgid ""
"Min-max Quantized Convolution is the convolution function, except the "
"definition of the inner product is modified. The input-output relation of"
" this function is as follows:"
msgstr ""
"Min-max Quantized Convolution は、convolution "
"関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.min_max_quantized_convolution:11 of
msgid "where :math:`Q(w_{n, m, i, j})` is the min-max quantization function."
msgstr "ここでの :math:`Q(w_{n, m, i, j})` は min-max quantization 関数です。"

#: nnabla.parametric_functions.min_max_quantized_convolution:13 of
msgid ""
"In the min_max_quantized convolution, the exponential moving average is "
"not used. the min and max quantization ranges are either the min-max of "
"weights and bias or trained."
msgstr ""
"min_max_quantized convolution "
"では、指数移動平均は使用されません。量子化範囲の最小値と最大値は、重みとバイアスの最小値と最大値であるか、学習によって決定されます。"

#: nnabla.parametric_functions.min_max_quantized_convolution:70 of
msgid ""
"Initializer for the maximum quantization rage, qr_max Default is "
":obj:`nnabla.initializer.ConstantInitializer` (2.0)."
msgstr ""
"最大量子化範囲のイニシャライザー、qr_max 。デフォルトは、 "
":obj:`nnabla.initializer.ConstantInitializer` (2.0)."

#: nnabla.parametric_functions.min_max_quantize:103
#: nnabla.parametric_functions.min_max_quantized_convolution:84 of
msgid ""
"Initializer for the maximum quantization rage, qr_max Default is "
":obj:`nnabla.initializer.ConstantInitializer` (6.0)."
msgstr ""
"最大量子化範囲のイニシャライザー 、 qr_max 。 デフォルトは、 "
":obj:`nnabla.initializer.ConstantInitializer` (6.0)。"

#: nnabla.parametric_functions.min_max_quantized_convolution:96 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"min_max_quantized_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"min_max_quantized_conv\"`` に登録されます。"

#: nnabla.parametric_functions.min_max_quantized_convolution:112 of
msgid ""
"with parametric_scope(name):\n"
"    output = min_max_quantized_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.pow2_quantized_affine:1 of
msgid "Pow2 Quantized Affine."
msgstr "Pow2 Quantized Affine ( 2 のべき乗量子化 Affine)"

#: nnabla.parametric_functions.pow2_quantized_affine:3 of
msgid ""
"Pow2 Quantized Affine is the affine function, except the definition of "
"the inner product is modified. The input-output relation of this function"
" is as follows:"
msgstr "Pow2 Quantized Affine は、Affine 関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.pow2_quantized_affine:11 of
msgid "where :math:`Q(w_{ji})` is the power-of-2 quantization function."
msgstr "ここで :math:`Q(w_{ji})` は 2のべき乗量子化関数です。"

#: nnabla.parametric_functions.pow2_quantized_affine:24
#: nnabla.parametric_functions.pow2_quantized_convolution:24 of
msgid ""
"3) Quantized values are stored as floating point number for `quantized "
"weight`, since this function is only for simulation purposes."
msgstr "3 ) この関数はシミュレーション専用であるため、量子化された値は `quantized weight` の浮動小数点数として格納されます。"

#: nnabla.parametric_functions.pow2_quantized_affine:47
#: nnabla.parametric_functions.pow2_quantized_affine:57 of
msgid "Indicate using zero as a quantized value. Default is false."
msgstr "量子化値としてゼロを使用することを示します。デフォルトは false です。"

#: nnabla.parametric_functions.pow2_quantized_affine:51
#: nnabla.parametric_functions.pow2_quantized_convolution:59 of
msgid ""
":math:`2^m` is upper bound and :math:`-2^m` is lower bound for weights. "
"Default is 2."
msgstr "重みにおいて :math:`2^m` は上限、 :math:`-2^m` は下限となります。デフォルトは2です。"

#: nnabla.parametric_functions.pow2_quantized_affine:61
#: nnabla.parametric_functions.pow2_quantized_convolution:69 of
msgid ""
":math:`2^m` is upper bound and :math:`-2^m` is lower bound for bias. "
"Default is 2."
msgstr "バイアスにおいて :math:`2^m` は上限、 :math:`-2^m` は下限となります。デフォルトは2です。"

#: nnabla.parametric_functions.pow2_quantized_affine:70 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"pow2_quantized_affine\"``;"
msgstr "次の変数は、パラメータスコープ ``\"pow2_quantized_affine\"`` に登録されます。"

#: nnabla.parametric_functions.pow2_quantized_affine:84 of
msgid ""
"with parametric_scope(name):\n"
"    output = pow2_quantized_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.pow2_quantized_convolution:1 of
msgid "Pow2 Quantized Convolution."
msgstr "Pow2 Quantized Convolution ( 2 のべき乗量子化 Convolution)"

#: nnabla.parametric_functions.pow2_quantized_convolution:3 of
msgid ""
"Pow2 Quantized Convolution is the convolution function, except the "
"definition of the inner product is modified. The input-output relation of"
" this function is as follows:"
msgstr ""
"Pow2 Quantized Convolution は、convolution "
"関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.pow2_quantized_convolution:11 of
msgid "where :math:`Q(w_{n, m, i, j})` is the power-of-2 quantization function."
msgstr "ここで :math:`Q(w_{n, m, i, j})` は2のべき乗量子化関数です。"

#: nnabla.parametric_functions.pow2_quantized_convolution:78 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"pow2_quantized_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"pow2_quantized_conv\"`` に登録されます。"

#: nnabla.parametric_functions.pow2_quantized_convolution:92 of
msgid ""
"with parametric_scope(name):\n"
"    output = pow2_quantized_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.pruned_affine:1 of
msgid "Pruned Affine."
msgstr "Pruned Affine (枝刈りされた Affine)"

#: nnabla.parametric_functions.pruned_affine:3 of
msgid ""
"Pruned Affine is the affine function, except the definition of the inner "
"product is modified. The input-output relation of this function is as "
"follows:"
msgstr "Pruned Affine は、Affine 関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.pruned_affine:11
#: nnabla.parametric_functions.pruned_convolution:11 of
msgid "where :math:`Q(w_{ji})` is the pruning function, i.e., `F.prune`."
msgstr "ここで :math:`Q(w_{ji})` は pruning 関数、すなわち `F.prune` です。"

#: nnabla.parametric_functions.pruned_affine:33
#: nnabla.parametric_functions.pruned_convolution:41 of
msgid "Initializer for weight."
msgstr "重みのイニシャライザー。"

#: nnabla.parametric_functions.pruned_affine:35
#: nnabla.parametric_functions.pruned_convolution:43 of
msgid "Initializer for bias."
msgstr "バイアスのイニシャライザー。"

#: nnabla.parametric_functions.pruned_affine:45
#: nnabla.parametric_functions.pruned_convolution:55 of
msgid "Pruning rate for weights."
msgstr "重みの pruning (枝刈りする) 割合"

#: nnabla.parametric_functions.pruned_affine:49
#: nnabla.parametric_functions.pruned_convolution:59 of
msgid "Pruning rate for bias."
msgstr "バイアスの pruning (枝刈りする) 割合"

#: nnabla.parametric_functions.pruned_affine:56 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"pruned_affine\"``;"
msgstr "次の変数は、パラメータスコープ ``\"pruned_affine\"`` に登録されます。"

#: nnabla.parametric_functions.pruned_affine:60 of
msgid ""
"W_q (``need_grad=False``) : Qunatized weights. (shape: ``(inmaps, "
"outmaps)``)"
msgstr "W_q (``need_grad=False``) : 量子化された重み (形状: ``(inmaps, outmaps)``)"

#: nnabla.parametric_functions.pruned_affine:70 of
msgid ""
"with parametric_scope(name):\n"
"    output = pruned_affine(<args>)"
msgstr ""

#: nnabla.parametric_functions.pruned_convolution:1 of
msgid "Pruned Convolution."
msgstr "Pruned Convolution (枝刈りされた Convolution)"

#: nnabla.parametric_functions.pruned_convolution:3 of
msgid ""
"Pruned Convolution is the convolution function, except the definition of "
"the inner product is modified. The input-output relation of this function"
" is as follows:"
msgstr "Pruned Convolution は、convolution 関数ですが、内積の定義が変更されています。この関数の入出力関係は次のとおりです。"

#: nnabla.parametric_functions.pruned_convolution:66 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"pruned_conv\"``;"
msgstr "次の変数は、パラメータスコープ ``\"pruned_conv\"`` に登録されます。"

#: nnabla.parametric_functions.pruned_convolution:70 of
msgid ""
"W_q (``need_grad=False``) : Qunatized weights. (shape: ``(outmaps, inmaps"
" // group, *kernel)``)"
msgstr ""
"W_q (``need_grad=False``) : 量子化された重み(形状: ``(outmaps, inmaps // group, "
"*kernel)``)"

#: nnabla.parametric_functions.pruned_convolution:80 of
msgid ""
"with parametric_scope(name):\n"
"    output = pruned_convolution(<args>)"
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:1 of
msgid "Min-max quantization."
msgstr "Min-max quantization (最小最大量子化)"

#: nnabla.parametric_functions.min_max_quantize:3 of
msgid ""
"This function uniformly quantizes values in the range of min and max "
"quantization levels."
msgstr "この関数は、最小および最大量子化レベルの範囲の値を均一に量子化します。"

#: nnabla.parametric_functions.min_max_quantize:5 of
msgid "Min-max quantization is defined as the following equation"
msgstr "最小最大量子化は、次の方程式として定義されます。"

#: nnabla.parametric_functions.min_max_quantize:7 of
msgid ""
"y = round \\left(\\frac{\\min(\\max(x, m), M) - m}{scale} \\right) "
"\\times scale + m,"
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:11 of
msgid "where the :math:`scale` is defined as"
msgstr "ここで、 :math:`scale` は次のように定義されます。"

#: nnabla.parametric_functions.min_max_quantize:13 of
msgid "scale = \\frac{M - m}{M_q - m_q},"
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:17 of
msgid "and"
msgstr "そして"

#: nnabla.parametric_functions.min_max_quantize:19 of
msgid "m_q = ql_{min}, \\\\ M_q = ql_{max}, \\\\ m = qr_{min}, \\\\ M = qr_{max}."
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:26 of
msgid "In the backward pass when using `ste_fine_grained` as false,"
msgstr "backward パスにおいて `ste_fine_grained` が false として使われる時、"

#: nnabla.parametric_functions.min_max_quantize:28 of
msgid "\\frac{\\partial q_i}{\\partial x_i} = 1."
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:33 of
msgid "In the backward pass when using `ste_fine_grained` as true,"
msgstr "backward パスにおいて `ste_fine_grained` が True として使われる時、"

#: nnabla.parametric_functions.min_max_quantize:35 of
msgid ""
"\\frac{\\partial q_i}{\\partial x_i}= \\left\\{ \\begin{array}{ll}   0 & "
"if \\ \\ \\ x_i > M \\\\   1 & if \\ \\ m \\le x_i \\le M \\\\   0 & if "
"\\ \\ x_i < m \\\\ \\end{array} \\right.."
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:44 of
msgid ":math:`qr_{min}` and :math:`qr_{max}` are treaded as follows."
msgstr ":math:`qr_{min}` と :math:`qr_{max}` は以下のように扱われます。"

#: nnabla.parametric_functions.min_max_quantize:46 of
msgid ""
"`x_min_max` is `True` and `ema` is `True`: Exponential moving average are"
" computed for each :math:`min(x)` and :math:`max(x)` then stored in "
":math:`qr_{min}` and :math:`qr_{max}`."
msgstr ""
"`x_min_max` が `True` で、 `ema` が `True` の場合： :math:`min(x)` および "
":math:`max(x)` ごとに指数移動平均が計算され、 :math:`qr_{min}` および :math:`qr_{max}` "
"に格納されます。"

#: nnabla.parametric_functions.min_max_quantize:49 of
msgid ""
"`x_min_max` is `True` and `ema` is `False`: :math:`min(x)` and "
":math:`max(x)` are computed then stored in :math:`qr_{min}` and "
":math:`qr_{max}`."
msgstr ""
"`x_min_max` が `True` で、 `ema` が `False` の場合： :math:`min(x)` と "
":math:`max(x)` が計算され、 :math:`qr_{min}` と :math:`qr_{max}` に格納されます。"

#: nnabla.parametric_functions.min_max_quantize:51 of
msgid ""
"`x_min_max` is `False` and `ema` is `True`: Exponential moving average "
"stored in :math:`qr_{min}` and :math:`qr_{max}` are used."
msgstr ""
"`x_min_max` が `False` で、 `ema` が `True` の場合： :math:`qr_{min}` と "
":math:`qr_{max}` に格納されている指数移動平均が使用されます。"

#: nnabla.parametric_functions.min_max_quantize:53 of
msgid ""
"`x_min_max` is `False` and `ema` is `False` Gradients of :math:`qr_{min}`"
" and :math:`qr_{max}` are computed in the backward pass."
msgstr ""
"`x_min_max` が `False` で、 `ema` が `False` の場合： :math:`qr_{min}` と "
":math:`qr_{max}` の勾配は、backward パスで計算されます。"

#: nnabla.parametric_functions.min_max_quantize:56 of
msgid ""
"More precisely, in inference of the min-max quantization, one has to "
"consider *zero-point (zp)* which corresponds to the real value 0, and its"
" data type is an integer. *zero-point* is defined as"
msgstr ""
"より正確には、min-max quantization の推論では、実際の値 0 に対応する *ゼロ点 ( zp )* "
"を考慮する必要があり、そのデータ型は整数です。 *ゼロポイント* は次のように定義されます"

#: nnabla.parametric_functions.min_max_quantize:60 of
msgid ""
"&& zp_f = ql_{min} -\\frac{qr_{min}}{scale}, \\\\   && zp = \\left\\{ "
"\\begin{array}{ll}   ql_{max} & if \\ \\ \\ zp_f >= ql_{max} \\\\   "
"round(zp_f) & if \\ \\ otherwise \\\\   ql_{min}  & if \\ \\ zp_f <= "
"ql_{min} \\\\ \\end{array} \\right.."
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:70 of
msgid ""
"Accordingly, in order to simulate quantization effect of *zero-point*, "
"during both forward and backward pass, :math:`qr_{min}` and "
":math:`qr_{max}` are adjusted as follows,"
msgstr ""
"したがって、 *ゼロ点* の量子化効果をシミュレートするために、forward パスと backward パスの両方で、 "
":math:`qr_{min}` と :math:`qr_{max}` は次のように調整されます。"

#: nnabla.parametric_functions.min_max_quantize:73 of
msgid ""
"qr_{min}^{adj} = ql_{min} - zp * scale, \\\\ qr_{max}^{adj} = ql_{max} - "
"zp * scale."
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:78 of
msgid "These operations are often called *nudge*."
msgstr "これらの操作は *nudge* と呼ばれます。"

#: nnabla.parametric_functions.min_max_quantize:80 of
msgid ""
"Finally, in the formulas of the min-max quantization, :math:`m` and "
":math:`M` are replaced by :math:`qr_{min}^{adj}` and "
":math:`qr_{max}^{adj}` respectively."
msgstr ""
"最後に、min-max quantization の式では、 :math:`m` と :math:`M` はそれぞれ "
":math:`qr_{min}^{adj}` と :math:`qr_{max}^{adj}` に置き換えられます。"

#: nnabla.parametric_functions.min_max_quantize:83 of
msgid "Input N-D array."
msgstr "入力 N-D 配列。"

#: nnabla.parametric_functions.min_max_quantize:85 of
msgid "Minimum quantization level. Default is 0."
msgstr "最小量子化レベル。デフォルトは 0 です。"

#: nnabla.parametric_functions.min_max_quantize:87 of
msgid "Maximum quantization level. Default is 255."
msgstr "最大量子化レベル。デフォルトは 255 です。"

#: nnabla.parametric_functions.min_max_quantize:89 of
msgid "The decay rate for the exponential moving average."
msgstr "指数移動平均の減衰率。"

#: nnabla.parametric_functions.min_max_quantize:91 of
msgid ""
"Use the min and max of x to compute quantization ranges. Default is "
"`False`."
msgstr "量子化範囲を計算するために、 x の最小値と最大値を使用します。デフォルトは `False` です。"

#: nnabla.parametric_functions.min_max_quantize:93 of
msgid ""
"Use the exponential moving average for the min and max quantization "
"ranges. Default is `False`."
msgstr "最小および最大量子化範囲に指数移動平均を使用します。デフォルトは `False` です。"

#: nnabla.parametric_functions.min_max_quantize:110 of
msgid ""
"Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, "
"Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko, \"Quantization and "
"Training of Neural Networks for Efficient Integer-Arithmetic-Only "
"Inference\", https://arxiv.org/abs/1712.05877"
msgstr ""

#: nnabla.parametric_functions.min_max_quantize:113 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"min_max_quantize\"``;"
msgstr "次の変数は、パラメータスコープ ``\"min_max_quantize\"`` に登録されます。"

#: nnabla.parametric_functions.min_max_quantize:115 of
msgid ""
"qr_min (``need_grad=False``) : Minimum quantization range, the "
"exponential movining average of min values of inputs initialized with "
"-6.0 if ema is True. (shape: ``ql_min.shape``)"
msgstr ""
"qr_min (``need_grad=False``) : 最小量子化範囲、 ema が True の場合、-6.0 "
"で初期化された入力の最小値の指数移動平均 (形状: ``ql_min.shape``)"

#: nnabla.parametric_functions.min_max_quantize:116 of
msgid ""
"qr_max (``need_grad=False``) : Maximum quantization range, the "
"exponential movining average of max values of inputs initialized with 6.0"
" if ema is True. (shape: ``ql_max.shape``)"
msgstr ""
"qr_max (``need_grad=False``) : 最大量子化範囲、 ema が True の場合に 6.0 "
"で初期化された入力の最大値の指数移動平均。(形状: ``ql_max.shape``)"

#: nnabla.parametric_functions.min_max_quantize:125 of
msgid ""
"with parametric_scope(name):\n"
"    output = min_max_quantize(<args>)"
msgstr ""

#: nnabla.parametric_functions.lstm_cell:1 of
msgid "Long Short-Term Memory."
msgstr "Long Short-Term Memory (長・短期記憶)"

#: nnabla.parametric_functions.LSTMCell.__call__:3
#: nnabla.parametric_functions.lstm_cell:18 of
msgid "Input N-D array with shape (batch_size, input_size)."
msgstr " (batch_size, input_size) の形状の入力 N-D 配列。"

#: nnabla.parametric_functions.lstm_cell:20
#: nnabla.parametric_functions.lstm_cell:22 of
msgid "Input N-D array with shape (batch_size, state_size)."
msgstr "(batch_size, state_size) の形状の入力 N-D 配列。"

#: nnabla.parametric_functions.lstm_cell:24 of
msgid "Internal state size is set to `state_size`."
msgstr "内部状態サイズは `state_size` に設定されます。"

#: nnabla.parametric_functions.lstm_cell:38 of
msgid ""
"affine/W (``need_grad=True``) : Stacked weight matrixes of LSTM block. "
"(shape: ``(inmaps, 4, state_size)``)"
msgstr ""
"affine/W (``need_grad=True``) : LSTM ブロックの重み行列(形状: ``(inmaps, 4, "
"state_size)``)"

#: nnabla.parametric_functions.lstm_cell:39 of
msgid ""
"affine/b (``need_grad=True``) : Stacked bias vectors of LSTM block. "
"(shape: ``(4, state_size,)``)"
msgstr ""
"affine/b (``need_grad=True``) : LSTM ブロックのバイアスベクトル(形状: ``(4, "
"state_size,)``)"

#: nnabla.parametric_functions.lstm_cell:48 of
msgid ""
"with parametric_scope(name):\n"
"    output = lstm_cell(<args>)"
msgstr ""

#: nnabla.parametric_functions.LSTMCell.__call__:1 of
msgid "Updates h and c by calling lstm function."
msgstr "lstm 関数を呼び出して h と c を更新します。"

#: nnabla.parametric_functions.spectral_norm:1 of
msgid "Spectral Normalization."
msgstr "Spectral Normalization (スペクトル正規化)"

#: nnabla.parametric_functions.spectral_norm:3 of
msgid "W_{sn} = \\frac{W}{\\sigma(W)}."
msgstr ""

#: nnabla.parametric_functions.spectral_norm:7 of
msgid ""
"where :math:`W` is the input matrix, and the :math:`\\sigma(W)` is the "
"spectral norm of :math:`W`. The spectral norm is approximately computed "
"by the power iteration."
msgstr ""
"ここで、 :math:`W` は入力の行列であり、 :math:`\\sigma(W)` は :math:`W` "
"のスペクトルノルムです。スペクトルノルムは、パワーイテレーションによって近似的に計算されます。"

#: nnabla.parametric_functions.spectral_norm:11 of
msgid ""
"Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida, "
"\"Spectral Normalization for Generative Adversarial Networks\", "
"International Conference on Learning Representations. 2018."
msgstr ""

#: nnabla.parametric_functions.spectral_norm:15
#: nnabla.parametric_functions.weight_normalization:18 of
msgid "Input N-D array with shape. This is normally network parameter."
msgstr "形状の入力 N-D 配列。これは通常ネットワークのパラメータです。"

#: nnabla.parametric_functions.spectral_norm:17
#: nnabla.parametric_functions.weight_normalization:20 of
msgid ""
"Output dimension. Default is 0. If the dimension is not 0, then the "
"specified dimension becomes the most-left dimension by transposing."
msgstr "出力次元。デフォルトは 0 です。次元が 0 でない場合、指定された次元は転置によって左端の次元になります。"

#: nnabla.parametric_functions.spectral_norm:19 of
msgid "Number of iterations. Default is 1."
msgstr "イテレーション回数。デフォルトは 1 です。"

#: nnabla.parametric_functions.spectral_norm:21
#: nnabla.parametric_functions.weight_normalization:23 of
msgid "Epsilon for the normalization. Default is 1e-12."
msgstr "正規化の際に用いられるイプシロン。デフォルトは 1e-12 です。"

#: nnabla.parametric_functions.spectral_norm:23 of
msgid "Use test mode. Default is False."
msgstr "テストモードを使用します。デフォルトは False です。"

#: nnabla.parametric_functions.spectral_norm:26 of
msgid "Spectrally normalized :math:`W_{sn}` with the same shape as :math:`W`."
msgstr ":math:`W` と同じ形状のスペクトル正規化された :math:`W_{sn}`"

#: nnabla.parametric_functions.spectral_norm:31 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"\n"
"b, c, h, w = 4, 64, 32, 32\n"
"\n"
"# Spectrally normalized convolution\n"
"apply_w = lambda w: PF.spectral_norm(w, dim=0)\n"
"h = nn.Variable.from_numpy_array(np.random.randn(b, c, h, w))\n"
"h = PF.convolution(h, with_bias=False, apply_w=apply_w)\n"
"\n"
"# Spectrally normalized affine\n"
"apply_w = lambda w: PF.spectral_norm(w, dim=1)\n"
"h = nn.Variable.from_numpy_array(np.random.randn(b, c))\n"
"h = PF.affine(h, with_bias=False, apply_w=apply_w)\n"
"\n"
"# Spectrally normalized embed\n"
"apply_w = lambda w: PF.spectral_norm(w, dim=1)\n"
"h = nn.Variable.from_numpy_array(np.random.randn(b, c))\n"
"h = PF.embed(h, c, apply_w=apply_w)"
msgstr ""

#: nnabla.parametric_functions.spectral_norm:54 of
msgid ""
"The following variables are registered in a parameter scope ``\"spectral-"
"norm\"``;"
msgstr "次の変数は、パラメータスコープ ``\"spectral-norm\"`` に登録されています。"

#: nnabla.parametric_functions.spectral_norm:56 of
msgid ""
"W_sn (``need_grad=False``) : Spectral Normalized Weight matrix. (shape: "
"``w.shape``)"
msgstr "W_sn (``need_grad=False``) : スペクトル正規化した重みの行列 (形状: ``w.shape``)"

#: nnabla.parametric_functions.spectral_norm:57 of
msgid "u (``need_grad=False``) : singular vector. (shape: ``(w.shape[dim], )``)"
msgstr "u (``need_grad=False``) : 特異ベクトル (形状: ``(w.shape[dim], )``)"

#: nnabla.parametric_functions.spectral_norm:66 of
msgid ""
"with parametric_scope(name):\n"
"    output = spectral_norm(<args>)"
msgstr ""

#: nnabla.parametric_functions.weight_normalization:1 of
msgid "Weight Normalization."
msgstr "Weight Normalization"

#: nnabla.parametric_functions.weight_normalization:3 of
msgid "\\mathbf{w} = g \\dfrac{\\mathbf{v}}{\\|\\mathbf{v}\\|}"
msgstr ""

#: nnabla.parametric_functions.weight_normalization:6 of
msgid ""
"where :math:`v` is the input matrix, and :math:`g` is learnable "
"multiplication factors each of which is applied to each output map at "
"`dim`. This function is in general used as callback passed to apply_w for"
" PF.convolution, PF.affine and so on. According to the author`s original "
"implementation (https://github.com/TimSalimans/weight_norm), :math:`v` "
"should be initialized by :math:`N(0, 0.05)`. To meet this condition, "
"initializer should be passed to convolution which Weight Normalization is"
" applied, like an example below."
msgstr ""
"ここでは、 :math:`v` は入力行列、 :math:`g` は学習可能な乗算係数であり、各乗算係数が `dim` "
"の各出力マップに適用されます。一般的に、この関数は PF convolution、PF affine などにおいて apply_w "
"に渡すコールバック関数として使われます。開発者の元の実装 (https://github.com/TimSalimans/weight_norm)"
" によると、 :math:`v` は :math:`N(0, 0.05)` "
"で初期化されるのが好ましいとされています。この条件を満たすためには、以下の例のように、Weight Normalization を適用した "
"convolution にイニシャライザーを渡す必要があります。"

#: nnabla.parametric_functions.weight_normalization:15 of
msgid ""
"`Tim Salimans, Diederik P. Kingma, Weight Normalization: A Simple "
"Reparameterization to Accelerate Training of Deep Neural Networks. "
"<https://arxiv.org/abs/1602.07868>`_"
msgstr ""

#: nnabla.parametric_functions.weight_normalization:26 of
msgid ":math:`W_{sn}` with the same shape as :math:`W`."
msgstr ":math:`W` と同じ形状の :math:`W_{sn}`"

#: nnabla.parametric_functions.weight_normalization:31 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"# h is nn.Variable.\n"
"\n"
"# convolution\n"
"# according to the original implementation, w should be initialized by "
"N(0, 0.05).\n"
"h = PF.convolution(h, ..., apply_w=PF.weight_normalization, "
"w_init=I.NormalInitializer(0.05))\n"
"\n"
"# affine\n"
"h = PF.affine(h, ..., apply_w=lambda w: PF.weight_normalization(w, "
"dim=1), w_init=I.NormalInitializer(0.05))"
msgstr ""

#: nnabla.parametric_functions.weight_normalization:47 of
msgid "The following variables are registered in a parameter scope ``\"wn\"``;"
msgstr "次の変数は、パラメータスコープ ``\"wn\"`` に登録されます。"

#: nnabla.parametric_functions.weight_normalization:49 of
msgid ""
"g (``need_grad=True``) : Weight Normalization adaptive scale scalar.. "
"(shape: ``w.shape[dim]``)"
msgstr ""
"g (``need_grad=True``) : Weight Normalization 適応スケールスカラー。 (形状: "
"``w.shape[dim]``)"

#: nnabla.parametric_functions.weight_normalization:58 of
msgid ""
"with parametric_scope(name):\n"
"    output = weight_normalization(<args>)"
msgstr ""

#: nnabla.parametric_functions.multi_head_attention:1 of
msgid "MultiHeadAttention."
msgstr "MultiHeadAttention"

#: nnabla.parametric_functions.multi_head_attention:3 of
msgid ""
"Computes multi-headed attention with query, key, and value. We use the "
"following notations to describe the inputs and outputs below. "
":math:`L_T`: target sequence length, :math:`L_S`: source sequence length,"
" :math:`B`: batch size, :math:`E`: embedding dimension."
msgstr ""
"クエリ、キー、および値を使用して、multi-headed attention "
"を計算します。以下では入力と出力を説明するために、次の表記を使用します。 :math:`L_T` ：ターゲットシーケンスの長さ、 "
":math:`L_S` ：ソースシーケンスの長さ、 :math:`B` ：バッチサイズ、 :math:`E` ：埋め込み次元。"

#: nnabla.parametric_functions.multi_head_attention:9
#: nnabla.parametric_functions.transformer:8 of
msgid ""
"A. Vaswani et al. \"Attention is All You Need.\" NIPS. 2017. "
"<https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf>"
msgstr ""

#: nnabla.parametric_functions.multi_head_attention:15 of
msgid ""
"q = nn.Variable((tgt_len, batch_size, embed_dim))\n"
"k = nn.Variable((src_len, batch_size, kdim))\n"
"v = nn.Variable((src_len, batch_size, vdim))\n"
"\n"
"out, w = PF.multi_head_attention(q, k, v)\n"
"out.forward()"
msgstr ""

#: nnabla.parametric_functions.multi_head_attention:24 of
msgid "Input N-D array with shape :math:`(L_T, B, E)`."
msgstr ":math:`(L_T, B, E)` の形状の入力 N-D 配列。"

#: nnabla.parametric_functions.multi_head_attention:26 of
msgid "Input N-D array with shape :math:`(L_S, B, E_k)`."
msgstr ":math:`(L_S, B, E_k)` の形状の入力 N-D 配列。"

#: nnabla.parametric_functions.multi_head_attention:28 of
msgid "Input N-D array with shape :math:`(L_S, B, E_v)`."
msgstr ":math:`(L_S, B, E_v)` の形状の入力 N-D 配列"

#: nnabla.parametric_functions.multi_head_attention:30 of
msgid ""
"Number of attention heads. Note that embedding dimensoin E must be "
"divisible by the number of heads. Default is 12 which is conventional."
msgstr ""
"attention head の数。次元 E の埋め込みは、head "
"の数で割り切れる必要があることに注意してください。デフォルトはよく用いられる12です。"

#: nnabla.parametric_functions.multi_head_attention:32 of
msgid "Dropout ratio applied to parameters. Default is 0."
msgstr "パラメータに適用されるドロップアウト比。デフォルトは 0 です。"

#: nnabla.parametric_functions.multi_head_attention:34
#: nnabla.parametric_functions.transformer:51
#: nnabla.parametric_functions.transformer_decode:25 of
msgid "Random generator for Initializer. Default is None."
msgstr "イニシャライザーのランダムジェネレーター。デフォルトは None です。"

#: nnabla.parametric_functions.multi_head_attention:36 of
msgid "Specify whether to include the bias parameters. Default is True."
msgstr "バイアス項を含めるか否かを指定します。 デフォルトは True です。"

#: nnabla.parametric_functions.multi_head_attention:38
#: nnabla.parametric_functions.transformer:53
#: nnabla.parametric_functions.transformer_decode:27
#: nnabla.parametric_functions.transformer_encode:21 of
msgid ""
"Specify whether to add attention bias parameters for key and value. "
"Default is False."
msgstr "キーと値に attention バイアスパラメータを追加するか否かを指定します。デフォルトは False です。"

#: nnabla.parametric_functions.multi_head_attention:40 of
msgid ""
"Input N-D array with shape :math:`(L_T, L_S)`. Values will be added to "
"the attention layer to prevent attention to certain positions."
msgstr ""
":math:`(L_T, L_S)` の形状の入力 N-D 配列。 特定の位置への attention を防ぐために、attention "
"層に値が追加されます。"

#: nnabla.parametric_functions.multi_head_attention:42 of
msgid ""
"Input N-D array with shape :math:`(B, L_S)`. Specified padding elements "
"will be ignored by the attention layer. Values must be either 1 or 0."
msgstr ""
":math:`(B, L_S)` の形状の入力 N-D 配列。指定されたパディング要素は attention 層によって無視されます。値は 1 "
"または 0 である必要があります。"

#: nnabla.parametric_functions.multi_head_attention:44
#: nnabla.parametric_functions.transformer:55
#: nnabla.parametric_functions.transformer_decode:29
#: nnabla.parametric_functions.transformer_encode:23 of
msgid ""
"When set to `True`, the weights and biases will not be updated. Default "
"is False."
msgstr "`True` に設定すると、重みとバイアスは更新されません。デフォルトは False です。"

#: nnabla.parametric_functions.multi_head_attention:46 of
msgid ""
"Parameter initializers can be set with a dict. Possible keys of the dict "
"include q_weight, k_weight, v_weight, q_bias, k_bias, v_bias, out_weight,"
" out_bias, attn_bias_k, attn_bias_v. A value of the dict must be an "
":obj:`~nnabla.initializer.Initializer` or a :obj:`numpy.ndarray`. E.g. "
"``{'q_bias': ConstantInitializer(0)}``."
msgstr ""
"パラメータイニシャライザーは dict で設定できます。dict "
"の設定可能なキーには、q_weight、k_weight、v_weight、q_bias、k_bias、v_bias、out_weight、out_bias、attn_bias_k、attn_bias_v"
" があります。dict の値は、 :obj:`~nnabla.initializer.Initializer` または "
":obj:`numpy.ndarray` である必要がります。例 ``{'q_bias': ConstantInitializer(0)}`` 。"

#: nnabla.parametric_functions.multi_head_attention:52 of
msgid ""
"Output :math:`y` with shape :math:`(L_T, B, E)` ~nnabla.Variable: Output "
":math:`h_n` with shape :math:`(B, L_T, L_S)`"
msgstr ""
":math:`(L_T, B, E)` の形状をもつ出力 :math:`y` \n"
"~nnabla.Variable: :math:`(B, L_T, L_S)` の形状をもつ出力 :math:`h_n`"

#: nnabla.parametric_functions.multi_head_attention:57 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"multi_head_attention\"``;"
msgstr "次の変数は、パラメータスコープ ``\"multi_head_attention\"`` に登録されます。"

#: nnabla.parametric_functions.multi_head_attention:59 of
msgid "q_weight (``need_grad=True``) : weights for query. (shape: ``(E, E)``)"
msgstr "q_weight (``need_grad=True``) : クエリの重み (形状: ``(E, E)``)"

#: nnabla.parametric_functions.multi_head_attention:60 of
msgid "k_weight (``need_grad=True``) : weights for key. (shape: ``(E_k, E)``)"
msgstr "k_weight (``need_grad=True``) : キーの重み (形状: ``(E_k, E)``)"

#: nnabla.parametric_functions.multi_head_attention:61 of
msgid "v_weight (``need_grad=True``) : weights for value. (shape: ``(E_v, E)``)"
msgstr "v_weight (``need_grad=True``) : 値の重み (形状: ``(E_v, E)``)"

#: nnabla.parametric_functions.multi_head_attention:62 of
msgid ""
"out_weight (``need_grad=True``) : weigths for out projection. (shape: "
"``(E, E)``)"
msgstr "out_weight (``need_grad=True``) : 射影の重み (形状: ``(E, E)``)"

#: nnabla.parametric_functions.multi_head_attention:63 of
msgid "q_bias (``need_grad=True``) : bias for query. (shape: ``(E, )``)"
msgstr "q_bias (``need_grad=True``) : クエリのバイアス (形状: ``(E, )``)"

#: nnabla.parametric_functions.multi_head_attention:64 of
msgid "k_bias (``need_grad=True``) : bias for key. (shape: ``(E, )``)"
msgstr "k_bias (``need_grad=True``) : キーのバイアス (形状: ``(E, )``)"

#: nnabla.parametric_functions.multi_head_attention:65 of
msgid "v_bias (``need_grad=True``) : bais for value. (shape: ``(E, )``)"
msgstr "v_bias (``need_grad=True``) : 値のバイアス (形状: ``(E, )``)"

#: nnabla.parametric_functions.multi_head_attention:66 of
msgid ""
"out_bias (``need_grad=True``) : bias for out projection. (shape: ``(E, "
")``)"
msgstr "out_bias (``need_grad=True``) : 射影のバイアス (形状: ``(E, )``)"

#: nnabla.parametric_functions.multi_head_attention:67 of
msgid ""
"attn_bias_k (``need_grad=True``) : attnetion bias for k. (shape: ``(E, "
"1)``)"
msgstr "attn_bias_k (``need_grad=True``) : k のattention バイアス (形状: ``(E, 1)``)"

#: nnabla.parametric_functions.multi_head_attention:68 of
msgid ""
"attn_bias_v (``need_grad=True``) : attnetion bias for v. (shape: ``(E, "
"1)``)"
msgstr "attn_bias_v (``need_grad=True``) : v の attention バイアス (形状: ``(E, 1)``)"

#: nnabla.parametric_functions.multi_head_attention:77 of
msgid ""
"with parametric_scope(name):\n"
"    output = multi_head_attention(<args>)"
msgstr ""

#: nnabla.parametric_functions.transformer:1 of
msgid "Transformer."
msgstr "Transformer (トランスフォーマー)"

#: nnabla.parametric_functions.transformer:3 of
msgid ""
"We use the following notations to describe the inputs and outputs below. "
":math:`L_T`: target sequence length, :math:`L_S`: source sequence length,"
" :math:`B`: batch size, :math:`E`: embedding dimension."
msgstr ""
"以下では入力と出力を説明するために、次の表記を使用します。 :math:`L_T` ：ターゲットシーケンスの長さ、 :math:`L_S` "
"：ソースシーケンスの長さ、 :math:`B` ：バッチサイズ、 :math:`E` ：埋め込み次元。"

#: nnabla.parametric_functions.transformer:12 of
msgid "Examples:"
msgstr "例："

#: nnabla.parametric_functions.transformer:14 of
msgid ""
"src = nn.Variable((src_len, batch_size, embed_dim),need_grad=True)\n"
"tgt = nn.Variable((tgt_len, batch_size, embed_dim),need_grad=True)\n"
"out = PF.transformer(src, tgt, num_heads=16, num_encoder_layers=12)\n"
"out.forward()"
msgstr ""

#: nnabla.parametric_functions.transformer:21 of
msgid "Input source sequence to the encoder with shape:math:`(L_S, B, E)`."
msgstr ":math:`(L_S, B, E)` の形状のエンコーダーへの入力ソースシーケンス。"

#: nnabla.parametric_functions.transformer:23 of
msgid "Input target sequence to the decoder with shape :math:`(L_T, B, E)`."
msgstr ":math:`(L_T, B, E)` の形状のデコーダーへの入力ターゲットシーケンス。"

#: nnabla.parametric_functions.transformer:25 of
msgid "Embedding dimension to be used. Default is 512."
msgstr "使用する埋め込み次元。デフォルトは 512 です。"

#: nnabla.parametric_functions.transformer:27 of
msgid "Number of attention heads. Default is 12."
msgstr "attention head の数。デフォルトは 12 です。"

#: nnabla.parametric_functions.transformer:29 of
msgid "Number of encoder layers to stack. Default is 6."
msgstr "使用するエンコーダー層数。デフォルトは 6 です。"

#: nnabla.parametric_functions.transformer:31 of
msgid "Number of decoder layers to stack. Default is 6."
msgstr "使用するデコーダー層数。デフォルトは 6 です。"

#: nnabla.parametric_functions.transformer:33
#: nnabla.parametric_functions.transformer_decode:11
#: nnabla.parametric_functions.transformer_encode:9 of
msgid "Dimension of the feedforward network model. Default is 2048."
msgstr "feedforward ネットワークモデルの次元。デフォルトは 2048 です。"

#: nnabla.parametric_functions.transformer:35 of
msgid "Dropout ratio applied. Default is 0.1."
msgstr "適用されるドロップアウト率。デフォルトは 0.1 です。"

#: nnabla.parametric_functions.transformer:37
#: nnabla.parametric_functions.transformer_decode:15
#: nnabla.parametric_functions.transformer_encode:13 of
msgid ""
"Non-linear activation function to be used. Default is None, which is set "
"as F.relu in the code."
msgstr "使用する非線形活性化関数。デフォルトは None で、その場合F.relu が使用されます。"

#: nnabla.parametric_functions.transformer:39 of
msgid "Additive mask for the src sequence (optional). :math:`(L_S, L_S)`."
msgstr "src シーケンスの追加マスク (オプション). :math:`(L_S, L_S)`"

#: nnabla.parametric_functions.transformer:41 of
msgid "Additive mask for the tgt sequence (optional).:math:`(L_T, L_T)`."
msgstr "tgt シーケンスの追加マスク (オプション). :math:`(L_T, L_T)`"

#: nnabla.parametric_functions.transformer:43 of
msgid "Additive mask for the encoder output (optional). :math:`(L_T, L_S)`."
msgstr "エンコーダー出力の追加マスク (オプション). :math:`(L_T, L_S)`"

#: nnabla.parametric_functions.transformer:45 of
msgid ""
"Key padding mask for src keys per batch (optional).:math:`(B, L_S)`. "
"Specified padding elements will be ignored by the attention layer. Values"
" must be either 1 or 0."
msgstr ""
"バッチごとの src キーのキーパディングマスク (オプション). :math:`(B, L_S)`. 指定されたパディング要素は "
"attention 層によって無視されます。値は 1 または 0 である必要があります。"

#: nnabla.parametric_functions.transformer:47 of
msgid ""
"Key padding mask for tgt keys per batch (optional).:math:`(B, L_T)`. "
"Specified padding elements will be ignored by the attention layer. Values"
" must be either 1 or 0."
msgstr ""
"バッチごとの tgt キーのキーパディングマスク(オプション). :math:`(B, L_T)`. 指定されたパディング要素は "
"attention 層によって無視されます。値は 1 または 0 である必要があります。"

#: nnabla.parametric_functions.transformer:49 of
msgid ""
"Key padding mask for memory keys per batch (optional).:math:`(B, L_S)`. "
"Specified padding elements will be ignored by the attention layer. Values"
" must be either 1 or 0."
msgstr ""
"バッチごとのメモリキーのキーパディングマスク (オプション). :math:`(B, L_S)`. 指定されたパディング要素は attention"
" 層によって無視されます。値は 1 または 0 である必要があります。"

#: nnabla.parametric_functions.transformer:58
#: nnabla.parametric_functions.transformer_decode:32 of
msgid "Output :math:`y` with shape :math:`(L_T, B, E)`"
msgstr "形状 :math:`(L_T, B, E)` の出力 :math:`y`"

#: nnabla.parametric_functions.transformer:62 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"transformer\"``;"
msgstr "次の変数は、パラメータスコープ ``\"transformer\"`` に登録されます。"

#: nnabla.parametric_functions.transformer:64 of
msgid ""
"encoder{layer#} (``need_grad=True``) : parameters for the n'th encoder "
"layer. (shape: ``Refer to transformer_encode for details``)"
msgstr ""
"encoder{layer#} (``need_grad=True``) : n 番目のエンコーダー層のパラメータ (形状: ``Refer to"
" transformer_encode for details``)"

#: nnabla.parametric_functions.transformer:65 of
msgid ""
"decoder{layer#} (``need_grad=True``) : parameters for the n'th decoder "
"layer. (shape: ``Refer to transformer_decode for details``)"
msgstr ""
"decoder{layer#} (``need_grad=True``) : n 番目のデコーダー層のパラメータ (形状: ``詳細については "
"transformer_decodeを参照してください`` )"

#: nnabla.parametric_functions.transformer:74 of
msgid ""
"with parametric_scope(name):\n"
"    output = transformer(<args>)"
msgstr ""

#: nnabla.parametric_functions.transformer_encode:1 of
msgid "Transformer Encoder."
msgstr "Transformer Encoder (トランスフォーマーエンコーダー)"

#: nnabla.parametric_functions.transformer_encode:3 of
msgid "Input sequnce to the encoder layer with shape :math:`(L_S, B, E)`."
msgstr ":math:`(L_S, B, E)` の形状のエンコーダー層への入力シーケンス。"

#: nnabla.parametric_functions.transformer_decode:7
#: nnabla.parametric_functions.transformer_encode:5 of
msgid "Number of embedding dimension."
msgstr "埋め込み次元の数。"

#: nnabla.parametric_functions.transformer_decode:9
#: nnabla.parametric_functions.transformer_encode:7 of
msgid "Number of attention heads."
msgstr "attention head の数。"

#: nnabla.parametric_functions.transformer_decode:13
#: nnabla.parametric_functions.transformer_encode:11 of
msgid "Dropout ratio. Default is 0.1."
msgstr "ドロップアウト率。デフォルトは 0.1 です。"

#: nnabla.parametric_functions.transformer_encode:15 of
msgid "Additive mask for the source sequence with shape :math:`(L_S, L_S)`"
msgstr "形状 :math:`(L_S, L_S)` のソースシーケンスの追加マスク"

#: nnabla.parametric_functions.transformer_encode:17 of
msgid ""
"Padding mask for the source sequence with shape :math:`(B, L_S)`. "
"Specified padding elements will be ignored by the attention layer. Values"
" must be either 1 or 0."
msgstr ""
":math:`(B, L_S)` の形状のソースシーケンスのパディングマスク 。指定されたパディング要素は attention "
"層によって無視されます。値は 1 または 0 である必要があります。"

#: nnabla.parametric_functions.transformer_encode:19 of
msgid "Random generator for Initializer. Defalut is None."
msgstr "イニシャライザーのランダムジェネレーター。デフォルトは None です。"

#: nnabla.parametric_functions.transformer_encode:26 of
msgid "Output :math:`y` with shape :math:`(L_S, B, E)`"
msgstr "形状 :math:`(L_S, B, E)` の出力 :math:`y`"

#: nnabla.parametric_functions.transformer_encode:30 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"transformer_encode\"``;"
msgstr "次の変数は、パラメータスコープ ``\"transformer_encode\"`` に登録されます。"

#: nnabla.parametric_functions.transformer_encode:32 of
msgid ""
"src_self_attn (``need_grad=True``) : self-attention parameters for source"
" sequence. (shape: ``Refer to multi_head_attention for details``)"
msgstr ""
"src_self_attn (``need_grad=True``) : ソースシーケンスの self-attention パラメータ(形状: "
"``詳細については multi_head_attention を参照してください`` )"

#: nnabla.parametric_functions.transformer_encode:33 of
msgid ""
"enc_affine1 (``need_grad=True``) : first affine used in encoder. (shape: "
"``Refer to affine for details``)"
msgstr ""
"enc_affine1 (``need_grad=True``) : エンコーダーで使用される最初の Affine (形状: ``詳細については "
"affine を参照してください`` )"

#: nnabla.parametric_functions.transformer_encode:34 of
msgid ""
"enc_affine2 (``need_grad=True``) : second affine used in encoder. (shape:"
" ``Refer to affine for details``)"
msgstr ""
"enc_affine2 (``need_grad=True``) : エンコーダーで使用される 2 番目の Affine (形状: "
"``詳細については affine を参照してください`` )"

#: nnabla.parametric_functions.transformer_encode:35 of
msgid ""
"enc_layer_norm1 (``need_grad=True``) : fist layer normalization used in "
"encoder. (shape: ``Refer to layer_normalization for details``)"
msgstr ""
"enc_layer_norm1 (``need_grad=True``) : エンコーダーで使用される最初の layer "
"normalization (形状: ``詳細については layer_normalization を参照してください`` )"

#: nnabla.parametric_functions.transformer_encode:36 of
msgid ""
"enc_layer_norm2 (``need_grad=True``) : second layer normalization used in"
" encoder. (shape: ``Refer to layer_normalization for details``)"
msgstr ""
"enc_layer_norm2 (``need_grad=True``) : エンコーダーで使用される 2 番目の layer "
"normalization (形状: ``詳細については layer_normalization を参照してください`` )"

#: nnabla.parametric_functions.transformer_encode:45 of
msgid ""
"with parametric_scope(name):\n"
"    output = transformer_encode(<args>)"
msgstr ""

#: nnabla.parametric_functions.transformer_decode:1 of
msgid "Transformer Decoder."
msgstr "Transformer Decoder (トランスフォーマーデコーダー)"

#: nnabla.parametric_functions.transformer_decode:3 of
msgid "Input sequnce to the decoder layer with shape :math:`(L_T, B, E)`."
msgstr ":math:`(L_T, B, E)` の形状のデコーダー層への入力シーケンス。"

#: nnabla.parametric_functions.transformer_decode:5 of
msgid ""
"Output sequnce from the last layer of the encoder with shape :math:`(L_T,"
" B, E)`."
msgstr ":math:`(L_T, B, E)` の形状のエンコーダーの最後の層からの出力シーケンス。"

#: nnabla.parametric_functions.transformer_decode:17 of
msgid "Additive mask for the target sequence with shape :math:`(L_T, L_T)`."
msgstr ":math:`(L_T, L_T)` の形状のターゲットシーケンスの追加マスク。"

#: nnabla.parametric_functions.transformer_decode:19 of
msgid "Additive mask for the memory sequcne with shape :math:`(L_T, L_S)`."
msgstr ":math:`(L_T, L_S)` の形状のメモリシーケンスの追加マスク。"

#: nnabla.parametric_functions.transformer_decode:21 of
msgid ""
"Padding mask for the target sequence with shape :math:`(B, L_T)`. "
"Specified padding elements will be ignored by the attention layer. Values"
" must be either 1 or 0."
msgstr ""
":math:`(B, L_T)` の形状のターゲットシーケンスのパディングマスク。指定されたパディング要素は、attention "
"層によって無視されます。値は 1 または 0 である必要があります。"

#: nnabla.parametric_functions.transformer_decode:23 of
msgid ""
"Padding mask for the mask sequence with shape :math:`(B, L_S)`. Specified"
" padding elements will be ignored by the attention layer. Values must be "
"either 1 or 0."
msgstr ""
":math:`(B, L_S)` の形状のマスクシーケンスのパディングマスク。指定されたパディング要素は、attention "
"層によって無視されます。値は 1 または 0 である必要があります。"

#: nnabla.parametric_functions.transformer_decode:36 of
msgid ""
"The following variables are registered in a parameter scope "
"``\"transformer_decode\"``;"
msgstr "次の変数は、パラメータスコープ ``\"transformer_decode\"`` に登録されます。"

#: nnabla.parametric_functions.transformer_decode:38 of
msgid ""
"tgt_self_attn (``need_grad=True``) : self-attention parameters for target"
" sequence. (shape: ``Refer to multi_head_attention for details``)"
msgstr ""
"tgt_self_attn (``need_grad=True``) : ターゲットシーケンスの self-attention パラメータ(形状:"
" ``詳細については  multi_head_attention を参照してください`` )"

#: nnabla.parametric_functions.transformer_decode:39 of
msgid ""
"tgt_memory_attn (``need_grad=True``) : attention parameters for target "
"sequence with output from encoder as key. (shape: ``Refer to "
"multi_head_attention for details``)"
msgstr ""
"tgt_memory_attn (``need_grad=True``) : エンコーダーからの出力をキーとするターゲットシーケンスの "
"attention パラメータ (形状: ``詳細については multi_head_attention for details "
"を参照してください``)"

#: nnabla.parametric_functions.transformer_decode:40 of
msgid ""
"dec_affine1 (``need_grad=True``) : first affine used in decoder. (shape: "
"``Refer to affine for details``)"
msgstr ""
"dec_affine1 (``need_grad=True``) : デコーダーで使用される最初の Affine (形状: ``詳細については "
"affine を参照してください`` )"

#: nnabla.parametric_functions.transformer_decode:41 of
msgid ""
"dec_affine2 (``need_grad=True``) : second affine used in decoder. (shape:"
" ``Refer to affine for details``)"
msgstr ""
"dec_affine2 (``need_grad=True``) : デコーダーで使用される 2 番目の Affine (形状: "
"``詳細については affine を参照してください`` )"

#: nnabla.parametric_functions.transformer_decode:42 of
msgid ""
"dec_layer_norm1 (``need_grad=True``) : fist layer normalization used in "
"decoder. (shape: ``Refer to layer_normalization for details``)"
msgstr ""
"dec_layer_norm1 (``need_grad=True``) : デコーダーで使用される最初の layer normalization"
" (形状: ``詳細については layer_normalization を参照してください`` )"

#: nnabla.parametric_functions.transformer_decode:43 of
msgid ""
"dec_layer_norm2 (``need_grad=True``) : second layer normalization used in"
" decoder. (shape: ``Refer to layer_normalization for details``)"
msgstr ""
"dec_layer_norm2 (``need_grad=True``) : デコーダーで使用される 2 番目の layer "
"normalization (形状: ``詳細については layer_normalization を参照してください`` )"

#: nnabla.parametric_functions.transformer_decode:44 of
msgid ""
"dec_layer_norm3 (``need_grad=True``) : third layer normalization used in "
"decoder. (shape: ``Refer to layer_normalization for details``)"
msgstr ""
"dec_layer_norm3 (``need_grad=True``) : デコーダーで使用される 3 番目の layer "
"normalization (形状: ``詳細については layer_normalization を参照してください`` )"

#: nnabla.parametric_functions.transformer_decode:53 of
msgid ""
"with parametric_scope(name):\n"
"    output = transformer_decode(<args>)"
msgstr ""

#: ../../python/api/parametric_function.rst:122
msgid "Parameter Initializer"
msgstr "パラメータイニシャライザー"

#: ../../python/api/parametric_function.rst:124
msgid ""
"Some of the parametric functions optionally takes parameter initializer "
"listed below."
msgstr "一部のパラメトリック関数は、オプションで以下のパラメータイニシャライザーを使用することができます。"

#: nnabla.initializer.BaseInitializer:1 of
msgid "Base class of the parameter initializer."
msgstr "パラメータイニシャライザーのベースクラス"

#: nnabla.initializer.BaseInitializer.__call__:1 of
msgid "Generates an array with an initializer."
msgstr "イニシャライザーで配列を生成します。"

#: nnabla.initializer.BaseInitializer.__call__:3 of
msgid ":obj:`numpy.ndarray` with the shape created."
msgstr "生成された形状の :obj:`numpy.ndarray` 。"

#: nnabla.initializer.BaseInitializer.__call__:6 of
msgid "Array."
msgstr "配列"

#: nnabla.initializer.BaseInitializer.__call__:7 of
msgid ":obj:`numpy.ndarray`"
msgstr ""

#: nnabla.initializer.BaseInitializer.__call__:9 of
msgid ""
"Subclasses of :class:`~nnabla.initializer.BaseInitializer` must override "
"this method."
msgstr ""
":class:`~nnabla.initializer.BaseInitializer` "
"のサブクラスはこのメソッドをオーバーライドする必要があります。"

#: nnabla.initializer.ConstantInitializer:1
#: nnabla.initializer.NormalInitializer:1
#: nnabla.initializer.OrthogonalInitializer:1
#: nnabla.initializer.RangeInitializer:1
#: nnabla.initializer.UniformInitializer:1
#: nnabla.initializer.UniformIntInitializer:1 of
msgid "ベースクラス: :class:`nnabla.initializer.BaseInitializer`"
msgstr ""

#: nnabla.initializer.ConstantInitializer:1 of
msgid "Generates a constant valued array."
msgstr "定数値で構成される配列を生成します。"

#: nnabla.initializer.ConstantInitializer:3 of
msgid "A constant value."
msgstr "定数値。"

#: nnabla.initializer.ConstantInitializer:8 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"w = I.ConstantInitializer(0.1)\n"
"b = I.ConstantInitializer() # this generates constant valued array of "
"default value 0\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv'"
msgstr ""

#: nnabla.initializer.NormalInitializer:1 of
msgid "Generates a random array from a specified normal distribution."
msgstr "指定された正規分布からランダム配列を生成します。"

#: nnabla.initializer.NormalInitializer:3 of
msgid "\\mathbf x \\sim {\\cal N} (\\mathbf 0 | \\sigma^2 \\mathbf I)"
msgstr ""

#: nnabla.initializer.NormalInitializer:6 of
msgid ":math:`\\sigma`."
msgstr ""

#: nnabla.initializer.NormalInitializer:8
#: nnabla.initializer.OrthogonalInitializer:5
#: nnabla.initializer.UniformInitializer:8
#: nnabla.initializer.UniformIntInitializer:8 of
msgid "Random number generator."
msgstr "乱数ジェネレーター。"

#: nnabla.initializer.NormalInitializer:13 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"w = I.NormalInitializer(5e-5)\n"
"b = I.NormalInitializer(0.0)\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

#: nnabla.initializer.UniformInitializer:1 of
msgid "Generates a random array from a specified uniform distribution."
msgstr "指定された均一分布からランダム配列を生成します。"

#: nnabla.initializer.UniformInitializer:3 of
msgid "\\mathbf x \\sim {\\cal U} (a, b)"
msgstr ""

#: nnabla.initializer.UniformInitializer:6 of
msgid "A tuple of two floats, :math:`(a, b)`."
msgstr "2 つの浮動小数点からなるタプル、 :math:`(a, b)` 。"

#: nnabla.initializer.UniformInitializer:13 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"w = I.UniformInitializer() # this generates uniform distribution within "
"the default range of (-1,1)\n"
"b = I.UniformInitializer((-0.5,0.5))\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

#: nnabla.initializer.UniformIntInitializer:1 of
msgid "Generates a random array from a specified integer uniform distribution."
msgstr "指定された整数均一分布からランダム配列を生成します。"

#: nnabla.initializer.UniformIntInitializer:3 of
msgid "\\mathbf x \\sim {\\cal U} ([a, b))"
msgstr ""

#: nnabla.initializer.UniformIntInitializer:6 of
msgid "A tuple of two ints, :math:`[a, b)`."
msgstr "2 つの整数からなるタプル、 :math:`[a, b)` 。"

#: nnabla.initializer.UniformIntInitializer:13 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"w = I.UniformIntInitializer() # this generates uniform integer "
"distribution within the default range of (0,10)\n"
"b = I.UniformIntInitializer((-1,1))\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

#: nnabla.initializer.RangeInitializer:1 of
msgid "Generates an array with sequence of numbers."
msgstr "数値のシーケンスをもつ配列を生成します。"

#: nnabla.initializer.RangeInitializer:3 of
msgid "\\mathbf x[i] = start + step * i"
msgstr ""

#: nnabla.initializer.RangeInitializer:6 of
msgid "A start value."
msgstr "最初の値。"

#: nnabla.initializer.RangeInitializer:8 of
msgid "A step value."
msgstr "間隔の値。"

#: nnabla.initializer.RangeInitializer:13 of
msgid ""
"import nnabla as nn\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([100])\n"
"x.d = I.RangeInitializer(0, 1)(x.shape)"
msgstr ""

#: nnabla.initializer.OrthogonalInitializer:1 of
msgid "Generates an orthogonal matrix weights proposed by Saxe et al."
msgstr "Saxe らによって提案された直交行列の重みを生成します。"

#: nnabla.initializer.OrthogonalInitializer:3 of
msgid "scaling factor which should be decided depending on a type of units."
msgstr "単位タイプに応じて決定する必要があるスケーリングファクター。"

#: nnabla.initializer.OrthogonalInitializer:10 of
msgid ""
"import numpy as np\n"
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"w = I.OrthogonalInitializer(np.sqrt(2.0))\n"
"b = I.ConstantInitializer(0.0)\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

#: nnabla.initializer.OrthogonalInitializer:24 of
msgid ""
"`Saxe, et al. Exact solutions to the nonlinear dynamics of learning in "
"deep linear neural networks. <https://arxiv.org/abs/1312.6120>`_"
msgstr ""

#: nnabla.initializer.calc_normal_std_he_forward:1 of
msgid "Calculates the standard deviation proposed by He et al."
msgstr "He らによって提案された標準偏差を計算します。"

#: nnabla.initializer.calc_normal_std_he_forward:3 of
msgid "\\sigma = \\sqrt{\\frac{2}{NK}}"
msgstr ""

#: nnabla.initializer.calc_normal_std_glorot:11
#: nnabla.initializer.calc_normal_std_he_backward:6
#: nnabla.initializer.calc_normal_std_he_forward:6
#: nnabla.initializer.calc_uniform_lim_glorot:12 of
msgid "Map size of an input Variable, :math:`N`."
msgstr "入力Variableのマップサイズ、 :math:`N` ."

#: nnabla.initializer.calc_normal_std_glorot:13
#: nnabla.initializer.calc_normal_std_he_backward:8
#: nnabla.initializer.calc_normal_std_he_forward:8
#: nnabla.initializer.calc_uniform_lim_glorot:14 of
msgid "Map size of an output Variable, :math:`M`."
msgstr "入力Variableのマップサイズ, :math:`M` ."

#: nnabla.initializer.calc_normal_std_glorot:15
#: nnabla.initializer.calc_normal_std_he_backward:10
#: nnabla.initializer.calc_normal_std_he_forward:10
#: nnabla.initializer.calc_uniform_lim_glorot:16 of
msgid ""
"Convolution kernel spatial shape. In above definition, :math:`K` is the "
"product of shape dimensions. In Affine, the default value should be used."
msgstr ""
"convolution カーネルの空間形状。上記の定義では、 :math:`K` は形状次元の積です。Affine "
"では、デフォルト値を使用する必要があります。"

#: nnabla.initializer.calc_normal_std_he_forward:17 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"s = I.calc_normal_std_he_forward(x.shape[1],64)\n"
"w = I.NormalInitializer(s)\n"
"b = I.ConstantInitializer(0)\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

#: nnabla.initializer.calc_normal_std_he_backward:31
#: nnabla.initializer.calc_normal_std_he_forward:31 of
msgid ""
"`He, et al. Delving Deep into Rectifiers: Surpassing Human-Level "
"Performance on ImageNet Classification. "
"<https://arxiv.org/abs/1502.01852>`_"
msgstr ""

#: nnabla.initializer.calc_normal_std_he_backward:1 of
msgid "Calculates the standard deviation of He et al. (backward case)."
msgstr "He らにより提案された標準偏差を計算します (backward の場合)。"

#: nnabla.initializer.calc_normal_std_he_backward:3 of
msgid "\\sigma = \\sqrt{\\frac{2}{MK}}"
msgstr ""

#: nnabla.initializer.calc_normal_std_he_backward:17 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"s = I.calc_normal_std_he_backward(x.shape[1],64)\n"
"w = I.NormalInitializer(s)\n"
"b = I.ConstantInitializer(0)\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

#: nnabla.initializer.calc_normal_std_glorot:1 of
msgid "Calculates the standard deviation proposed by Glorot et al."
msgstr "Glorot らによって提案された標準偏差を計算します。"

#: nnabla.initializer.calc_normal_std_glorot:5 of
msgid ""
"We have updated the definition as following from v.1.2. It may affect the"
" behavior of existing scripts that rely on the default initialization."
msgstr "v.1.2 から以下のように定義を更新しました。デフォルトの初期化を用いている既存のスクリプトの動作に影響を与える可能性があります。"

#: nnabla.initializer.calc_normal_std_glorot:8 of
msgid "\\sigma = \\sqrt{\\frac{2}{K(N + M)}}"
msgstr ""

#: nnabla.initializer.calc_normal_std_glorot:22 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"s = I.calc_normal_std_glorot(x.shape[1],64)\n"
"w = I.NormalInitializer(s)\n"
"b = I.ConstantInitializer(0)\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

#: nnabla.initializer.calc_normal_std_glorot:36
#: nnabla.initializer.calc_uniform_lim_glorot:37 of
msgid ""
"`Glorot and Bengio. Understanding the difficulty of training deep "
"feedforward neural networks "
"<http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf>`_"
msgstr ""

#: nnabla.initializer.calc_uniform_lim_glorot:1 of
msgid ""
"Calculates the lower bound and the upper bound of the uniform "
"distribution proposed by Glorot et al."
msgstr "Glorot らによって提案された均一分布の下限と上限を計算します。"

#: nnabla.initializer.calc_uniform_lim_glorot:5 of
msgid ""
"We have updated the definition as following from v.1.3. It may affect the"
" behavior of existing scripts that rely on the default initialization."
msgstr "v.1.3 から以下のように定義を更新しました。デフォルトの初期化を用いている既存のスクリプトの動作に影響を与える可能性があります。"

#: nnabla.initializer.calc_uniform_lim_glorot:8 of
msgid "b &= \\sqrt{\\frac{6}{K(N + M)}}\\\\ a &= -b"
msgstr ""

#: nnabla.initializer.calc_uniform_lim_glorot:23 of
msgid ""
"import nnabla as nn\n"
"import nnabla.parametric_functions as PF\n"
"import nnabla.initializer as I\n"
"\n"
"x = nn.Variable([60,1,28,28])\n"
"lb,ub= I.calc_uniform_lim_glorot(x.shape[1],64)\n"
"w = I.UniformInitializer((lb,ub))\n"
"b = I.ConstantInitializer(0)\n"
"h = PF.convolution(x, 64, [3, 3], w_init=w, b_init=b, pad=[1, 1], "
"name='conv')"
msgstr ""

